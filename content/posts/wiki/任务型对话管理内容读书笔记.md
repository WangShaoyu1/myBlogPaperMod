---
author: "王宇"
title: "任务型对话管理内容读书笔记"
date: 四月28,2023
description: "廖鸿珍"
tags: ["廖鸿珍"]
ShowReadingTime: "12s"
weight: 474
---
一、背景
----

人机交互(Human Computet Interaction, HCI)作为信息时代人类与计算机之间信息交流的基础技术，受到学术界和工业界的广泛关注。人机对话(Human-Machine Dialogue)是人机交互技术的核  
心领域，旨在最大限度地模仿人与人之间的对话方式，使得人类能够用更自然的方式与机器进行交流。艾伦·图灵（Alan Turing）在1950年提出图灵测试，认为如果人类无法区分和他对话交谈的是机器还是人类，那么就可以说机器通过了图灵测试，拥有高度的智能。

二、对话系统的发展历程
-----------

**第一代对话系统主要是基于规则的对话系统**，以ell为首的第一代对话系统，主要依赖专家制定的人工语法规则和本体设计。这种方法易理解，但是由于其全部使用符号规则和模板需要消耗大量的人力和物力，导致跨领域的扩展性严重不足。 

**基于统计学方法的数据驱动的第二代对话系统，**不需要人工设计规则和模板，通过统计机器学习方法降低对话系统的手工复杂性。这种方法具有弱学习能力，但是解释性差、不易修补漏洞，仍旧难以扩大规模。

**第三代对话系统是基于深度学习为主的对话系统**，依然延续了统计对话系统的框架，但各个模块都采用了神经网络模型。

对话系统的迅猛发展也引起工业界的广泛关注，以微软小冰为代表的聊天机器人使得人机对话技术更具实用价值和商业价值，但仍在自然性、逻辑性和流畅性等方面和人类有一定的差距。在任务型  
对话系统领域，苹果ST、亚马逊Ech。、微软敦煌小冰等开始步入应用阶段，帮助用户便捷处理复杂任务，减轻了人工负担。但是，这些系统的实现离不开大量手工定制规则模板，工程量巨大，缺乏通用性和可移植性，技术方法有待进一步探索。目前，任务型对话系统逐渐应用在各行各业，使得“人机”交互方式不再是简单的输入设备和触摸屏，而是具有个性化的自然语言交互

三、对话系统类型
--------

根据不同的应用场景将对话系统分为两种类型：任务型对话系统(task-oriented dialogue systems)和非任务型对话系统(non-task-oriented dialogue systems)，非任务型对话系统又称闲聊机器人(chat bots)，两种类型的对比如下

![](/download/attachments/101816897/image2023-4-26_20-23-26.png?version=1&modificationDate=1682511806884&api=v2)

任务型对话系统面向垂直领域，目的是使用尽可能少的对话轮数帮助用户完成预定任务或动作，例如预定机票、酒店和餐馆等。大多数任务型对话系统对话数据规模较小，难以通过大量数据进行模型训练，前期需用手工制定的规则解决冷启动问题，这使得对话系统的构建变得昂贵和耗时，限制了对话系统在其他领域的使用，非任务型对话系统面向开放领域，要求其回复具有一致性、多样化和个性化。由于话题自由，因此对系统的知识要求极高。实际的非任务型对话系统容易产生“安全回复”问题，如“我不知道”，“我也是”，“好的”等，使得聊天机器人的大多数答案趋近相同。同时，聊天是一个连续交互的过程，句子的语义需要结合对话上下文才能确定。但目前非任务型对话系统的语料大多是从社交网络爬虫所得，缺乏多轮对话相关的上下文语料，导致非任务型对话系统难以保持上下文信息的一致性。因此，非任务型对话系统离实际应用尚有差距。

任务型对话系统从结构上可分成两类，一类是 pipeline 系统，采用模块化结构（如图1），一般包括四个关键模块：

*   自然语言理解（Natural Language Understanding, NLU）  
    对用户的文本输入进行识别解析，得到槽值和意图等计算机可理解的语义标签。
*   对话状态跟踪（Dialog State Tracking, DST）  
    根据对话历史，维护当前对话状态，对话状态是对整个对话历史的累积语义表示，一般就是槽值对(slot-value pairs)。
*   对话策略（Dialogue Policy）  
    根据当前对话状态输出下一步系统动作。一般对话状态跟踪模块和对话策略模块统称为对话管理模块（Dialogue manager, DM）。
*   自然语言生成（Natural Language Generation, NLG）  
    将系统动作转换成自然语言输出。

![](/download/attachments/101816897/%E5%9B%BE8.png?version=1&modificationDate=1682512587796&api=v2)

任务型对话系统的另一种实现是端到端系统，也是近年来学界比较热门的方向（如图2），这类结构希望训练一个从用户端自然语言输入到机器端自然语言输出的整体映射关系，具有灵活性强、可拓展性高的特点，减少了设计过程中的人工成本，打破了传统模块之间的隔离。然而，端到端模型对数据的数量和质量要求很高，并且对于填槽、API 调用等过程的建模不够明确，现阶段业界应用效果有限，仍处在探索中。

![](/download/attachments/101816897/%E5%9B%BE16.png?version=1&modificationDate=1682512918326&api=v2)

四、对话模型三大问题：
-----------

*   可拓展性差
*   标注数据少
*   训练效率低

 对话管理模型痛点一：可拓展性差

如前文所述，对话管理器由两部分组成：对话状态跟踪器（DST）和对话策略（dialog policy）。

传统的 DST 研究中，最具代表的是剑桥大学的学者们在2017年提出的神经信度跟踪模型（neural belief tracker, NBT）\[12\]，利用神经网络来解决单领域复杂对话的对话状态跟踪问题。NBT 通过表征学习（representation learning）来编码上轮系统动作、本轮用户语句和候选槽值对，在高维空间中计算语义的相似性，从而检测出本轮用户提到的槽值。因此 NBT 可以不依赖于人工构建语义词典，只需借助槽值对的词向量表示就能识别出训练集未见但语义上相似的槽值，实现槽值的可拓展。

后续地，剑桥学者们对 NBT 进一步改进，将输入的槽值对改成领域-槽-值三元组，每轮识别的结果采用模型学习而非人工规则的方法进行累积，所有数据采用同一个模型训练，从而实现不同领域间的知识共享，模型的总参数也不随领域数目的增加而增加。

在传统的 Dialogue Policy 研究领域中，最具代表性的是剑桥学者们提出的基于 ACER 方法的策略优化。通过结合 Experience replay 技巧，作者分别尝试了 trust region actor-critic 模型和 episodic natural actor-critic 模型，验证了 AC 系列的深度增强（强化）学习算法在样本利用效率、算法收敛性和对话成功率上都达到了当时最好的表现。

然而传统的对话管理模型在可拓展性方面仍需改进，具体在三个方面：1）如何处理变化的用户意图，2）如何变化的槽位和槽值，3）如何处理变化的系统动作。

**变化的用户意图**

在实际应用场景中，时常会出现由于用户意图未被考虑到，使得对话系统给出不合理回答的情况。如图3所示的例子，用户的“confirm”意图未被考虑，这时就需要加入新的话术来帮助系统处理这样的情况。

![](/download/attachments/101816897/%E5%9B%BE1.png?version=1&modificationDate=1682513914238&api=v2)

**变化的槽位和槽值**  
在多领域或复杂领域的对话状态跟踪问题中，如何处理槽位与槽值的变化一直是一个难题。对于有的槽位而言，槽值可能是不可枚举的（这里的不可枚举指的是槽值没有限制，或可取值过多），例如，时间、地点和人名，甚至槽值集合是动态变化的，例如航班、电影院上映的电影。在传统的对话状态跟踪问题中，通常默认槽位和槽值的集合固定不变，这样就大大降低了系统的可拓展性。

**变化的系统动作**

可拓展性问题的最后一个方面在于系统动作空间难以预定义。如图7所示，在设计一个电子产品推荐系统时，也许一开始并不会考虑到用户会问到如何升级产品操作系统这样的问题，但现实的情况是你无法限定用户只问系统能解决的问题。如果系统动作空间事先框定，在用户提出新问题时就会导致一连串的答非所问，导致极差的用户体验。

![](/download/attachments/101816897/%E5%9B%BE7.png?version=1&modificationDate=1682514102344&api=v2)

#### 对话管理模型痛点二：标注数据少

随着对话系统应用领域的多样化，对数据的需求也更加多样化，若想训好一个任务型对话系统，通常都需要尽可能多的该领域的数据，但一般来说，想要获取高质量的有标注数据的成本很高。为此学者们进行了各种研究尝试，主要可分为三种思路：1）用机器自动标注数据，降低数据标注的成本；2）对话结构挖掘，尽可能高效利用无标注数据；3）加强数据采集策略，高效获取优质的数据。

#### 对话管理模型痛点三：训练效率低

随着深度增强学习在游戏围棋领域的大获成功，该方法在任务导向型对话领域也有广泛应用。例如ACER 对话管理方法，使用了 model-free 深度增强学习，通过结合 Experience Replay、信度域约束、预训练等技巧，大大提高了增强学习算法在任务型对话领域的训练效率和稳定性。

然而，简单地套用增强学习算法并不能满足对话系统的实际应用。这主要是因为对话领域不像游戏围棋那样有清晰的规则、奖励函数，动作空间简单明确，还有完美的环境模拟器可以生成数以亿计的高质量交互数据。

对话任务中，一般包括了多样变化的槽位槽值和动作意图，这使得对话系统的动作空间急剧增大且难以预定义。传统扁平的增强学习（flat reinforcement learning）方法由于对所有的系统动作进行 one-hot 编码，会存在维度灾难，因此不再适用于处理动作空间非常大的复杂对话问题，为此学者们进行了诸多研究尝试，包括 model-free RL、model-based RL 和 human-in-the-loop 三个方向。

五、总结
----

目前的对话系统发展迅速，但仍存在诸多的问题：如可拓展性差、标注数据少、训练效率低等，需要我们逐个去优化解决，使人工智能对话领域得到新的进步。

  

  

  

[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)

[Configure buttons visibility](/users/tfac-settings.action)