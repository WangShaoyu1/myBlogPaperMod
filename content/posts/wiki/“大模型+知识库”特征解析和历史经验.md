---
author: "王宇"
title: "“大模型+知识库”特征解析和历史经验"
date: 十二月25,2023
description: "大模型+知识文档"
tags: ["大模型+知识文档"]
ShowReadingTime: "12s"
weight: 689
---
*   1[1\. 测试目的和结论](#id-“大模型+知识库”特征解析和历史经验-测试目的和结论)
    *   1.1[1.1. 基本结论和指导意见](#id-“大模型+知识库”特征解析和历史经验-基本结论和指导意见)
*   2[2\. 只使用提示词情况](#id-“大模型+知识库”特征解析和历史经验-只使用提示词情况tt2)
    *   2.1[2.1. 强领域约束提示词](#id-“大模型+知识库”特征解析和历史经验-强领域约束提示词)
    *   2.2[2.2. 弱领域约束提示词](#id-“大模型+知识库”特征解析和历史经验-弱领域约束提示词)
*   3[3\. 使用提示词+知识库的情况](#id-“大模型+知识库”特征解析和历史经验-使用提示词+知识库的情况)
    *   3.1[3.1. 回复准确率受提示词和匹配知识库的影响](#id-“大模型+知识库”特征解析和历史经验-回复准确率受提示词和匹配知识库的影响)
        *   3.1.1[3.1.1. 没有匹配相关知识时](#id-“大模型+知识库”特征解析和历史经验-没有匹配相关知识时)
        *   3.1.2[3.1.2. 匹配相关知识时](#id-“大模型+知识库”特征解析和历史经验-匹配相关知识时)
    *   3.2[3.2. 确保拼接文本的篇幅在合适的范围](#id-“大模型+知识库”特征解析和历史经验-确保拼接文本的篇幅在合适的范围)
    *   3.3[3.3. 统计类意图的处理](#id-“大模型+知识库”特征解析和历史经验-统计类意图的处理)
*   4[4\. 多知识库情况](#id-“大模型+知识库”特征解析和历史经验-多知识库情况)
*   5[5\. 不同格式知识库](#id-“大模型+知识库”特征解析和历史经验-不同格式知识库)

1\. 测试目的和结论
===========

**当前（2023年12月）及未来我们需要使用“大模型+知识库”的形式，去为用户提供服务。但是使用这种形式的技术去为用户提供服务的我们，对这种形式的技术还有一些的未知的地方。诸如“用户问和提示词不相关的问题时，它会发生什么？”，“我上传2个知识库时，它又会怎么回答？”等等。对这些问题，或许用过大模型的同事会有一些直觉性、先验性的判断。为了验证这种判断，以及觉察一些更细节、以及我们不小心忽略的东西。我们须建立对“大模型+提示词+知识库”这种技术形式的不同情况的测试评估，以形成更全面的认知。这也便于我们之后具体应用的开发设计。**

要分析“大模型+知识库”的形式。首先先得回到用户，理解用户脑海里面自己和自己的对话，理解场景的含义。

我们用大模型的目的是什么？换句话说：当你点开文心一言app输入文字，或者你点开chatGPT输入文字的时候。你到底想干嘛？你的目的是什么？  
我们不会无缘无故的点开文心一言，我们点开他是因为我们有所诉求！我们期望解决某个问题！我们填写的提示词，即是为了解决某个问题、达成某个目的，而设置的。要达成目的，肯定要指明做什么事，有什么要求。而知识库是帮助更好的达成目的的手段。知识库不能称为场景。知识库得结合提示词，而作为达成目的的手段而生。  
场景即是目的。我们每有一个目的，就每有一个场景。你想要找好吃的食谱，这就是一个场景。你想买新食记的饺子，这又是另一个场景。大模型是可以支持一个提示词里设定多个场景的。

基于以上分析，大模型+知识库的使用就可能包含以下不同的情况。当然还有一种是多个大模型进行协同分工的情况，当前先不讨论这种情况。

A场景相关知识库：食谱领域知识

用户

知识库

知识库问答技术

文档问答

TableQA

结构化数据

文档数据

结构化数据

提示词

A场景：编写PPT大纲

用户

提示词

A场景：食谱推荐

A场景相关知识库：食谱领域知识

用户

提示词

A场景：食谱推荐

B场景：情感咨询

A场景相关知识库：食谱领域知识

用户

提示词

A场景：食谱推荐

C场景：情感咨询

B场景：商品推荐

B场景相关知识库：商品领域知识

A场景相关知识库：食谱领域知识

用户

提示词

A场景：食谱推荐

C场景：情感咨询

B场景：商品推荐

B场景相关知识库：商品领域知识

N场景：XXXXX

知识库

知识库

知识库

1

2

3

4

5

![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij48cGF0aCBkPSJNMjEuOTkgNGMwLTEuMS0uODktMi0xLjk5LTJINGMtMS4xIDAtMiAuOS0yIDJ2MTJjMCAxLjEuOSAyIDIgMmgxNGw0IDQtLjAxLTE4ek0xOCAxNEg2di0yaDEydjJ6bTAtM0g2VjloMTJ2MnptMC0zSDZWNmgxMnYyeiIvPjxwYXRoIGQ9Ik0wIDBoMjR2MjRIMHoiIGZpbGw9Im5vbmUiLz48L3N2Zz4= "显示评论")

//<!\[CDATA\[ (function() { $ = AJS.$; var graphContainer = document.getElementById('drawio-macro-content-2eaaebfd-e609-4df2-a91f-bb22c464901c'); DrawioProperties = { contextPath : AJS.contextPath(), buildNumber : 8401 }; var readerOpts = {}; readerOpts.loadUrl = '' + '/rest/drawio/1.0/diagram/crud/%E6%83%85%E5%86%B5/114669640?revision=19'; readerOpts.imageUrl = '' + '/download/attachments/114669640/情况-4ccfe43a7c1fae1b5e2f551aace61745ef52d5ad.png' + '?version=19&api=v2'; readerOpts.editUrl = '' + '/plugins/drawio/addDiagram.action?ceoId=114669640&owningPageId=114669640&diagramName=%E6%83%85%E5%86%B5&revision=19'; readerOpts.editable = true; readerOpts.canComment = true; readerOpts.stylePath = STYLE\_PATH; readerOpts.stencilPath = STENCIL\_PATH; readerOpts.imagePath = IMAGE\_PATH + '/reader'; readerOpts.border = true; readerOpts.width = '1200'; readerOpts.simpleViewer = false; readerOpts.tbstyle = 'top'; readerOpts.links = 'auto'; readerOpts.lightbox = true; readerOpts.resourcePath = ATLAS\_RESOURCE\_BASE + '/resources/viewer'; readerOpts.disableButtons = false; readerOpts.zoomToFit = true; readerOpts.language = 'zh'; readerOpts.licenseStatus = 'OK'; readerOpts.contextPath = AJS.contextPath(); readerOpts.diagramName = decodeURIComponent('%E6%83%85%E5%86%B5'); readerOpts.diagramDisplayName = ''; readerOpts.aspect = 'eCfN\_jPU5WSyWwxNSIL5'; readerOpts.ceoName = '“大模型+知识库”特征解析和历史经验'; readerOpts.attVer = '19'; readerOpts.attId = '114673119'; readerOpts.lastModifierName = '未知用户 (tangwei)'; readerOpts.lastModified = '2023-12-21 16:27:42.567'; readerOpts.creatorName = '未知用户 (tangwei)'; //Embed macro specific info readerOpts.extSrvIntegType = '$extSrvIntegType'; readerOpts.gClientId = '$gClientId'; readerOpts.oClientId = '$oClientId'; readerOpts.service = '$service'; readerOpts.sFileId = '$sFileId'; readerOpts.odriveId = '$odriveId'; readerOpts.diagramUrl = '$diagramUrl'; readerOpts.csvFileUrl = '$csvFileUrl'; readerOpts.pageId = '$pageId' || Confluence.getContentId(); readerOpts.aspectHash = '$aspectHash'; readerOpts.useExternalImageService = '$useExternalImageService' == 'true'; readerOpts.isTemplate = '$isTemplate' == 'true'; if (readerOpts.width == '') { readerOpts.width = null; } // LATER: Check if delayed loading of resources can be used for image placeholder mode var viewerPromise = createViewer(graphContainer, readerOpts); if(readerOpts.editable) { $(graphContainer).data('viewerConfig', readerOpts); $(graphContainer).on('drawioViewerUpdate', updateDrawioViewer); } viewerPromise.done(function(viewer) { updateCachedDiagram(graphContainer, readerOpts, viewer); }); })(); //\]\]>

1.1. 基本结论和指导意见
--------------

第一种情况是最常见的。基本上文心一言上的各种提示词模板、星火大模型的大部分助手。均是这种使用形式。

*   **问和A场景无关的问题结论。**通过测试，我们发现2个细节：①如果我们为场景A编写的是强领域约束的提示词，那么与A场景无关的问题，更大的可能会被理解为场景A，而以场景A的需求回复。如果为场景A编写的是弱领域约束的提示词，那么与A场景无关的问题，有更大可能性会被正确回复。②如果设定诸如：“广州影子科技有限公司的智能客服，不仅能回答公司相关的问题，也能回答各个领域的知识”的提示词，大模型就能比较好的回复其他场景的问题。

第二种情况也是比较常见的。通过接入知识库，提供更准确的知识服务。类似的场景是：设置一个食谱推荐官，使用食谱信息数据库作为知识库，这样大模型能根据食谱数据库为用户推荐食谱。

*   **回复的准确率以及如何提高回复效果。**通过测试，我们发现3个细节：①回复准确率受提示词和匹配知识库的影响。当没有匹配相关知识时，通过合理调整数据内容、数据切分、优化匹配知识的阈值和数量，能够有效优化准确率；当已匹配相关知识，通过设定诸如“先理解用户的问题”、“给出回复前，你需要自行通过列举的方式以确保答案的准确性”等 能够较为有效的提高准确率。②确保拼接文本的篇幅在合适的范围，因为字越多，模型找到正确答案的可能性越低，导致识别准确率降低。③大模型本身是很难处理统计类的意图的。分为两种难度。第一，诸如：“锅巴饭和白切鸡一共有多少卡路里”，这种指定某几个实体，计算他们之间的数字总和、差值等，大模型可能会算错；第二，诸如：“最受欢迎（点赞量最高）的食谱是哪个？”、“处理步骤最简单的食谱是哪几个”这种需要首先查看所有食谱，然后再做计算推理的，大模型几乎无法做到。要处理这种问题，2种可行的方式分别是使用TableQA技术和把这些计算整理成知识。整理成知识这种方式，已实践并有不错效果（参考23年12月元旦项目）。TableQA技术当前的产品准确率较低，暂时不可用。
*   **问和A场景无关的问题结论。**结论与第一种情况一致。

第三、四种情况也会用到。此时通常要先指示大模型进行场景识别，然后再依据场景的特性去回复用户。

*   **当存在多个不同场景的知识库时，如果知识库的内容有相近的地方，则会有混淆的可能。反之，知识库内容差异较大，混淆的可能也会相应减少**。
*   **问和A场景无关的问题结论。**结论与第一种情况一致。

知识库技术有文档问答和TableQA技术。文档问答本身是可以放入结构化数据和文档数据的。

  

往下的内容以结论到论据的顺序编写。

2\. 只使用提示词情况
============

提示词对回复的效果影响较大。强领域约束的提示词，会使得大模型基本在提示词约束的场景内回答。弱领域约束的提示词，会让大模型能够回复知识库和其他场景的问题。

2.1. 强领域约束提示词
-------------

以下设置的提示词中标记角色为：PPT大纲撰写高手。结果无论用户问题的意图指向什么场景：如心理咨询、情感引导、数学、物理等等场景，其回复给出的都是一个PPT大纲。这样一个提示词是属于一个强领域约束的提示词。

![](/download/thumbnails/114669640/image2023-12-13_22-17-40.png?version=1&modificationDate=1702477060070&api=v2)

2.2. 弱领域约束提示词
-------------

通过在角色中设定一些较为生活化的角色，补充一些特殊要求，模型对与场景无关的回答会能回答，并回答的更好。

下面这个例子设定的主场景是食谱推荐，厨师的角色。当问用户其他场景时，模型会回复”对不起，您的问题似乎与食谱和商品无关。如果您有任何关于食谱或商品的问题，例如询问某种食物的营养成分，或者需要推荐某种适合您的食品，我会很乐意为您提供帮助。“

![](/download/attachments/114669640/image2023-12-19_15-25-3.png?version=1&modificationDate=1702970712017&api=v2)

但是当设定角色同时还是一个生活家，以及要求模型”客人问其他问题，像一个朋友一样和他们聊天“。这时问到其他场景，模型即能正常的回复问题。弱领域约束的提示词可能包括一些生活化的角色、要求、任务等等。

![](/download/attachments/114669640/image2023-12-13_22-29-22.png?version=1&modificationDate=1702477761716&api=v2)![](/download/attachments/114669640/image2023-12-13_22-36-25.png?version=1&modificationDate=1702478187035&api=v2)

3\. 使用提示词+知识库的情况
================

每份知识库部分情况下即代表一个场景。与用户问题相关的知识，会被检索出并插入到大模型的prompt中，作为提示词的一部分输入给大模型。其技术原理可参考（[GPT embedding和fine-tuning技术解析](https://wiki.yingzi.com/pages/viewpage.action?pageId=101812168)）。

3.1. 回复准确率受提示词和匹配知识库的影响
-----------------------

当没有匹配相关知识时，通过合理调整数据内容、数据切分、优化匹配知识的阈值和数量，能够有效优化准确率；当已匹配相关知识时，通过设定诸如“先理解用户的问题”、“给出回复前，你需要自行通过列举的方式以确保答案的准确性”等 能够较为有效的提高准确率。

### 3.1.1. 没有匹配相关知识时

**模型能够回复正确的基本前提是拼接有与问题相关的知识**。虽然未拼接的情况下，模型也可能回复正确，但这种情况毕竟是极少数（猜测可能是模型通过推理得出的答案，或也可能是模型厂商偷用上传的知识库进行了训练）。我们首要关注的还是确保相关知识能够得到正确匹配。可优化的项目和经验方法包括：

可优化项目

方法

案例

数据内容

人为的补充知识的完整主语、宾语等信息。通过增加主语、宾语等信息可增加知识被匹配的概率。基本上可以这样认为：知识越完整，被匹配的概率越高。

*   ”7月27日，《设计与人》“这条知识，修改为”2023年7月27日，UED技术线举办《设计与人》培训活动，讲师是贺春斌“

数据切分

知识规整的条件下，使用自定义切分，人为控制每条知识的内容。

![](/download/attachments/114669640/image2023-12-25_15-50-17.png?version=1&modificationDate=1703490618061&api=v2)类似这样知识有明显边界的，使用自定义切分。确保每条知识之间不被混淆。

每条知识的长度不宜太长。

  

知识阈值

多实验多尝试。还需根据场景的特征调整。

  

知识拼接数量

多实验多尝试，但不适宜拼接太少。

可以分别测试10、15、20、25...的准确率。选择准确率较高的值。

### 3.1.2. 匹配相关知识时

当已匹配相关知识时，通过设定诸如“先理解用户的问题”、“给出回复前，你需要自行通过列举的方式以确保答案的准确性”等 能够较为有效的提高准确率。当然方法不只一个，在吴恩达的[【ChatGPT】吴恩达『提示工程』课程](https://zhuanlan.zhihu.com/p/626966526) 中详细介绍了该方法和其他有效的方法。

3.2. 确保拼接文本的篇幅在合适的范围
--------------------

![](/download/attachments/114669640/image2023-12-25_15-18-27.png?version=1&modificationDate=1703488707970&api=v2)

该篇论文（[Stanford study challenges assumptions about language models: Larger context doesn't mean better understanding  (venturebeat.com)](https://venturebeat.com/ai/stanford-study-challenges-assumptions-about-language-models-larger-context-doesnt-mean-better-understanding/)）显示当前大模型的一些特征：

*   **提供更多上下文信息并非总是有益的**。尽管在某些情况下，向语言模型提供更多的上下文信息可以提高其性能，但是在一定量之后，增加更多的上下文信息可能无法带来显著的性能改进。
*   **模型优先使用开头和末尾信息**。语言模型更容易处理输入信息的开头和末尾部分，所以把关键信息放在这些位置或缩短文档长度可能有助于提升性能。

该篇模型没有提供document的文本长度，无法准确预估其特征影响的范围。但是足以警惕的是：上下文不要太长！

3.3. 统计类意图的处理
-------------

**大模型本身是很难处理统计类的意图的**。分为两种难度。

第一，诸如：“锅巴饭和白切鸡一共有多少卡路里”，这种指定某几个实体，计算他们之间的数字总和、差值等，大模型可能会算错。以下正确数值为3427。

![](/download/attachments/114669640/image2023-12-25_17-20-37.png?version=1&modificationDate=1703496037475&api=v2)  
第二，诸如：“最受欢迎（点赞量最高）的食谱是哪个？”、“处理步骤最简单的食谱是哪几个”这种需要首先查看所有食谱，然后再做计算推理的，大模型几乎无法做到。

![](/download/attachments/114669640/image2023-12-25_17-21-32.png?version=1&modificationDate=1703496092631&api=v2)![](/download/attachments/114669640/image2023-12-25_17-22-14.png?version=1&modificationDate=1703496135035&api=v2)

要处理这种问题，2种可行的方式分别是使用 TableQA技术 和 把这些计算整理成知识。

*   将计算类场景整理成知识这种方式，已实践并有不错效果（参考23年12月元旦项目）。整理知识类似如下：

![](/download/attachments/114669640/image2023-12-25_17-25-27.png?version=1&modificationDate=1703496327602&api=v2)

*   大模型版TableQA技术当前的产品准确率较低，暂时不可用。

（参考[大模型知识问答测试](https://wiki.yingzi.com/pages/viewpage.action?pageId=114662838)中对通义版TableQA的准确率测算 和 [阿里智能对话机器人（通义版）](https://wiki.yingzi.com/pages/viewpage.action?pageId=114667467)对其技术原理的解析）

4\. 多知识库情况
==========

  

该种方式可能适用于这种场景：以手机万得厨app场景为例，万得厨app有食品类商品售卖、有食谱、食谱发布分享、有万得厨设备管理等场景。如要一个大模型同时去支持这些场景的对话回复，那么大模型需要识别不同场景，而根据场景去扮演商品导购师、食谱”导购“师、客服、个人助手等角色。并且商品导购师、食谱”导购“师、个人助手需要分别搭配商品知识库、食谱知识库和个人信息知识库。该场景下，毫无疑问的，大模型同时也要兼顾其他场景的回复。

那么此时大模型对于这种复杂场景的支持力度如何？大模型会如何回复？我们设计了如下的测试场景

提示词：

角色设定：你是一个机器人  
目标任务：根据需求中的步骤执行  
需求说明：  
请按如下步骤执行：  
1、识别用户的意图是食谱场景、商品场景、企业客服场景、情绪舒缓场景或其他场景。  
2、说出自己的场景判断。  
3、若是食谱场景、商品场景、企业客服场景，则根据知识库回答。若是情绪舒缓场景，则提供情感咨询的专业服务。若是其他场景，则按那个场景的情况回答

  
场景说明：  
1、食谱场景：食谱是做菜的菜单。包含步骤、食材、食谱营养  
2、商品场景：食品类的商品，设计食品类商品推荐、商品购买、商品信息查询  
3、企业客服场景：涉及广州影子公司的对外交流、培训活动、团建等活动信息查询

  

相关知识库：  
<wikicontent>

请根据以上内容回答用户的问题。

用户问题：<wikiquestion>

知识库：食谱知识库、商品知识库、影子元旦知识库

结果：[import20231225-2124.xlsx](/download/attachments/114669640/import20231225-2124.xlsx?version=1&modificationDate=1703516093313&api=v2)

![](/download/attachments/114669640/image2023-12-25_22-18-8.png?version=1&modificationDate=1703513888206&api=v2)

其结果预示着以下特征和难点：

*   不同场景的知识库近似时，回复的内容容易混淆。万得厨中的商品是基本是食品类商品，比较容易和食谱互相之间混淆。
*   不同场景的知识库近似，同时问题对两个场景间指代不明确，但是明确是这两个场景范围内的问题。回复主要会根据匹配的知识库回答。会出现商品和食谱同时出现在回复中的情况。
*   差异比较大的场景混淆的可能性较低。如心理咨询和企业客服场景、商品和食谱场景 这两类差异较大的场景，误触可能性低。
*   其他场景也能回复。结论同[只使用提示词情况]()

准确率无法得出结论和推测。不同场景因知识库不同，准确率和特征影响程度不一。

5\. 不同格式知识库
===========

引用 [大模型知识问答测试](https://wiki.yingzi.com/pages/viewpage.action?pageId=114662838) 该文档数据。阿里通义使用的是[数据库问答](https://wiki.yingzi.com/pages/viewpage.action?pageId=114667467)技术，科大讯飞和百度文心使用的是文档问答技术。测试中，使用的都是同一份食谱数据。

![](/download/attachments/114669640/image2023-12-15_14-23-46.png?version=1&modificationDate=1702621426650&api=v2)

  

[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)

[Configure buttons visibility](/users/tfac-settings.action)