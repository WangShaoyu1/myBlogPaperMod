---
author: "王宇"
title: "1.8、小米语音助手小爱同学调研"
date: 三月30,2023
description: "1、竞品调研"
tags: ["1、竞品调研"]
ShowReadingTime: "12s"
weight: 63
---
*   1 [一、产品背景](#id-1.8、小米语音助手小爱同学调研-一、产品背景)
*   2[二、产品架构和生态](#id-1.8、小米语音助手小爱同学调研-二、产品架构和生态)
*   3[三、产品背后的核心技术](#id-1.8、小米语音助手小爱同学调研-三、产品背后的核心技术)
    *   3.1[3.1 全双工关键技术](#id-1.8、小米语音助手小爱同学调研-3.1全双工关键技术)
        *   3.1.1[3.1.1 拒识](#id-1.8、小米语音助手小爱同学调研-3.1.1拒识)
            *   3.1.1.1[3.1.1.1 策略拒识](#id-1.8、小米语音助手小爱同学调研-3.1.1.1策略拒识)
            *   3.1.1.2[3.1.1.2 语义拒识](#id-1.8、小米语音助手小爱同学调研-3.1.1.2语义拒识)
            *   3.1.1.3[3.1.1.3 多模态拒识](#id-1.8、小米语音助手小爱同学调研-3.1.1.3多模态拒识)
        *   3.1.2[3.1.2 语义判不停](#id-1.8、小米语音助手小爱同学调研-3.1.2语义判不停)
            *   3.1.2.1[3.1.2.1 规则系统](#id-1.8、小米语音助手小爱同学调研-3.1.2.1规则系统)
            *   3.1.2.2[3.1.2.2 单轮判别模型](#id-1.8、小米语音助手小爱同学调研-3.1.2.2单轮判别模型)
            *   3.1.2.3[3.1.2.3 多轮判不停](#id-1.8、小米语音助手小爱同学调研-3.1.2.3多轮判不停)
*   4[四、产品的硬件整体设计](#id-1.8、小米语音助手小爱同学调研-四、产品的硬件整体设计)
    *   4.1[4.1 小米小爱音箱pro拆解细节](#id-1.8、小米语音助手小爱同学调研-4.1小米小爱音箱pro拆解细节)
        *   4.1.1 [4.1.1 外部细节](#id-1.8、小米语音助手小爱同学调研-4.1.1外部细节)
        *   4.1.2[4.1.2 内部细节](#id-1.8、小米语音助手小爱同学调研-4.1.2内部细节)
    *   4.2[4.2 拆解总结](#id-1.8、小米语音助手小爱同学调研-4.2拆解总结)
*   5[五、个人对于小爱同学的思考。](#id-1.8、小米语音助手小爱同学调研-五、个人对于小爱同学的思考。)

一、产品背景
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

小米公司推出的智能语音助手小爱同学，是一款基于人工智能技术的智能语音助手。它可以通过语音指令实现音乐播放、智能家居控制、日程提醒等多种功能。本文将对小爱同学进行调研分析，探讨其市场表现、用户评价、产品特点等方面。市场表现小爱同学自推出以来受到了很多用户的关注和追捧。目前，小爱同学已拥有超过1.6亿的用户，覆盖了中国大陆、香港、台湾等地区。在智能语音助手市场中，小爱同学已成为竞争对手无法忽视的一员。据小米公司公布的数据，截至2021年4月，小爱同学每天处理的语音指令超过2亿次，市场份额达到了50%以上。

二、产品架构和生态
---------

小米的语音助手小爱同学是一款基于人工智能技术的智能助手，可以通过语音指令来帮助用户完成各种操作。小爱同学的产品架构主要包括以下几个部分：

       1. 语音识别：通过语音识别技术将用户的语音指令转化为文本信息。

1.  语义理解：通过语义理解技术对用户的指令进行分析并提取出关键信息，从而确定用户的意图。
2.  对话管理：通过对话管理技术进行对话交互，帮助用户完成指令。
3.  服务接入：通过接入各种服务，为用户提供各种实用功能

小爱同学的生态接入主要包括以下几个方面：

1.  小米智能家居：小爱同学可以接入小米智能家居，实现家庭生活的智能化控制，如智能开关灯、智能控制空调等。
2.  第三方应用：小爱同学可以接入各种第三方应用，如订餐、打车、购物等。
3.  互联网服务：小爱同学可以接入各种互联网服务，如查询天气、股票、新闻等。
4.  其他智能设备：小爱同学也可以接入其他智能设备，如智能音箱、智能电视等，实现设备之间的联动控制。

三、产品背后的核心技术
-----------

### 3.1 全双工关键技术

![](https://pic2.zhimg.com/80/v2-79b0dd39385e10284fe8500a6b621165_720w.webp)

首先是回声消除，由于小爱音箱在说话的时候会把自己的声音也录音，所以需要消除音箱自己的声音。这部分主要是通过前端声学算法解决，而回声消除也是全双工非常必要的部分。

第二是拒识，小爱音箱会一直开着麦克风，难免录入很多背景噪音，比如周围人的说话声，拒识的功能就是把无效的语音过滤掉。

第三是多轮对话，连续的对话模式，对基于上下文的意图理解有更高的要求，用户可以在多轮交互中让小爱完成更复杂的任务，并允许任务的切换。

第四是节奏控制，用户会以更加自然的方式对话小爱音箱，就会存在着停顿、节奏的变化，这时需要通过判不停更加智能地适应用户的说话节奏。当用户连续发出多条指令时，也需要对每一条指令的回复进行优先级控制。

第五是主动对话，全双工的场景下，不仅是用户问小爱，小爱还可以主动地抛出话题，引导对话。

最后对服务架构也有比较高的挑战，由于小爱音箱会实时连续不断地把语音传上来，对系统的效率有很高的要求，需要有高效的通信协议，同时能支持多模态的输入和异步的处理。

总结一下，全双工交互的实现，涉及到的技术链条相对比较长，从声学、语音到NLP，涉及到算法与架构，需要各个模块的配合，才能达到相对比较好的体验。下面我会对中间的两部分内容：拒识和节奏控制中的语义判不停，分享一下我们在这方面做的一些实践、一些思考，希望能对大家有一些启发。

#### 3.1.1 拒识

拒识功能就是识别出哪些话是同小爱说的，哪些不是同小爱说的。为什么拒识很重要呢？有统计数据表明，在全双工场景下无效人声占比大约在15%~30%之间，这个比例非常高，如果对所有的请求都响应，会对用户产生很大的干扰，导致全双工的可用性非常差。

![](https://pic3.zhimg.com/80/v2-b744d467f2e2520d9e82ee26eb995a8e_720w.webp)

无效音拒识，首先是非人声部分，非人声主要指的是一些背景噪音以及周围环境产生的声音，这一部分目前通过VAD已经能比较成熟地解决。另一部分是不清晰的人声，通过ASR可能识别不出文字或者对文字不是太置信，这时候可以通过ASR拒识。另外，还有很多无效人声需要拒识处理。

![](https://pic2.zhimg.com/80/v2-212c505ad4b96c4fe1e3df628e0dee6d_720w.webp)

拒识具体要解决哪些问题呢？上图给了一些具体的例子：比如周围人的聊天声，需要被拒识；用户在小爱音箱旁，跟周围的人说话，小爱音箱要能识别出来，将其拒识；假设在会议室里其他人在发言，要怎样识别？假设在家里，小孩在朗读课文，怎么识别出来不是同小爱音箱说话？所以这种与小爱没有交互意图的声音需要拒识。还有一类是电子人声，比如在电视旁边放了一个小爱智能音箱，电视里有人说话，小爱音箱如何识别出来？这是我们要解决的问题。

![](https://pic3.zhimg.com/80/v2-0ed08479640c5cf2aa99d5b324db7526_720w.webp)

在拒识方面我们的做法大致可以分为四个阶段：

第一个阶段是场景拒识，对应场景式全双工。这种方案相对来说比较直接，首先我们定义好场景，确定场景下的意图集合，这是一个有限的集合。然后在意图集合中识别出用户意图，如果不在意图集合内的指令就可以不做响应。这种方式对于场景式全双工来说，基本上能达到可用的效果。

然后我们需要做全领域的全双工，这时我们直接想到的是采用策略拒识的方法，策略拒识顾名思义是人工设计的一些策略。制定策略要分析需要拒识的声音有什么样的规律，根据我们能用到的特征设计策略，这种方法在系统冷启动的阶段是比较适合的，因为我们拿不到太多的数据。有足够多的数据的时候，就要向端到端数据建模的方式发展，就有了后续的语义拒识和多模态拒识。

##### 3.1.1.1 **策略拒识**

**![](https://pic1.zhimg.com/80/v2-5e303a7847c7083a4b6c6206a6b8e898_720w.webp)**

关于策略拒识，我们的做法是将策略拒识的架构分为两层，底层是特征提取层，上层是策略层。

**![](https://pic3.zhimg.com/80/v2-3374206c546899a5865b7e38bd5bd192_720w.webp)**

特征提取层通过各种模块提取特征。关于特征，首先是NLU部分，NLU是利用小爱大脑意图识别的能力，给出domain和意图的打分。还有一部分是语言模型，语言模型会给每一个query计算出困惑度，表示一个query合法的程度，然后通过ASR模块，提供一些语音方面的特征，包括用户说话的语速、信噪比，包括音量等，ASR可以对query提供置信度信息，置信度表征的是语音清晰的程度。策略的制定采用启发式，我们人工针对具体的case设计了各种策略，系统里大概有十来种策略，比如根据query是不是无意语义进行拒识、对于超长的query进行拒识、对于一些长尾的闲聊很有可能是周围人在聊天，进行拒识。还会根据用户说话的语速，假设用户在很短的时间内说了很长的话，有可能不是正常地在与小爱对话。

策略拒识的优点首先是比较适合在系统的冷启动阶段使用，比较易于快速迭代。另外一点是可解释性比较强，能针对具体问题，理解背后原因，而且能制定相应的策略进行修正。策略拒识还存在缺点，由于拒识策略的设计是基于一部分特征，而不是综合利用所有特征，也就无法学习特征的组合。

当不同特征的策略有冲突的时候，这种办法就很难处理了

##### 3.1.1.2 语义拒识

![](https://pic1.zhimg.com/80/v2-2f2aa2d705414fff718b0f82c6e0941c_720w.webp)

我们的解决思路是数据建模的方式，基于当前的query和历史的query，建立二分类的模型，通过模型学习各类特征的最佳组合策略。这个思路有一个前提假设，用户“跟小爱说”和“不是跟小爱说”的query在语义空间上是不同的，用模型把两个空间划分出来，这样两个语义空间交集的部分，决定了这个问题能解决的上限。

![](https://pic4.zhimg.com/v2-b718c60d358c4774a8de4b8e1a284fb7_r.jpg)

介绍一下我们的做法，数据方面，人工标注大约26K的训练集，采用的特征，首先策略拒识中用到的一些文本特征，针对query提取表示向量，然后加一些统计特征，比如query的频次、统计特征，从一方面也能反映query的合法性和热门程度。我们还用了上下文特征，对上一轮query的domain打分。

![](https://pic1.zhimg.com/80/v2-119508dc958b317285a3ffb991f43194_720w.webp)

模型采用了BERT二分类，首先通过BERT提取出query和上一轮query的向量表示，通过外部的模块提取出刚才提到的一些可解释的特征，以拼接的方式，接上全连接层和softmax进行分类。

![](https://pic4.zhimg.com/80/v2-60c485b1aec2883ce12b440ea6661cdb_720w.webp)

介绍一下效果，我们使用了1万的测试集，相对于策略拒识，语义拒识的准确率能提升10%，召回率能提升10%。效果是非常明显的，但语义拒识也存在着问题。

首先语义识别比较依赖于文本，如果ASR有错误的话，会产生比较大的干扰。比如一段无意义的人声如果被识别成有头部意图的query的话，很容易干扰拒识的工作。

第二个问题是有些时候我们无法单纯从文本确定是不是在和小爱说话，比如用户对着旁边的孩子说给我背一下《弟子规》。其实小爱音箱收到这条指令的时候，也可以执行。这个case说明“跟小爱说”和“不是跟小爱说”，语义空间是有交叉的，这一部分问题单纯通过语义是解决不了的。

##### 3.1.1.3 多模态拒识

这就引入了我们的下一个方案：多模态的拒识。解决思路是通过DNN从原始的音频信号中提取语音特征的模式，同语义特征联合优化，得到更优的结果。

![](https://pic2.zhimg.com/80/v2-484488dd9a6c311af813c743af5243c5_720w.webp)

这就涉及到语音特征的提取，语音信号如果想在神经网络中处理，需要先进行预处理，输入是一维的声音序列，对应到每个时间点，是信号的强度。通过处理之后，会产生一个二维的M乘N矩阵，M是每一帧能拿到的特征维度，N对应到每一帧是时间维度。

![](https://pic2.zhimg.com/v2-8e7c79786994c3ef81078af3ea7646f1_r.jpg)

语音特征的提取有非常通用的流程，很多开源的工具就可以实现这样的操作。通过一系列的处理，可以提取到各类特征，比如常用的fbank、MFCC。

![](https://pic2.zhimg.com/80/v2-4693074f99f8624fdd617541b4b97e11_720w.webp)

可以利用这些特征做下一步的处理。关于模型的选择，我们对比了很多类模型，这里列出两种，一种是单语音模型，另一种是语音加语义的模型。单语音模型的输入只有用户的语音，语音加语义模型会把用户的语音和ASR取得的文本以及其他的一些语义特征，都输入到模型中去。最终效果，语音加语义的模型效果是要优于单语音模型的。单语音模型效果比之前的语义模型是更优。

![](https://pic3.zhimg.com/v2-7e574b856d4fdb0e69c2b4d99858202a_r.jpg)

我们采用的是语音加语义的模型的结构，也就是我们实验中效果最好的模型的结构。这个结构里最初的输入是语音，然后会有两路处理，一路是语音处理，一路是文本处理。语音处理会经过特征提取模块，得到一些二维的特征矩阵，还会经过语音的encoder，语音encoder可以选择适合处理语音的一些模型，比如CNN、CNN+LSTM，这里我们选用的是CNN+LSTM。语音经过ASR处理之后会得到文本，然后经过文本的encoder，文本的encoder也有很多种选择，我们可以选择比较流行的BERT。语音和文本分别得到表示向量一步融合。这一步融合是根据下层的网络设计确定，可以采用attention的机制，也可以通过门控的机制进行融合。

另外两边是一些高阶特征，包括从声音能提出来的一些比如音量、语速、信噪比，上图右边是通过NLU模块提到的语义的高阶特征，然后把三类特征做拼接，最后综合分类。

经过30K训练集，10K测试集，语音加语义拒识的模型准确率相对于语义拒识提升22%，召回率能提升10%。以上就是关于拒识部分的一些工作。

#### 3.1.2 语义判不停

接下来介绍一下语义判不停的部分。

![](https://pic1.zhimg.com/80/v2-0a0583b6aebed8e79928912731db8f58_720w.webp)

语义判不停要解决的问题是如何更加准确地对用户说话中存在的一些停顿判断句子是否结束。根据小爱的用户日志统计，我们发现大约5%~10%的query是没有说完的，这说明用户的很多请求还没来得及说完，小爱音箱就提前响应了。判断用户说完通用的方案是采用的VAD判停，这是一种声学方案，根据尾部的静音时长，设置一个固定的阈值，比如300毫秒到500毫秒，如果静音时长超过阈值就认为用户的话说完了，但如果用户的停顿超过这个时长就会出现过早判停的问题。针对这个问题的解决方案是在vad判停之后，再从语义的角度判断用户的query是不是完整。如果没有完整的话，继续延长收音时长，让用户话完请求。

![](https://pic3.zhimg.com/80/v2-e193faddd0ba9cd9340ea99ab375a266_720w.webp)

我们采用的方案，处理流程主要分为三步：第一步是规则系统。如果通过规则系统能给出判断的结果，就不会走下一步了。如果规则系统无法确定，就会进行第二步，单轮判别模型。如果单轮判定模型认为用户没说完的话，假设在多轮的场景下，会进行第三步多轮修正，给出最终的结果。

##### 3.1.2.1 规则系统

![](https://pic2.zhimg.com/80/v2-b81a7f385a67ac0639a6ceca09b32ce1_720w.webp)

规则系统主要解决三类query，一类是数量较少相对集中的头部的query，，这一类query通过文本精确匹配的方式能很好地解决。第二类是一些有特定模式的query，可以去做正则的匹配。还有一类是短query，短query用模型相对难处理，我们采用了词性序列匹配的方式进行处理。规则扩充一部分是手动补充，还可以基于用户的session挖掘。如果一个query用户没有说完就被打断了，用户往往会重新再说一遍，这样我们可以计算一个query在历史上被重说的概率，从而拿到很多的候选，然后再做进一步的处理。

##### 3.1.2.2 单轮判别模型

关于模型的部分，模型主要是解决一些中长尾的query，我们先后尝试了两种方法。第一种是基于语言模型的方法，第二种是基于分类模型的方法。

![](https://pic1.zhimg.com/80/v2-620da9c5590618fd929487a277588a4c_720w.webp)

基于语言模型的方法是根据语言模型估计句子说完的概率，这种想法是非常直观的。因为语言模型比较擅长根据句子的前一个词计算出下一个词在词表上的分布。我们在NLP任务中一般会把句尾也当作一个词，这时候我们计算下一个词是句尾的概率，就可以表示一个句子说完的概率。

我们采用的是LSTM模型，模型的训练使用了中文的公开的一些数据集，也加入了小爱的一些query。判不停的条件用到三个：第一个条件是EOS的概率，就是句子下一个词是句尾的概率，这个概率越大，说明句子结束的概率越大。第二个条件是句子的混乱度，它表征了一个句子符合语法的程度，如果一个句子的混合度非常高，我们认为它可能是一些无效的query，这时候就不会做判不停。第三个条件是字数。

![](https://pic3.zhimg.com/80/v2-6c4696341157681e1bfa3817adf43a8a_720w.webp)

相对于规则系统，加LSTM之后，准确率是有所下降的，因为规则系统是人工审核过的一些规则，准确率相对比较高。

加LSTM之后，在召回上大概有6%的提升，不是太大。这种方法存在一个问题：因为语言模型训练是基于非常大量数据的。如果想优化语言模型，周期相对比较长，经过一版优化之后，对于具体任务可能并没有太明显的效果，而且判别时可以用的参数也比较有限。所以说这种方法，比较难针对具体的任务进行特定的优化。

![](https://pic3.zhimg.com/80/v2-cdad80e3ddd19db81d533067a6358992_720w.webp)

所以我们又尝试基于有监督的方式，用到的是BERT的二分类，也是比较容易想到的一种方法。这种方法的优点是利用大规模预训练模型学到的一些知识，针对特定的任务，对模型效果进行优化，所以理论上能达到更好的效果。由于分类模型其实是比较成熟的，对这样一个具体任务的优化，主要还是在数据建设还有数据增强方面。

然后关于数据集的构建，对于判不停任务，我们把不完整的query看作正样本，正样本的比例在实际的query分布中是很低的，所以我们的重点是如何寻找到更多的正样本。可以利用已有的规则系统，语言模型筛选出一批正样本，但是仅用这些的样本是不够的，如果只用这些样本，只能学到系统已有的一些知识，所以还需要在线上随机抽样一批query进行人工标注，这样能增加样本的多样性。模型效果的继续优化，主要是采用数据增强的方式，针对一些错误的case，寻找出一些类似的表达的query，挖掘出更多错误的样本。

![](https://pic2.zhimg.com/80/v2-2abe03ef1b52e8a2c7767af27c39064d_720w.webp)

经过上面的优化，模型的效果已经达到了可用状态。这时候模型需要到线上提供服务，但是BERT模型实际在线服务的延时和QPS，离我们系统的要求是有一些距离的，所以需要继续对性能做优化。

这时我们尝试采用模型蒸馏的方式，训练一个更小的模型，具体的做法是：首先利用训练集训练了一个大的BERT模型，在BERT模型上效果比较好。然后将这个模型作为teacher模型，最终目标是训练一个更小的ALBERT tiny模型，这是一个层数更少更窄的模型，这个模型如果在线上提供服务，性能会非常高。我们通过大的BERT模型对小的ALBERT tiny蒸馏，蒸馏的方法是在训练小模型时，计算Loss的时候，除了包含真实label产生的Loss，还会根据Teacher模型计算出来的logits和Student的模型计算出来的logits，计算蒸馏损失，最后把两种损失做加权求和，得到总的Loss。通过这种方式，最终得到小的模型可以学到BERT大模型的一些知识，在效果没有太明显下降的情况下，性能可以达到系统的要求。所以最终优化后的ALBERT tiny模型，在三个GPU的条件下，P99能在20毫秒以内，QPS能到250左右。

上图是分类模型的效果，规则系统加上ALBERT之后，相对于原有的规则系统，准确率是有些下降的，但是召回率增长了14.8个点，比LSTM要好一些。

##### 3.1.2.3 **多轮判不停**

接下来介绍一下多轮判不停，这是对于一些单轮判不完整的query。基于多轮的情况下，可以完整地表达用户意图，这时不需要判不停。这里列了一个例子：上一轮用户说下载《王者荣耀》，小爱音箱回答确定要下载吗？用户说下载。如果用户首轮说下载，我们往往会认为接下来是要下载某一款软件，比如下载《王者荣耀》，但是在多轮情况下，就是完整的。针对上面这种case，只是对上一轮单轮判不完整的query才会出现，所以处理的流程是针对单轮模型判不停的query，采用多轮模型对结果修正。

如何进行建模呢？如何把上一轮或上几轮的信息，用到单轮模型的分类上呢？

我们是这样思考的。分析这一类case会发现，这种情况的次轮，跟上一轮有一些承接关系，或者是对上一轮小爱音箱反问的回复，或者是在当前轮会省略掉之前的一些槽位。比如用户在上一轮需要定个闹钟，小爱音箱反问定个几点的？用户就说8点的，这时小爱会把上轮意图省略掉。其实这里有着非常明显的承接关系，所以我们可以把这个任务定义成对上下文的承接关系进行建模，就比较自然地想到可以用BERT 句对分类任务去做。我们实际做的时候是把前三轮的query和answer作为上句，当前轮的query作为下句，经过BERT模型做分类。

这种方法经过实践验证，效果确实不错，能够把刚才的那些case相对比较准确地识别出来，提升了系统3个点的准确率，召回率有微弱下降。

四、产品的硬件整体设计
-----------

#### 4.1 小米小爱音箱pro拆解细节

#####  4.1.1 外部细节

![](/download/attachments/97893361/image2023-3-22_15-49-53.png?version=1&modificationDate=1679471394182&api=v2)

![](/download/attachments/97893361/image2023-3-22_15-51-54.png?version=1&modificationDate=1679471514289&api=v2)

包装盒顶部控制区域特写，最外圈是环形的灯带，向里是六个麦克风拾音孔，中间是控制按键：音量加减按键，静音按键，播放暂停按键。

![](/download/attachments/97893361/image2023-3-22_15-52-19.png?version=1&modificationDate=1679471539997&api=v2)

音箱底部有一圈防滑胶条，中间有一个小标签：小米小爱音箱Pro，型号LX06，中国制造，输入12V2A，小米通讯技术有限公司，CMIIT ID 2019AP4423，SN23948/A9TP09157。

![](/download/attachments/97893361/image2023-3-22_15-52-50.png?version=1&modificationDate=1679471570452&api=v2)

音箱背部的接口，上面是AUX IN音频接口，下面是充电接口。

##### 4.1.2 内部细节

![](/download/attachments/97893361/image2023-3-22_15-55-36.png?version=1&modificationDate=1679471736606&api=v2)

主板上有一块屏蔽罩。

![](/download/attachments/97893361/image2023-3-22_15-55-56.png?version=1&modificationDate=1679471756490&api=v2)

内部导线特写，有海绵包裹防止共振噪声。

![](/download/attachments/97893361/image2023-3-22_15-57-0.png?version=1&modificationDate=1679471820946&api=v2)

取下扬声器，扬声器与音腔之间有缓震泡棉。

![](/download/attachments/97893361/image2023-3-22_15-57-26.png?version=1&modificationDate=1679471846625&api=v2)

较大的倒相孔，能够得到更好的低音效果。

#### 4.2 拆解总结

小米小爱音箱Pro的外型沿袭了自小米AI音箱以来的经典圆柱形设计，内部主板和扬声器的安置方式也相近；外壳上的小米Logo为金色，彰显Pro的身份。

硬件配置方面，小米小爱音箱Pro与小米小爱智能音箱相差无几，全频12W的扬声器、 晶晨 A113X 主控芯片、 环形麦克风阵列、双频WiFi、蓝牙网关等都相同。两者目前的差价为30元，我爱音频网认为多花30元购买小米小爱音箱Pro 更划算一些，毕竟它支持红外遥控传统家电，使用起来更方便。

参考链接: [【小米小爱音箱拆解报告】](https://baijiahao.baidu.com/s?id=1660194658392175266&wfr=spider&for=pc)

五、个人对于小爱同学的思考。
--------------

小米音箱的硬件层面有以下优点：1. 音质好：小米音箱采用了2.75英寸全频单元和双长行程低音单元，能够提供清晰、饱满、富有层次感的音质效果。

1.  多功能：小米音箱不仅可以播放音乐，还可以接收语音指令、播报天气、新闻、故事等有用信息，还能控制智能家居设备，实现多种功能。
2.  设计美观：小米音箱外观简洁大方，采用网格纹理设计，具有现代感和科技感。
3.  硬件配置高：小米音箱采用了4核1.4GHz处理器、2GB内存、8GB存储空间等高配置，保证了音箱的高效稳定运行。
4.  价格实惠：小米音箱的价格相对较为实惠，是同类产品中性价比较高的一款产品

小米的语音助手小爱同学值得学习的地方有以下几点：1. 技术创新：小爱同学采用了先进的人工智能技术，如语音识别、自然语言处理、语义理解等，能够为用户提供更智能化和便捷的服务。

1.  生态建设：小爱同学通过与各种智能设备和服务的接入，建立了庞大的智能生态系统，为用户提供了更多的服务和选择。
2.  用户体验：小爱同学通过自然语言交互，提供更友好、更直观的用户体验，能够更好地满足用户的需求。
3.  安全保障：小爱同学注重用户隐私保护和数据安全，采用了多重安全措施，保证了用户的信息安全。
4.  市场营销：小爱同学通过多种渠道和方式进行市场营销，如与小米手机、智能家居等产品的搭配销售，积极参与各种营销活动等，吸引了大量用户并提高了品牌知名度。

[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)

[Configure buttons visibility](/users/tfac-settings.action)