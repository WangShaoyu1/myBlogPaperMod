---
author: "王宇"
title: "4、语音图形界面（VGUI）"
date: 七月31,2023
description: "多模交互设计知识学习"
tags: ["多模交互设计知识学习"]
ShowReadingTime: "12s"
weight: 383
---
*   1[第五章 语音图形界面](#id-4、语音图形界面（VGUI）-第五章语音图形界面)
    *   1.1[5.1 GUI与VUI的融合](#id-4、语音图形界面（VGUI）-5.1GUI与VUI的融合)
    *   1.2[5.2 GUI和VUI融合的三种实现方式——VGUI：](#id-4、语音图形界面（VGUI）-5.2GUI和VUI融合的三种实现方式——VGUI：)
    *   1.3[5.3 VGUI设计原则：](#id-4、语音图形界面（VGUI）-5.3VGUI设计原则：)
    *   1.4[5.4 VGUI核心设计要点](#id-4、语音图形界面（VGUI）-5.4VGUI核心设计要点)

第五章 语音图形界面
==========

5.1 GUI与VUI的融合
--------------

· 融合GUI与VUI的原因：

1.  视觉通道已不能满足日益复杂的人机交互需要。单一的视觉通道会使人的信息感知效率受限，同时在短时间内大量的视觉信息会造成用户视觉通道过载；
2.  我们的视觉系统和听觉系统是相互依存的，视觉提供的是位于前方的具有丰富细节信息的图像，而听觉提供的则是环绕我们四周的信息。听觉通道的特征可以弥补视觉通道的不足，并且降低视觉通道的负载；
3.  人机交互逐渐从二维平面转向三维空间，包括VR、AR、智能座舱和跨设备交互，语音交互是最好的隔空交互方式之一。

· GUI在前期被研究人员定义为以窗口（Windows）、图标（Icons）、菜单（Menu）和指示装置（Pointing Devices）为基础的图形用户界面，也称为WIMP界面。常见的GUI操作系统如Windows、OS X、Linux、iOS和Android都属于WIMP界面。

*   在WIMP界面里，每个窗口都是一个独立的执行程序，也是执行程序的可视范围。当多个窗口同事出现在桌面（Desktop）上时，用户可以对它们进行交叠和并排的操作。
*   每个图标都能激活一个窗口，不同的图标表示不同含义，例如文件、文件夹、快捷方式、应用或设备。
*   菜单时可选命令或选项的一个列表。
*   指示装置是指操作界面的设备，鼠标是使用最普遍的，在触摸屏上手指和手写笔也是一种指示装置。

· GUI的特点：

1.  通过焦点，对看到的界面元素进行直接操作。通过光标（cursor），用户可以对界面里的任何操作对象进行点击、长按、拖拽等操作，这种交互方式被称为“可见即可点”。——GUI的缺点：如果没有焦点的确认，GUI不知道用户在操作哪个对象。
2.  信息的展示和交互由屏幕和GUI元素决定。如果没有用鼠标或用手指触控的方式使界面产生滚动或切换，就可以认为屏幕上的内容是固定的，超出屏幕的信息都是不可见的。——GUI的缺点：在桌面和窗口中，看不到的内容无法被用户阅读和操作。
3.  GUI交互流程是固定的。交互流程由信息架构决定，每个应用的信息架构都是固定的。——GUI的缺点：不能随时切换流程和路径，只能通过实体/虚拟按键或以手势的方式回到特定路径上。
4.  信息会随着不同的排版和布局发生变化。在GUI的布局设计中，设计师普遍遵循了格式塔原理。
5.  支持多任务切换。一个窗口代表一项任务，用户可以通过焦点切换告诉操作系统现在哪个窗口正在被用户使用。多任务切换体现出GUI的高效率和便捷性。

· VUI的特点：（详细的优势和不足见第三章）

1.  VUI的交互手段由词组和语法决定。VUI没有控件、组件、页面等界面元素的说法。VUI的操作对象不是主语就是宾语，但用户说话时不一定会把它们全说出来（因为是眼睛看到的、脑海里出现的、上下文提及到的，说话时容易被忽略），**缺乏主语/宾语或代词指定不明对于VUI来说是一种挑战**。
2.  VUI是“所想即所说”。与GUI的交互对象仅是当前页面里的元素不同，VUI的交互对象可以是任何事物（眼睛看到的、脑海里出现的、上下文提及到的）。
3.  VUI一句话等于一项或多项操作。体现VUI的高效率，一般来说GUI完成一项任务需要分几个步骤，而VUI只需要一句话就可以搞定：“帮我订一张明天8点飞往北京的机票”。
4.  VUI交互流程是可变化的。VUI在流程上没有可视化的分支结构，更没有返回逻辑，在多轮对话里只能一直往前推进。GUI的信息架构是固定的，但是VUI的信息架构是需要变化的，用户的发散性思维导致用户的行为可能很随意，会随时打断当前任务跳到其他流程上。
5.  VUI不适合用于复杂任务。VUI没有界面和文字引导，加上用户工作记忆的限制，导致用户接受的信息是有限的，过长的对话会影响用户对内容的理解和判断。
6.  VUI的交互方式由剧本决定。对用户而言，说话的内容和风格都会影响用户对智能语音助手性格的认知，所以编写剧本需要考虑场景是什么样的，提前定义好语音助手的性格特征，以及怎样和用户对话。
7.  VUI可以影响用户情感。声音能够影响用户的情感。

· GUI与VUI融合时会遇到的问题：（部分问题目前已经找到较好的解决方法，见后）

1.  信息输出效率不一样。融合需要考虑用户的注意力分配问题，当用户的注意力集中在某一个通道时，其他通道获取信息的效率会迅速下降。
2.  操作对象不一样。GUI的操作对象是获取焦点的界面元素，VUI的操作对象时主语或宾语，二者并不一定有关联，要考虑属性打通的问题。GUI中的Button可以有Default、Hover、Focus、Active和Disable多种状态属性；而VUI的指令中并没有基础属性这一说法，并不管Button属于什么状态，只管指令是否被顺利执行。要实现通过语音交互来操作界面里的元素，就要根据元素的不同特点赋予它们更多的业务属性和状态属性。
3.  表达方式不一样。GUI通过文本、图片等和布局结构来表达，VUI通过语音来表达。在VUI与GUI耦合时会遇到一些歧义的地方：在GUI中，返回到上一个界面可以通过“返回”按钮或其他意思相近的图标来表达，在VUI中，“返回”“上一页”指令也可以回到上一个界面，但“上一页”在返回和翻页中是不一样的含义，因此在融合时需要把带有歧义的指令做好容错设计。
4.  交互流程不一样。GUI是结构化的，VUI的交互流程是随时可变的。VUI因为与GUI融合拥有了返回逻辑，而GUI的界面逻辑需要考虑VUI可变化的交互流程来简化自己的界面。
5.  两种交互方式融合会带来互斥问题。两种互斥现象：（1）操作互斥：在VUI剧本中，GUI操作可能会影响VUI剧本，比如GUI支持多任务切换，而VUI是没有多任务并行这一概念的。（2）反馈互斥：VUI在同一时间只能播放一条信息，在VUI播报时，如果GUI的反馈涉及VUI的播报，则新的内容要么截断当前播报，要么等待当前播报内容结束，这两种方式都会对用户体验产生影响。
6.  两种交互方式融合会带来时序问题。多个模态融合时，如何处理模态间的先后顺序是设计多模交互最核心的问题。绝大部分的语音交互识别和理解都是在云端进行，而GUI绝大部分的操作都是在客户端完成的，客户端和云端数据传输产生的时差会直接影响多模交互的先后顺序。如果一项操作由于时差问题导致其相应和反馈晚于它的下一个操作，则整个交互流程就有可能出现重大问题。

5.2 GUI和VUI融合的三种实现方式——VGUI：
---------------------------

1. 应用级语音交互：在语音交互过程中，系统会调出一个语音应用遮盖当前界面，用户只能对语音应用进行操作或退出语音应用。**从技术实现的角度看，模态之间的相互转换要求所有的输入和输出系统必须完全理解用户的所有状态和行为，这需要在系统底层提前定义好各种规则。**然而基于图形界面的操作系统比语音交互系统成熟数十年，语音交互已经无法在拥有几千万行甚至上亿行代码的图形操作系统上深度嵌入自己的代码且不出错。应用级语音交互的特点如下：

*   应用级语音交互会脱离当前应用和场景。
*   应用级语音交互由剧本决定交互路径。（不依赖于ios和Android，也不依赖图形界面，能够独立工作）
*   应用级语音交互以听觉通道为主，弱化图像用户界面的信息。（带屏智能音箱的GUI：放大字号，简化界面的排版布局）

2. 可见即可说：在界面上看到什么元素，只要说出它的名字，系统就会通过模拟点击的方式操作该元素。**可见即可说只需要语音识别和正则表达式匹配就能实现对界面元素的模拟操作**，只能让用户看着界面的交互组件一句句说出来，而不能让用户一句话把一项任务做完，算不上真正的VGUI融合。可见即可说的特点如下：

*   可见即可说用视觉通道接受信息，用语音的方式输出信息。
*   可见即可说可以在任意界面上使用。
*   可见即可说不支持复杂的意图识别。（不需要复杂的自然语言理解技术就能实现，yincident不支持交互剧本、意图识别、业务逻辑理解等功能）

3. 系统级语音交互：可以理解为应用级语音交互和可见即可说的结合体，解决了所有数据和任务都集成在一个应用里的问题。以系统级语音交互为代表的多模融合需要重构系统框架且有强大的技术支撑才能被实现，实际应用中，在手机和PC上没有太大的实质性作用（仅有少数：Google的Duplex on the Web和iOS14的Siri），真正发挥作用的领域是汽车、AR、VR和跨设备交互。系统级语音交互的能力如下：

*   系统级语音交互属于GUI操作系统的一部分，拥有连续对话的能力，可以随时随地操控GUI上的界面元素。
*   系统级语音交互不会脱离应用和场景单独使用，它的交互流程由剧本和界面元素决定。
*   系统级语音交互拥有意图识别和业务逻辑理解能力，系统可以理解用户的意图，也可以依据特定场景主动发起语音交互。
*   系统级语音交互具有信息汇集和理解的能力，是信息的中枢但服务于系统和各个应用。
*   系统级语音交互能突破界面的限制，可以随时随地跳转到任意应用和界面上。

· VGUI的特点：

*   多通道结合使用可以提升工作效率。以Siri为例，用户通过语音启动任务后，随后的步骤允许用户通过触摸屏进行交互。
*   显示对话内容有利于用户记忆和理解对话内容。通过对话流即对话用户界面（Conversation UI）的方式显示完整的上下文。
*   结合视觉通道输出信息可以减少语音播报唠叨。如查询未来一周的天气预报。
*   VUI可以随时随地操控GUI上的界面元素。
*   VGUI依赖连续对话的能力。

· 应用级语音交互与可见即可说的区别：（1）应用级语音交互是一个独立的VUI操作系统，而可见即可说是GUI操作系统的辅助手段之一；（2）应用级语音交互不依赖连续对话的能力，可见即可说若仅靠唤醒词和单论对话，则体验较差。

5.3 VGUI设计原则：
-------------

· VGUI重要的不是界面设计，而是用户的交互行为和目的。针对上述提到的融合带来的问题，以下设计原则可以帮助解决：

1.  **交互是一种行为，它具有目的性**。这句话是整个VGUI融合的核心，用户在意的是系统和应用能不能帮助他们达成目的，GUI的控件和页面、VUI的剧本都是辅助用户完成他们目的的手段，因此重要的是用户的交互行为和目的。
2.  **每种交互方式都能持续工作**。当前的语音交互在每次使用时都需要唤醒语音识别能力。VGUI融合的前提是系统/应用拥有全双工语音交互的能力，能持续一段时间倾听用户所说的话，为了避免泄露隐私和噪声影响，可以在一段时间内用户不说话后主动退出。
3.  **每种交互方式统一以GUI为参照对象**。  
    原因有：（1）视觉通道接收的信息占所有感官接收信息的83%；（2）GUI显示的内容可以维持静止状态（VUI不行）；（3）GUI有丰富、成熟的控件和组件，可以跟各种交互方式进行绑定。  
    以GUI为参照对象不代表各种交互模态只能与当前界面交互，也可以跟“不可见”的界面和功能进行交互。但要切记，在GUI中不能打断交互任务和事件，其他交互方式同样不能被打断，比如在GUI中有一些最高层级的弹窗用于安全警示、重要内容确认，用户只有在当前界面完成任务后才能回到主页面，这时其他交互方式也应该相应收敛意图识别范围，让用户只聚焦于当前任务。
4.  **每种交互方式相互融合，取长补短**。相互配合的前提是互不干扰。  
    VUI的缺点在于：（1）交互状态不明显；（2）受限于工作记忆。因此VUI的交互流程中可以配合GUI或其他LED灯光效果强化VUI状态显示；语音播报的内容、句式和语法结构必须简单（内容播报尽量控制在10s内，中文和数字约40字以内），如果GUI内容支持语音播报，那播报应该与显示的文本一致，且GUI上显示当前的播报进度。  
    GUI的缺点在于：需要用户看着屏幕才能正常交互，美国国家公路交通安全管理局（NHTSA）提到车载系统的GUI设计尽量能让司机在行驶过程中快速完成任务，但在引入车联网和辅助驾驶相关技术（VUI）后，新型车载系统的功能又逐渐丰富起来。为了弥补GUI的缺点和提升驾驶场景中用户和系统的交换全，GUI与VUI可以这样融合：

*   VUI可以操控GUI的界面和功能，尤其文本输入功能；
*   GUI显示的文本内容允许VUI播报相关内容；
*   由VUI播报完整信息，GUI通过排版显示重点信息；——利用了听觉和视觉通道各自接收信息的总量和时间差，最先通过听觉获取信息，如果用户觉得信息重要就会瞥几眼屏幕，这时排版突出重点信息可以提升整个接收效率。
*   基于VUI的声纹识别能直接省略用户在GUI中输入密码的交互步骤。、

当用户没有注视着操作对象发起语音交互时，需要用户说出操作对象的完整名称及语音播报完整的反馈是没有问题的；但如果用户盯着操作对象，就知道反馈结果是什么，这时还进行语音播报反而“鸡肋”。可以通过简短的音效来替代VUI操作GUI时的语音反馈，不仅能减少对用户的干扰，还能让用户形成听觉记忆。

5\. **以用户当前操作对象为目标发起交互流程**。考虑操作对象切换的问题。VGUI融合的关键是将VUI意图中的主语或宾语和GUI里的控件、组件或容器进行绑定，并且以GUI为参照对象，让操作对象显性化，系统通过操作对象的对照就能知道VUI与GUI的操作对象是否一致。当用户通过不同的交互通道处理操作对象时，无论是操作同一个对象、不同对象、操作对象与其他对象联动，都需要做到同步更新各自的交互流程和相应数据，并在VUI和GUI中体现出来。  
6\. **明确告诉用户当前的交互流程到哪里了**。每种交互方式都具备“选中目标”“执行过程”“结果反馈”三种属性。“选中目标”让用户和系统知道当前的操作对象；“执行过程”让用户知道当前的交互进度；“结果反馈”需要考虑“成功执行”与“失败执行”两种情况，“失败执行”又包括“业务支持失败”和“听不懂”。  
7\. **GUI控件/组件应支持多种交互方式，如有差异，建议增加说明**。在多模交互下，不同类型的操作控件/组件应有不同的VUI意图和流程来支持，比如在按钮图标上增加文字、链接前增加数字等，若无法修改设计方案，则需要通过其他方式告诉用户暂不支持其他通道的交互操作（只能触屏）。  
8\. **由交互管理器统一管理多种交互方式之间的操作和状态，包括容错管理、意图/界面切换**。由于多通道之间的信息输入和输出存在不同效率、同步/异步及兼容/互斥的差异，因此构建交互管理器有助于管理多模态交互之间的状态，同时也有利于管理第5点，监控不同操作对象及交互通道产生操作数据时的先后顺序，并将这些信息同步给所有的交互通道。

· 重构GUI操作：GUI通过文案、图形和结构表示信息。在VGUI中，操作型控件的文案设计会受到限制：

*   文案符合“可见即可说”的原则。“可见即可说”包括用户看得懂+用户朗读顺畅。
*   文案中尽量不要出现汉字、数字、标点和大小写字母的混合。识别多语言和数字混合是一个很大的挑战，会影响ASR识别的准确率（比如“1”“e”“衣”）；标点和大小写字母是辅助文字记录语言的符号，是书面语的组成部分，在说话时并不会出现。但不可避免的是，在WiFi、蓝牙和地图列表中一定会出现多种符号的混合，建议在列表前增加数字作为标识，用户只用说“第几个”就可以了。同时，也不建议在多符号混合的密码输入框中增加语音输入的功能。
*   文案之间避免过于相似，文案长度尽量控制为2-6个字符。文案越长，文案相似的可能性就越小；但用户朗读时就越浪费用户的注意力。每个控件的文案尽量控制为2-6个字符，既能涵盖大部分功能需要表达的信息，又能保证语音指令命中的准确率，朗读时间在1.5秒以内，保证VUI指令的高效性。
*   文案结构简单。从VUI指令的角度来看，指令要符合“动宾短语”和“把XX设置为YY”两种结构，因此GUI文案可以围绕这两种结构进行设计。在GUI中，绝大部分的图标代表一个名词，而VUI指令更多的是“动词+名词”的结构，用户看得懂图标不代表能立刻说出图标的意思，或者用户的理解与设计师想表达的含义不一致。因此建议，在VGUI中能不用图标表示的功能就尽量不用，如果真要用，可以在图标底部增加文字信息。

以“打开/关闭蓝牙”为例，在设计GUI时有三种常用方法：①在按钮上显示“关闭蓝牙”，点击按钮后文案变为“打开蓝牙”；②通过带有“蓝牙”文案的标签和开关两种控件来表示；③在按钮上显示“蓝牙”，然后通过按钮点击状态/不可点击状态来标识蓝牙是否被开启。对三种方式进行用户测试，结果表明，只要操作简单明了，不一定要将动词放到GUI文案中。

· GUI组件和容器的文案设计：在设计组件时，组件内部结构设计要符合格式塔原理，关键内容尽量保持在12个字以内（朗读时间3秒左右）。容器用来承载不同的控件和组件，本身意义不大，设计时要站在用户角度考虑用户需要什么。

*   列表（list）和选项（item）容器的设计，可以在列表前增加数字作为标识，方便用户通过指令操作；同时，建议每个选项最好只有一个操作。
*   菜单（menu）、微调框（spinner）这类控件，在VGUI里并不适用，如果一定要使用，则需要重新构造结构：建议绑定一个固定标签来提示用户该怎么说。
*   消息框（toast）在VGUI里适合使用声音进行反馈。
*   文本框（text fields）时用户输入内容的控件，在VGUI中，推荐将语音输入的功能融入到输入法应用中，方便用户通过输入法的功能编辑文字。需要注意，在语音输入时是不支持空格、换行、选中、删除和退出等文本编辑操作的。搜索框是文本框的一种延伸，除了基本的功能外，还可以通过指令“搜索XXX”让用户直接发起搜索。
*   选择器（pickers）一般包含两个以上选项，比如时间选择器和日期选择器。在VGUI中，很难直接通过指令对选择器进行操作，建议通过意图分析识别用户的整句话，然后通过技术手段将每个数值解析出来同步给GUI。同理，电话拨号键盘也是如此处理。

![](/download/attachments/105272062/image2023-7-31_17-43-28.png?version=1&modificationDate=1690796608593&api=v2)![](/download/thumbnails/105272062/image2023-7-31_17-43-16.png?version=1&modificationDate=1690796596744&api=v2)

  

· GUI页面设计：有些指令可以直接跳转到任意一个页面，**页面的命名方式很重要**。不要给页面命名一些让用户说出来感到疑惑的名字（比如“打开微信‘我’”）；另外，有些命名方式应该支持多元化的表达（比如“钱包”在粤语里被叫做“银包”）。

5.4 VGUI核心设计要点
--------------

· LMK（Low Memory Killer），操作系统中的一种程序，当系统处于低内存状态时，LMK会释放那些不太重要进程的内存，让系统运行更加流畅，目的是避免内存被某个应用滥用，导致系统卡顿，甚至崩溃。

· 用户完成一件事是目的，中间的步骤都是行为。语音交互指令需要分为全局指令和局部指令，行为是局部指令，而目的是全局指令。全局指令是指它能在系统内全范围执行，不会被内存管理取消；局部指令是指仅对当前仍在内存里的界面元素和交互任务负责，还有的指令是需要和上下文有关，当脱离上下文就会直接变成没有指定对象的操作，也属于局部指令。

· MVC框架：Model View Controller，模型-视图-控制器，是软件设计中常用的设计模式。模型用于封装与应用程序的业务逻辑相关的数据以及对数据的处理方法；视图能够实现数据有目的的显示；控制器起到不同层面间的组织作用，用于控制应用程序的流程，处理事件并作出反应。

· 局部指令可以理解为基于视图的行为，而全局指令可以理解为基于控制器、模型的行为和目的。

· VUI全局展示区域：浮层形式，能够在任何GUI界面响应，且不能遮住GUI的重要区域。这时VUI全局展示区域与当前的GUI界面之间的关系，有两种情况：  
（1）用语音交互的方式替代当前的触控交互，该替代方法不会对任务及界面产生影响；  
（2）在当前任务下想通过语音交互的方式发起另外一项任务，这时系统存在两个任务，它们的关系要么是共存的（两个任务同时显示在界面里），要么是互斥的（旧任务界面切换到新任务界面）。

![](/download/attachments/105272062/image2023-7-31_17-43-57.png?version=1&modificationDate=1690796637984&api=v2)

· VUI全局展示区域内展示的内容一定是全局指令的内容。同时，有些全局指令的数据来源于云端（如闲聊、百科等），这些在客户端没有响应的应用作为载体，VUI全局展示区域则为这些全局指令提供了展示载体。

· 全局指令和局部指令的声音反馈是不一样的：对于全局指令来说，该指令有可能是在任何场景下发出的，包括用户不看界面的时候，这时完整的语音反馈对于用户来说非常重要；但是对于局部指令来说，用户肯定是看着当前界面发出指令的，可以用简短的音效来代替局部指令的语音反馈，有效降低对用户的干扰。——重点在于用户是否在看着屏幕，后续如果能通过视线追踪识别用户是否在看屏幕，语音反馈就可以做出动态调整，从而提高用户体验。

· 界面是否能跳转需要考虑很多细节：

![](/download/attachments/105272062/image2023-7-31_17-44-24.png?version=1&modificationDate=1690796664145&api=v2)

· 在VGUI中，VUI和GUI融合后的控件或组件包含以下属性，VGUI里用{}的方式定义每个最小的交互模块，具体是将以上属性跟控件绑定在一起，还是跟视图（view）绑定在一起，可以由开发者自行定义。这样能够降低GUI和VUI在开发上的耦合度，同时降低对开发者重构代码的要求

![](/download/attachments/105272062/image2023-7-31_16-59-43.png?version=1&modificationDate=1690793983533&api=v2)

1.  名字：每个独立可用的控件或组件的属性列表里都需要有“name”这个属性
2.  执行范围：只允许在当前界面执行，说明是局部指令；允许在其他界面执行，说明是全局指令
3.  控件状态和当前状态：最小交互模块内部可能是由不同控件和组件混合而成，要将最小交互模块包含的状态和属性定义清楚，尤其是当前状态
4.  区域内多模交互响应容错：当控件/组件互斥时，交互事件以客户端最后一次操作的事件为准。多个模态之间的合作在时间上可以分为同步合作和异步合作，同步合作是指多个模态同时工作；异步合作是指多个模态在前后合作。在同一个交互对象上进行多通道交互，要以客户端最后一次操作的事件为准，因为服务端下发指令的事件不能代表用户操作的时间——举一个极端的例子：当前出现一个弹窗，弹窗内有一个开关控件，用户用语音控制开关“打开”，但由于网络原因指令迟迟不下发，这时用户点了弹窗的“关闭”按钮，然后语音指令下发了。这时作者建议弹窗内的那个开关仍然保持“关闭”状态，因为从用户视角来看，他知道刚刚的操作没有正常执行，确认开关仍处于“关闭”状态才关闭的弹窗【有没有可能用户并没有确认刚刚的操作有没有正确执行，只是觉得自己已经说了这个指令，然后就关闭弹窗了，可能用户默认刚才的指令已经正确执行了？】——有两种解决办法：第一种是当上一个指令没有执行前，阻塞其他交互事件，但这样的方法不太可取；第二种是将迟来的指令继续执行，但同样会导致用户不理解。因此建议：如果云端返回的指令延迟超过5秒，该指令就可以直接被屏蔽掉，并语音回复“当前网络较差，请稍后再试”
5.  允许交互/不可交互：Enable/Disabale状态。在用VUI控制GUI时，用户可能隔着一米的距离跟交互界面交互，这些轻微的视觉变化对于用户来说并不明显，所以建议在用VUI控制GUI时，根据当前交互状态提供更显性的动画效果
6.  成功执行VUI响应事件/执行失败VUI响应事件：将执行失败的原因告诉用户
7.  跳转事件/当前界面执行：**界面转场动画效果较明显，在这个条件下可以不需要通过VUI进行反馈，或者适当加入音效**

![](/download/attachments/105272062/image2023-7-31_17-44-37.png?version=1&modificationDate=1690796677261&api=v2)

  
  
![](/download/attachments/105272062/image2023-7-31_17-44-52.png?version=1&modificationDate=1690796692969&api=v2)![](/download/attachments/105272062/image2023-7-31_17-45-5.png?version=1&modificationDate=1690796705992&api=v2)

![](/download/attachments/105272062/image2023-7-31_17-45-31.png?version=1&modificationDate=1690796731474&api=v2)![](/download/attachments/105272062/image2023-7-31_17-45-43.png?version=1&modificationDate=1690796744117&api=v2)

![](/download/attachments/105272062/image2023-7-31_17-45-58.png?version=1&modificationDate=1690796758813&api=v2)

· 触控手势也可以与语音指令进行绑定，以下是常用的触控手势：

*   跟页面滑动相关的手势：

*   “向上滑”“向下滑”——页面内容滑动30%（举例）；
*   “向下翻页”“向上翻页”——页面内容滑动90%（举例）；
*   “回到顶部”——返回列表顶端

*   跟图片、地图相关的手势：

*   “放大到最大”“缩小到最小”；
*   “放大一点”“缩小一点”——缩放20%（举例）；
*   “往上/下/左/右移动”——移动20%（举例）；
*   地图：“放大/缩小到X米”——X可以是10、20、100等

  

  

[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)

[Configure buttons visibility](/users/tfac-settings.action)