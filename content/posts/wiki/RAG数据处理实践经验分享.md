---
author: "王宇"
title: "RAG数据处理实践经验分享"
date: 六月27,2024
description: "知识插件"
tags: ["知识插件"]
ShowReadingTime: "12s"
weight: 704
---
*   1[1\. RAG数据处理的目标](#RAG数据处理实践经验分享-RAG数据处理的目标)
*   2[2\. 数据收集](#RAG数据处理实践经验分享-数据收集)
    *   2.1[2.1. 数据收集领域判断](#RAG数据处理实践经验分享-数据收集领域判断)
        *   2.1.1[2.1.1. 确定领域知识体系](#RAG数据处理实践经验分享-确定领域知识体系)
        *   2.1.2[2.1.2. 确定知识来源](#RAG数据处理实践经验分享-确定知识来源)
    *   2.2[2.2. 收集数据](#RAG数据处理实践经验分享-收集数据)
*   3[3\. 数据处理](#RAG数据处理实践经验分享-数据处理)
    *   3.1[3.1. 标题标注](#RAG数据处理实践经验分享-标题标注)
        *   3.1.1[3.1.1. 程序识别](#RAG数据处理实践经验分享-程序识别)
        *   3.1.2[3.1.2. 人工审核](#RAG数据处理实践经验分享-人工审核)
        *   3.1.3[3.1.3. 通配符标注](#RAG数据处理实践经验分享-通配符标注)
        *   3.1.4[3.1.4. 其他情况](#RAG数据处理实践经验分享-其他情况)
    *   3.2[3.2. 文本清洗](#RAG数据处理实践经验分享-文本清洗)
        *   3.2.1[3.2.1. 目录、练习题、致谢、参考文献等大块文本清除](#RAG数据处理实践经验分享-目录、练习题、致谢、参考文献等大块文本清除)
        *   3.2.2[3.2.2. 页尾页码删除](#RAG数据处理实践经验分享-页尾页码删除)
        *   3.2.3[3.2.3. 引用、续表等特定文本删除](#RAG数据处理实践经验分享-引用、续表等特定文本删除)
    *   3.3[3.3. 表格清洗](#RAG数据处理实践经验分享-表格清洗)
        *   3.3.1[3.3.1. 表格转换](#RAG数据处理实践经验分享-表格转换)
        *   3.3.2[3.3.2. 表格进一步清洗](#RAG数据处理实践经验分享-表格进一步清洗)
        *   3.3.3[3.3.3. 表引用删除](#RAG数据处理实践经验分享-表引用删除)
    *   3.4[3.4. 图片清洗](#RAG数据处理实践经验分享-图片清洗)
        *   3.4.1[3.4.1. 图片内容识别为文本](#RAG数据处理实践经验分享-图片内容识别为文本)
        *   3.4.2[3.4.2. 图片引用](#RAG数据处理实践经验分享-图片引用)
    *   3.5[3.5. 公式清洗](#RAG数据处理实践经验分享-公式清洗)
        *   3.5.1[3.5.1. 图片转latex](#RAG数据处理实践经验分享-图片转latex)

1\. RAG数据处理的目标
==============

RAG数据处理的目标是为大模型提供优质的、干净的、精简的可参考数据。

**理想数据：**

1.  优质：找到唯一的、最全、最新、全先进的对应领域知识。
2.  干净：要清除无关数据。文本读起来逻辑通顺、无废字、无无用的符号。满足“未来第三人原则”。
3.  精简：最好是陈述句，直接描述结论和论据。无过多无用的语气词。

实际操作中，优质和干净是尽量满足。精简一般书籍都做的比较好。

2\. 数据收集
========

2.1. 数据收集领域判断
-------------

找到优质的领域知识的第一步是确定数据收集的范围和目标。从知识“唯一性”的优质数据目标出发，我们可以以这样一个策略执行：**先确定领域知识的知识体系，然后从体系出发找到每一个分支，最新最权威的数据源**。

以养猪业为例，养猪领域的知识是很大的，同时描述猪的知识也肯定有很多本书。我们要找到哪些知识？到底要哪些书？从“全国图书馆参考联盟”网检索“家畜育种学”，就能找到60本左右的书籍。毫无疑问，我们无需对这60本全部收集和清洗。我们只需要选择一本最合适的书籍。

### 2.1.1. 确定领域知识体系

确定领域知识体系，可以让我们避免知识的缺漏。同时根据知识体系，可以引导我们去寻找更针对性的书籍。要找到优质的领域知识，可以从大学专业的培养计划、专业证书的考试范围等，找到一个知识尽量互相不重合、全面的领域知识体系。

![](/download/attachments/129175181/image2024-6-27_9-38-59.png?version=1&modificationDate=1719452339206&api=v2)

### 2.1.2. 确定知识来源

从知识结构的每个分支里，找到尽量新的、权威的、被认可的书籍或者网站数据。

1.  找知名厉害的学校采购的教材
2.  专业机构指定的教材
3.  尽量找到最新版本

![](/download/attachments/129175181/image2024-6-27_9-39-50.png?version=1&modificationDate=1719452390241&api=v2)![](/download/attachments/129175181/image2024-6-27_9-43-52.png?version=1&modificationDate=1719452632701&api=v2)

2.2. 收集数据
---------

以下是一部分常用的数据来源

1.  **商业服务**
    1.  **淘宝可定制的pdf书商（淘宝目前只发现有一家店具备定制能力）**
2.  培训机构
    1.  兽医培训机构
    2.  营养师培训机构
3.  学校
    1.  校内二手交易群
    2.  校内悬赏群
4.  网上公开的图书馆
    1.  [libgenesis.net](https://libgenesis.net/)
    2.  [libgenesis.net (z-library.se)](https://zh.z-library.se/)
5.  网站
    1.  兽医类官网
    2.  注册营养师官网

  

3\. 数据处理
========

数据处理的目标主要是干净。实际操作上涉及以下的内容

1.  标题标注
2.  文本清洗
3.  表格清洗
4.  图片清洗
5.  公式清洗

目前能找到的书籍，几乎是PDF版。需要先将PDF转换成word，才能进行进一步数据处理，这一步使用的技术是OCR。经过试用和对比WPS、Paddlepaddle的OCR方案，结果是WPS的识别效果是最好的。但是即使是最好WPS，识别出来文档依旧有很多的问题。例如：

1.  识别不准问题：
    1.  图片中的符号被识别为文本
    2.  表格识别不完整
    3.  文本顺序错误
    4.  。。。
2.  OCR是无法识别标题，需要去重新标注一遍

只能说，打开word看起来是好的，实际是比较乱的。

同时为了进一步实现数据处理的目标，下面会介绍不同情况的处理经验办法。

![](/download/thumbnails/129175181/image2024-6-27_11-3-33.png?version=1&modificationDate=1719457413978&api=v2)![](/download/attachments/129175181/image2024-6-27_11-6-17.png?version=1&modificationDate=1719457577865&api=v2)![](/download/thumbnails/129175181/image2024-6-27_11-6-59.png?version=1&modificationDate=1719457619844&api=v2)

3.1. 标题标注
---------

OCR识别的PDF无法直接识别并标注标题。然而标题对于RAG文本块的切片具有重要的参考意义的，影响的是切片片段文本的关联性、逻辑性，最终影响的是大模型的回复效果。

但是标题可以通过几种方式，结合起来快速标注。

1.  标题一般是有一定规律的文本。可以识别具备这种规律的文本为标题。例如1.1 第一章 第一节 一、xxx 等
2.  无法被程序识别的标题文本。只能手动标注。但是可以借助word的快捷键，提高效率。
3.  使用word通配符标注标题

![](/download/attachments/129175181/image2024-6-27_11-40-0.png?version=1&modificationDate=1719459600862&api=v2)

### 3.1.1. 程序识别

首先程序识别标题，然后人工筛选，并设置标题层级。程序判断的大致逻辑，如上述。由github上的项目借鉴来的算法，加上我们的改造。虽无法做到100%准确，但是基本做到98%识别。基于识别的结果，在excel中，可以快速定位标题，并判断和设置层级关系。

![](/download/thumbnails/129175181/image2024-6-27_13-50-21.png?version=1&modificationDate=1719467421714&api=v2)![](/download/thumbnails/129175181/image2024-6-27_13-51-52.png?version=1&modificationDate=1719467512980&api=v2)

### 3.1.2. 人工审核

由于算法和人的失误，会造成部分的标题没有标注。但是在算法识别的基础上，人很容易识别剩余未标注的标题，补全完整。另，word可对样式设置快捷键。

![](/download/attachments/129175181/image2024-6-27_13-53-35.png?version=1&modificationDate=1719467616057&api=v2)![](/download/thumbnails/129175181/image2024-6-27_13-56-11.png?version=1&modificationDate=1719467771628&api=v2)

### 3.1.3. 通配符标注

部分单纯文字的但是有规律的标题。编写的算法没有识别。可以通过word提供的查找替换功能，定位标题并标注。

![](/download/thumbnails/129175181/image2024-6-27_14-7-50.png?version=1&modificationDate=1719468470920&api=v2)

### 3.1.4. 其他情况

其他情况一般很少，先手动标注。

  

3.2. 文本清洗
---------

一本书籍中，除了有用的正文，剩下的几本都是无用的内容。例如目录、练习题、参考文献、致谢、页尾、页码、引用、续表等等。保留这些信息，会让知识库充斥一部分的垃圾数据。影响最终大模型回复效果。

### 3.2.1. 目录、练习题、致谢、参考文献等大块文本清除

针对大块的文本。一般目录、练习题、参考文献等，这些都有特定的标题和内容。目前比较能防止误删，并且比较快速的方法，是在标题正确标注的基础上，通过识别目录、练习题、参考文献等特定文字，判断当前文本，是否处理这些区域，从而判断当前文字是否需要删除。

![](/download/thumbnails/129175181/image2024-6-27_11-46-55.png?version=1&modificationDate=1719460015706&api=v2)![](/download/thumbnails/129175181/image2024-6-27_11-47-9.png?version=1&modificationDate=1719460029669&api=v2)![](/download/thumbnails/129175181/image2024-6-27_11-47-24.png?version=1&modificationDate=1719460044211&api=v2)![](/download/thumbnails/129175181/image2024-6-27_14-19-37.png?version=1&modificationDate=1719469177532&api=v2)

### 3.2.2. 页尾页码删除

页尾页码通常是“书名+页码”或者“章节+页码”的形式存在。根据其特点，实践上有效的办法是，通过计算这一文本与书名和章节名的相似度，当相似度很高时，说明当前文本是页尾页码，自动删除。相似度需要先使用embedding模型，将段落文本转成向量。经验上，使用一个很小的模型，当前使用的大概是200M左右大小的“bge-base-zh-v1.5”，即可完全满足页尾页码的清洗需求。模型小，运算速度比会比较快。

![](/download/thumbnails/129175181/image2024-6-27_14-16-50.png?version=1&modificationDate=1719469010115&api=v2)

### 3.2.3. 引用、续表等特定文本删除

使用正则表达式删除。经验上，正则表达式的编写得具体，不能太泛化，否则会导致很多的误删。

![](/download/thumbnails/129175181/image2024-6-27_14-30-29.png?version=1&modificationDate=1719469829361&api=v2)

3.3. 表格清洗
---------

表格数据经常存在于书籍中，但是表格数据要被大模型所用、所理解，需要较为复杂的清洗和转换。

### 3.3.1. 表格转换

需要将表格转化为“文本表示的表格”。有效的做法，需要将表格转换成下面样式的文本。通过python的docx库，可编写代码实现。

![](/download/thumbnails/129175181/image2024-6-27_11-6-59.png?version=1&modificationDate=1719457619844&api=v2)![](/download/thumbnails/129175181/image2024-6-27_14-42-3.png?version=1&modificationDate=1719470523503&api=v2)

### 3.3.2. 表格进一步清洗

若OCR识别的表格不规整，目前没办法程序处理，只能手动进行调整。例如

1.  多行表头，转成一行表头
2.  重复识别列，修改回正确数量的列
3.  将表名和表备注合并成一行
4.  将没识别成表的表，转成表
5.  。。。

![](/download/attachments/129175181/image2024-6-27_14-46-42.png?version=1&modificationDate=1719470802277&api=v2)![](/download/thumbnails/129175181/image2024-6-27_14-47-50.png?version=1&modificationDate=1719470871030&api=v2)

这些情况多、有一些复杂度，人工审核的难度是比较高的。可以通过编写审核程序来，判断表格是否可能存在问题。

### 3.3.3. 表引用删除

由于文档会以切片形式作为一个知识单元。当一个知识单元中的某段话引用了某个表，而恰巧（大概论）这个表不在同一个切片内，就可能会造成大模型的误解。

可以通过正则表达式，识别并清除

![](/download/attachments/129175181/image2024-6-27_14-53-28.png?version=1&modificationDate=1719471208645&api=v2)

  

3.4. 图片清洗
---------

图片是肯定需要删除。因为图片对于大语言模型来说，不是可以输入的内容。所以当前对图片的清洗目标，就只有删除图片。然而由于OCR识别不准的问题，图片的删除依旧需要进一步的清洗。

总的来说图片的清洗相对简单，一般来说有2种情况进行注意。

1.  图片内容识别为文本
2.  图片引用

### 3.4.1. 图片内容识别为文本

图片的一大问题是，OCR可能会把图片中的某个字识别为文本。若不删除这些文本，就会导致知识库里存在无意义的噪音文本。这部分通过异常识别器，可以清除一部分。但是考虑到误删，目前还是需要一部分的人为清除。

![](/download/thumbnails/129175181/image2024-6-27_11-3-33.png?version=1&modificationDate=1719457413978&api=v2)![](/download/attachments/129175181/image2024-6-27_11-6-17.png?version=1&modificationDate=1719457577865&api=v2)

### 3.4.2. 图片引用

图片引用如表引用。引用文本会造成大模型的理解困难。

这部分可根据图片引用的文本特征，通过正则表达式删除。

3.5. 公式清洗
---------

公式是书籍里的重要知识。保留公式，能够保留书籍里的关键信息。但是OCR算法并不具备识别和转化公式的能力。若公式只是如 1+1=2，很简单的单行公式，没有上标下标，复杂符号之类的，OCR能够招架。若公式稍复杂，就会被转化成一张图片。

图片无法提供给大模型，则必须将公式图片转化为公式文本，才能保留住这部分的知识。

![](/download/attachments/129175181/image2024-6-27_15-13-22.png?version=1&modificationDate=1719472402278&api=v2)

但是如何把这种有上标下标、有除号等复杂表示的公式，用一行文本表示出来？目前主流的办法有

1.  Latex
2.  MathML
3.  MathType
4.  ...

当前用的是latex，因为讯飞有latex公式识别模型，可以帮助提高当前的清洗效率。

### 3.5.1. 图片转latex

我们实际的操作中，先训练了一个判断图片是否是公式的公式识别CNN模型。用模型先判断图片是否是公式，若是公式，则通过讯飞的公式识别算法，将图片中的公式转化为latex公式，这样可以避免识别额度被浪费掉。

![](/download/attachments/129175181/image2024-6-27_15-16-12.png?version=1&modificationDate=1719472572098&api=v2)

不过讯飞的公式识别模型效果并不好，从过去的经验看，60~70%左右的公式都或多或少有一点问题。还需要人工去审核这个公式是否完全正确。

![](/download/attachments/129175181/image2024-6-27_15-9-5.png?version=1&modificationDate=1719472146041&api=v2)

  

  

  

  

  

  

  

  

  

  

  

  

[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)

[Configure buttons visibility](/users/tfac-settings.action)