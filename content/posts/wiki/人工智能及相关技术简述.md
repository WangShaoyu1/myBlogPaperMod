---
author: "王宇"
title: "人工智能及相关技术简述"
date: 七月02,2023
description: "黄婷"
tags: ["黄婷"]
ShowReadingTime: "12s"
weight: 221
---
*   1[1\. 什么是人工智能（AI）？](#id-人工智能及相关技术简述-什么是人工智能（AI）？)
*   2[2\. 机器学习(ML)概述](#id-人工智能及相关技术简述-机器学习\(ML\)概述)
*   3[3\. 人工智能简史](#id-人工智能及相关技术简述-人工智能简史)
    *   3.1[3.1. 第一次人工智能热潮是推理与搜索时代](#id-人工智能及相关技术简述-第一次人工智能热潮是推理与搜索时代)
    *   3.2[3.2. 第二次人工智能热潮是知识时代](#id-人工智能及相关技术简述-第二次人工智能热潮是知识时代)
    *   3.3[3.3. 第三次人工智能热潮是深度学习和大数据时代](#id-人工智能及相关技术简述-第三次人工智能热潮是深度学习和大数据时代)
*   4[4\. 国内外人工智能发展对比](#id-人工智能及相关技术简述-国内外人工智能发展对比)
*   5[5\. 人工智能产业链](#id-人工智能及相关技术简述-人工智能产业链)
*   6[6\. 自然语言处理（NLP）分支](#id-人工智能及相关技术简述-自然语言处理（NLP）分支)
    *   6.1[6.1. 自然语言处理概述](#id-人工智能及相关技术简述-自然语言处理概述)
    *   6.2[6.2. 语言模型和自然语言处理（NLP）](#id-人工智能及相关技术简述-语言模型和自然语言处理（NLP）)
    *   6.3[6.3. chatgpt基本原理](#id-人工智能及相关技术简述-chatgpt基本原理)

1\. 什么是人工智能（AI）？
================

目前, 对人工智能还没有广泛认可的统一定义, 很多专家学者给出了一些有代表性的解读。**美国麻省理工学院Winston教授在《人工智能》一书中指出: “人工智能就是研究如何使计算机去做过去只有人才能做的智能的工作。“**

**一种定义：人工智能是利用数字计算机或者数字计算机控制的机器模拟、延伸和扩展人的智能，感知环境、获取知识并使用知识获得最佳结果的理论、方法、技术及应用系统。**例如，计算机视觉是人工智能，可以识别图像和视频中的对象。 

根据人工智能是否能真正实现推理、思考和解决问题，可以将人工智能分为**弱人工智能和强人工智能**。 

强人工智能指具有自我意识的智能, 这种人工智能要求机器有知觉、有意识, 遇到问题时能像人类一样进行决策。由于实现难度巨大, 强人工智能至今无法取得重大进展。弱人工智能是指没有思维意识的智能机器, 这些机器按照预编写好的程序进行工作, 并不真正拥有智能。当今的人工智能发展主要围绕弱人工智能展开。

![](/download/attachments/105258938/image2023-7-1_15-58-29.png?version=1&modificationDate=1688198310607&api=v2)

人工智能和机器学习、深度学习的关系：机器学习是人工智能的一个实现途径，深度学习是机器学习的一个方法（与人工神经网络相关）。

2\. 机器学习(ML)概述
==============

机器学习是一种人工智能的分支领域，是指通过计算机算法和模型来让计算机系统能够自动学习并不断改进性能的一种方法。

换句话说，**机器学习可以从数据中自动分析出规律，获得模型，并利用模型自主地对未知数据进行预测。**

![](/download/attachments/105258938/image2023-6-30_15-2-38.png?version=1&modificationDate=1688108558715&api=v2)

机器学习可以大致分为三种：监督学习，非监督学习和强化学习。  
• **监督学习：**从标记的训练数据（样本）中，利用特征和标签之间的关系进行学习和预测的过程。例子：猫狗图像识别。  
• **非监督学习：**指在没有给定标签或目标变量的情况下，学习数据内在的结构、规律或者特征。无监督学习的目标是找到数据内部的隐藏模式，通常用于聚类分析、降维、异常检测等领域。例子：找同类。  
• **强化学习：**指让机器能够在与环境不断交互的过程中，根据不断试错和反馈，逐渐学习到达成特定目标的最优策略（获得最大的奖赏）。

3\. 人工智能简史
==========

人工智能发展史共有三次浪潮，而这三次浪潮代表了三个时代，其中给人最印象深刻的是三盘棋：1962年的国际跳棋、1997年的国际象棋、2016年的围棋。

![](/download/attachments/105258938/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B.png?version=1&modificationDate=1688105377329&api=v2)

**人工智能的三次浪潮**

3.1. 第一次人工智能热潮是推理与搜索时代
----------------------

**1956年，在美国汉诺斯小镇召开的达特茅斯夏季研讨会（主办人：约翰·麦卡锡（John McCarthy），主题：用机器来模仿人类学习以及其他方面的智能），被认为是人工智能的起源。**这是一次头脑风暴式的研讨会，整整持续了两个月，虽然大家没有达成普遍的共识，但是为会议的内容起了一个名字——“人工智能”。  
在第一次人工智能热潮中，主要做的是求解迷宫问题、人机博弈、小游戏、自动定理证明等内容。  
人工智能的权威马文·明斯基针对风靡一时的神经网络，指出了它在特定条件下的局限性，即不能解决异或问题。美国政府出台了一个报告（ALPAC负面报告），认为机器翻译在短期内将难有成果。因此，到20世纪70年代，第一次人工智能的严冬来袭。

3.2. 第二次人工智能热潮是知识时代
-------------------

在第二次人工智能热潮中，主要做的是人机对话。它和第一次浪潮中利用推理和搜索等简单规则不同，它仅仅依靠“知识”的支持。  
这里有一个概念叫**“专家系统”**，**专家系统是指引入某个专业领域的知识，再经过推理，计算机便能够像该领域的专家一样出色工作。**  
比如：由斯坦福大学研制的医疗专家系统，是一种帮助医生对住院的血液感染患者进行诊断和选用抗菌素类药物进行治疗的人工智能。  
知识导入使得计算机变得更聪明，但知识描述之复杂与困难超出了当初预想，知识的输入是无穷无尽的，因此到1995年左右开始，人工智能研究又一次迎来寒冬。

3.3. 第三次人工智能热潮是深度学习和大数据时代
-------------------------

第三次人工智能热潮起源于2006年，深度学习的算法、数据和算力三者的结合使得机器可以自己从原始数据中去学习，促使第三次人工智能热潮的来临。  
2011年，Google Brain（谷歌大脑）开始建设，而且这个时代互联网迅猛发展，使得**大数据**（大数据的4V特征：规模性（Volume）、高速性（Velocity）、多样性（Variety）、价值性（Value））成为现实，为深度学习的实现提供了很好的数据基础。从**算力**的角度上来讲，不光是CPU，GPU可以做到一个很好的并行处理，而Google公司更是研发了专为深度学习设计的TPU，使得深度学习的训练速度更快。**算法**本身也取得了突破，深度学习算法迅速发展。

4\. 国内外人工智能发展对比
===============

中国仍然处于人工智能发展早期。目前美国在人工智能关键环节的多项指标都领先于中国 (表1) 。以硬件环节为例, 中国半导体产品国际市场占有率仅为4%, 远落后于美国占比全球50%的能力。以硬件环节为例, 中国半导体产品国际市场占有率仅为4%, 远落后于美国占比全球50%的能力。

表1 美国多项指标领先于中国

![](/download/attachments/105258938/%E8%A1%A81%20%E7%BE%8E%E5%9B%BD%E5%A4%9A%E9%A1%B9%E6%8C%87%E6%A0%87%E9%A2%86%E5%85%88%E4%BA%8E%E4%B8%AD%E5%9B%BD.jpg?version=1&modificationDate=1688107711555&api=v2)

5\. 人工智能产业链
===========

总体来看, 人工智能行业可分为基础支撑层、技术层和应用层。

表2 人工智能产业链

层级

核心能力

细分领域

产业生态搭建

层级

核心能力

细分领域

产业生态搭建

基础层

计算力

芯片、传感器、云计算/大数据

其中芯片具有极高的技术门槛, 且生态搭建已基本成型。目前该层级的主要贡献者是Nvidia和英特尔在内的国际科技巨头。中国的实力相对薄弱。

技术层

技术开发及输出

计算机视觉、自然语言处理、语音识别、机器学习

科技巨头谷歌、IBM、亚马逊、苹果、阿里、百度都在该层级深度布局。中国人工智能技术层在近年发展迅速, 除了BAT在内的科技企业之外, 出现了如商汤、旷视、科大讯飞等诸多独角兽公司。

应用层

商业化的解决方案

机器人、无人机、自动驾驶、智能客服、智能物流、客户画像等

从全球来看, Facebook、苹果将重心集中在了应用层, 先后在语音识别、图像识别、智能助理等领域进行了布局。得益于人工智能的全球开源社区, 这个层级的门槛相对较低。目前, 应用层的企业规模和数量在中国人工智能层级分布中占比最大。

![](/download/attachments/105258938/%E4%B8%AD%E5%9B%BD%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BA%A7%E4%B8%9A%E9%93%BE%E5%9B%BE%E8%B0%B1.jpg?version=1&modificationDate=1688107995634&api=v2)

**中国人工智能产业链图谱**

6\. 自然语言处理（NLP）分支
=================

6.1. 自然语言处理概述
-------------

**自然语言处理将人类语言转化为计算机程序可以处理的形式, 以及将计算机数据转化为人类自然语言的形式, 从而让计算机可以理解人类的语言。**

自然语言处理( Natural Language Process，NLP) 问题包括机器翻译( Machine Translation) 、文本摘要( Text Summarization) 、问答系统( Question Answering)   等诸多任务。

早在 1950 年，**图灵提出的 “图灵测试”被认为是自然语言处理思想的开端**——在测试者与被测试者（一个人和一台机器）隔开的情况下，通过一些装置（如键盘）， 向被测试者随意提问。进行多次测试后，如果有超过30%的测试者不能确定被测试者是人还是机器，那么这台机器就通过了测试，并被认为具有人类智能。

自然语言处理自诞生起，经历了五次研究范式的转变（如下图所示）：由最开始基于小规模专家知识的方法，逐步转向基于机器学习的方法。机器学习方法也由早期基于浅层机器学习的模型变为了基于深度学习的模型。为了解决深度学习模型需要大量标注数据的问题，2018 年开始又全面转向基于大规模预训练语言模型的方法（第一代 GPT和BERT模型），其突出特点是充分利用**大模型、大数据和大计算**以求更好效果。

![](/download/attachments/105258938/image2023-7-1_17-42-17.png?version=1&modificationDate=1688204537325&api=v2)

**自然语言处理研究范式的发展历程**

6.2. 语言模型和自然语言处理（NLP）
---------------------

**语言模型可以学习一个文本库（称为语料库），并用概率分布来预测词语或词语序列**，即词语或序列出现的可能性有多大。例如，当你说“张三喜欢吃……”时，下一个词为“苹果”的概率会比“桌子”更高。如果它正在预测序列中的下一个词，则称为单项推导（next-token prediction），类似于**续写**；如果它正在预测序列中缺失的词，则称为掩码语言建模（masked language modeling），类似于**填空**。

由于它是一个概率分布，可能会有许多可能性不同的概率高的单词可以填进去。虽然你可能认为始终选择概率最大的最佳候选词是一个最好的策略，但它可能会产生重复的话。因此，在实践中，研究人员会在从首选候选词中选择单词时添加一些随机性（温度）。

![](/download/attachments/105258938/%E5%85%B8%E5%9E%8B%E7%9A%84%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B%E4%B8%AD.png?version=1&modificationDate=1688221751450&api=v2)

**典型的自然语言处理过程**

*   **预处理（Pre-processing)**：使用句子分割、分词（将文本分解为称为标记的小片段）、词干提取（去除后缀或前缀）、去除停用词、更正拼写等技术处理原始文本（Original Input)。例如，“张三喜欢吃苹果”将被处理为\["张三", "喜欢","吃", "苹果"\]。
*   **编码或嵌入（Encoding or Embedding）**：将处理后的文本转换为数字向量(Encoded Vectors)，以便模型可以处理。
*   **传递给模型（Feed to Model）**：将编码的输入传递给模型进行处理。
*   **获取结果（Get Result）**：从模型中获得代表潜在词汇的数字向量的概率分布(Probability Distribution)结果。
*   **解码（Decoding）**：将向量转换回可读的单词。
*   **后处理（Post-processing）**：使用拼写检查、语法检查、标点、大写等进行输出的优化。

6.3. chatgpt基本原理
----------------

![](/download/attachments/105258938/image2023-7-1_23-21-46.png?version=1&modificationDate=1688224906660&api=v2)

**Transformer整体结构（引自谷歌论文）**

ChatGPT 强大的基础模型采用 Transformer 架构，Transformer是一种基于自注意力机制的深度神经网络模型，可以高效并行地处理序列数据。原始的 Transformer 模型包含两个关键组件：编码器和解码器。**编码器**用于将输入序列映射到一组中间表示，**解码器**则将中间表示转换为目标序列。编码器和解码器都由多层的注意力模块和前馈神经网络模块组成。其中**自注意力模块可以学习序列中不同位置之间的依赖关系**，即在处理每个位置的信息时，模型会考虑序列中其他所有位置上的信息，这种机制使得 Transformer 模型能够有效地处理长距离依赖关系。

例如：“张三喜欢吃苹果。他每天都吃它们。” 在这个句子中，通过计算单词向量之间的相似性评分，注意机制使用数学算法告诉模型这些单词是相关的：“他”指的是“张三”，“它们”指的是“苹果”。通过这个机制，Transformer 可以更好地以一种更连贯的方式“理解”文本序列中的意义。

  

[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)

[Configure buttons visibility](/users/tfac-settings.action)