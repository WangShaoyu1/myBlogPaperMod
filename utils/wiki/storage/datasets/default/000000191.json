{
	"title": "大模型中控管理技术预研",
	"author": "王宇",
	"publishTime": "十一月28,2023",
	"readTime": "12s",
	"tags": "[\"黄婷\"]",
	"description": "黄婷",
	"article": "*   1[1\\. 概况](#id-大模型中控管理技术预研-概况)\n*   2[2\\. 大模型中控应用技术调研](#id-大模型中控管理技术预研-大模型中控应用技术调研)\n    *   2.1[2.1. 工具学习技术解析](#id-大模型中控管理技术预研-工具学习技术解析)\n        *   2.1.1[2.1.1. 意图理解](#id-大模型中控管理技术预研-意图理解)\n        *   2.1.2[2.1.2. 工具理解](#id-大模型中控管理技术预研-工具理解)\n        *   2.1.3[2.1.3. 规划与推理](#id-大模型中控管理技术预研-规划与推理)\n    *   2.2[2.2. Plugins技术解析](#id-大模型中控管理技术预研-Plugins技术解析)\n        *   2.2.1[2.2.1. MCFM](#id-大模型中控管理技术预研-MCFM)\n        *   2.2.2[2.2.2. API Platform](#id-大模型中控管理技术预研-APIPlatform)\n        *   2.2.3[2.2.3. API Selector](#id-大模型中控管理技术预研-APISelector)\n        *   2.2.4[2.2.4. Action Executor](#id-大模型中控管理技术预研-ActionExecutor)\n    *   2.3[2.3. HuggingGPT 解析](#id-大模型中控管理技术预研-HuggingGPT解析)\n        *   2.3.1[2.3.1. 前言](#id-大模型中控管理技术预研-前言)\n        *   2.3.2[2.3.2. 任务规划](#id-大模型中控管理技术预研-任务规划)\n        *   2.3.3[2.3.3. 模型选择](#id-大模型中控管理技术预研-模型选择)\n        *   2.3.4[2.3.4. 任务执行](#id-大模型中控管理技术预研-任务执行)\n        *   2.3.5[2.3.5. 响应生成](#id-大模型中控管理技术预研-响应生成)\n        *   2.3.6[2.3.6. 存在的问题](#id-大模型中控管理技术预研-存在的问题)\n        *   2.3.7[2.3.7. 快速体验](#id-大模型中控管理技术预研-快速体验)\n*   3[3\\. 大模型中控实现方案思考](#id-大模型中控管理技术预研-大模型中控实现方案思考)\n    *   3.1[3.1. 任务识别](#id-大模型中控管理技术预研-任务识别)\n    *   3.2[3.2. 技能选择](#id-大模型中控管理技术预研-技能选择)\n    *   3.3[3.3. 任务执行](#id-大模型中控管理技术预研-任务执行.1)\n    *   3.4[3.4. 响应生成（可选）](#id-大模型中控管理技术预研-响应生成（可选）)\n*   4[4\\. 参考文章](#id-大模型中控管理技术预研-参考文章)\n\n1\\. 概况\n======\n\n解决不同领域和多模态的复杂人工智能任务是迈向人工通用智能（AGI）的关键步骤。\n\n尽管大模型（LLM）在很多方面取得了显著的成果，但在特定领域的任务上，仍然存在一定的局限性，这些任务往往需要专业化的工具或领域知识才能有效解决。虽然现有的人工智能专业化模型可以用于不同的领域和模态，但还无法处理复杂的人工智能任务。鉴于大型语言模型（LLM）在语言理解、生成、交互和推理方面的突出表现，或许可以将 LLM 作为控制器，来管理现有的模型/接口/插件/工具，以解决复杂的任务。整合专用工具与大模型可以充分发挥各自独特的优势。专用工具可以解决模型时效性不足的问题、增强专业知识、提高可解释性和鲁棒性。而大模型在理解复杂数据和场景方面具备很强的推理规划能力，能与现实世界进行灵活的交互。\n\n基于此，本文首先会给出当前大模型作为中控应用的相关技术调研情况，然后提出大模型在对话系统中充当中控，并实现意图理解与分发、给出响应的可行方案。\n\n2\\. 大模型中控应用技术调研\n===============\n\n2.1. 工具学习技术解析\n-------------\n\n中控大模型需要在理解用户意图的基础上，选择合适的工具完成用户期望的目标，最核心的问题就是工具的选择和使用，因此了解当前的工具学习技术是很有必要的，本节主要总结了**[基础模型工具学习](/download/attachments/114661101/Tool%20Learning.pdf?version=1&modificationDate=1701082212372&api=v2)**综述论文的相关内容。\n\n**工具学习是指让模型能够理解和使用各种工具来完成任务的学习过程。**从学习目标的角度来看，现有工具学习主要可以分为两类：\n\n*   **工具增强学习（Tool-augmented Learning）**，利用各种工具的执行结果，增强基础模型性能。在这一范式中，工具执行结果被视为辅助生成高质量输出的外部资源。\n*   **工具导向学习（Tool-oriented Learning）**，将学习过程重点从增强模型性能转向工具执行本身。这一类研究关注开发能够代替人类控制工具并进行序列决策的模型。\n\n上述两类方法的核心差异在于学习过程的侧重点，即通过工具执行来增强基础模型（工具为AI服务）或者通过基础模型优化工具的使用（AI为工具服务）。\n\n一个通用的工具学习框架包含**人类用户**和**四个关键组成部分：工具集、控制器、感知器和环境：**\n\n**![](https://pic2.zhimg.com/80/v2-d0a152040a314525d9e124ca13463641_720w.webp)**\n\n*   **工具集（Tool Set）**：可供模型使用的各种工具。从交互接口的视角可以分为三类：基于物理交互的工具、基于GUI交互的工具、基于程序交互的工具。\n*   **控制器（Controller）**：通常使用基础模型建模，负责接收用户的指令，并根据这些指令制定可执行的计划从而调用工具执行。\n*   **感知器（Perceiver）**：负责接收来自环境和用户的反馈信息，并汇总给控制器。\n*   **环境（Environment）**：模型所处的场景，包括物理环境和虚拟环境等。\n\n整个过程从用户指令开始，接收到指令后，由基础模型支持的控制器被激活，并为该指令制定计划从而控制执行工具与环境进行交互；工具执行可能导致环境发生变化，感知器捕捉这些变化并将信息反馈给控制器，进行新一轮的工具执行；人类也可以提供反馈来纠正或协助控制器的决策。经过多轮工具执行后，实现用户需求；最后，控制器可以将工具返回的信息汇总给用户。\n\n工具学习领域存在以下重点研究问题：\n\n### 2.1.1. 意图理解\n\n控制器需要理解用户所给出的自然语言指令，识别其对应的任务目标。意图理解在现实工具学习应用场景中仍存在着诸多挑战：（1）**指令模糊问题**：用户给出的指令很有可能是不精确甚至多义的。（2）**指令多样问题**：用户给出的指令天然具有个性化和多样性。\n\n### 2.1.2. 工具理解\n\n控制器使用工具的前提是理解工具的功能与使用方式。人类在学习使用工具时通常会有两种途径，一是**从工具的说明书或是教程中学习；**二是**通过观察其它人使用工具的过程来学习。**类似的，现有工具学习工作通常采用两种提示学习技术实现工具理解：零样本提示学习和少样本提示学习。但是提示学习的有效性很大程度上取决于模型能力，而且会受到输入上下文长度的限制。\n\n零样本提示学习描述工具的功能、输入输出格式等，少样本提示学习则通过具体的使用案例来提示模型如何使用对应工具。\n\n### 2.1.3. 规划与推理\n\n对于复杂任务，控制器需要具备一定的规划和推理能力，以便将任务拆分成若干子任务。这一过程中的推理能力可以分为两类：**内省推理（Introspective Reasoning）**是指控制器在不涉及与环境交互的情况下，仅根据指令对任务进行推理和规划，无需中间执行结果。这种推理方式侧重于分析任务的本质，通过对指令的理解来生成相应的规划；与之相反，**外省推理（Extrospective Reasoning），**涉及控制器与环境的交互。在这种情况下，控制器会根据先前步骤的执行结果逐步推理并生成规划。这种方式强调了模型的实时调整和适应能力，使得控制器能够在完成任务过程中不断优化规划策略。\n\n2.2. Plugins技术解析\n----------------\n\nChatGPT模型本身没有能力去调用和执行程序，只能输出文本指令(代码)，让其他系统去执行动作，这个执行动作的系统就是插件。所以，**ChatGPT会使用工具的意思是，它可以输出特定的代码，供执行器执行并返回结果。**目前这些工具，大部分都是以API形式提供的。\n\n要实现插件控制功能，需要做几件事情：\n\n*   **训练LLM学会使用工具**(输出调用API的代码)。\n*   **告诉LLM有哪些工具**，并且告诉它这些工具如何使用。\n*   **告诉LLM在什么情况下需要使用这些工具**。\n\n在ChatGPT里，具体做法如下：\n\n*   首先，按照 OpenAPI 标准为 API 编写规范，这个规范就是工具的使用手册。\n*   然后，将API的规范转化为prompt，要尽可能的详细，包括每个功能的具体使用说明。\n*   最后，对于用户提出的问题，如果 ChatGPT 确定要从 API 中获取信息，将在答复之前发出API请求，并把API返回结果添加到回复上下文中。\n\n插件技术是大模型作为中控应用的一个场景，有一些可以借鉴的地方，因此，本节重点总结了微软最近发表的[TaskMatrix.AI论文](/download/attachments/114661101/TaskMatrix.pdf?version=1&modificationDate=1701082149831&api=v2)中涉及的相关技术。\n\nTaskMatrix.AI 包括了四个组分：\n\n*   **Multimodal Conversational Foundation Model (MCFM)**， 负责和用户进行交互，理解目标以及多模态输入，生成可执行code来调用API\n*   **API Platform**， 提供了一个统一的文档规定，来存储百万级别的API ，允许API 开发者进行注册，更新和删除\n*   **API Selector**，负责根据用户输入选择相关的API\n*   **API Executor**，负责调用API，执行LLM生成的动作代码，返回中间以及最终执行结果\n\n### 2.2.1. MCFM\n\nPlugins技术的核心就是MCFM，其需要能够理解用户意图，以及生成动作代码。此外，MCFM还可以利用用户反馈进行学习，有两种学习机制：\n\n*   **RLHF：**提高MCFM对API的理解和动作代码生成的能力，以及API selector 检索API的准确率。具体操作为：通过人工反馈来训练一个奖励模型，该模型可以对任务是否已完成进行分类。在 RLHF 训练期间，MCFM 可以使用很多策略来生成solution outline，以及选择和组合API的方式，奖励模型可以提供反馈，来说明生成内容是否良好。通过RLHF，MCFM 和 API 选择器可以优化相关策略并寻求更好的方法来完成任务。\n\n*   **Feedback to API Developers：**这里意思是，反馈也可以帮助API开发者改进所写的文档，使得其开发的API能够更好的被MCFM理解和调度。\n\nMCFM核心架构如下图，其具体执行逻辑如下：\n\n*   指令和会话上下文，MCFM 首先生成一个solution outline（步骤1），这是对解决任务所需步骤的文本描述。用户经常使用简短的表达式来传达他们的高级任务意图，因此 MCPM 利用世界知识生成完成任务所需的步骤，并给出文本描述。\n*   API 选择器根据solution outline从 API 平台中选择最相关的 API（步骤 2）\n*   MCFM 使用选择的 API 生成动作代码，这些 API 将在后面的阶段执行。\n*   将用户对任务是否完成的反馈传达给 MCFM 和 API 开发人员。\n\n![](/download/attachments/114661101/image2023-11-27_17-45-36.png?version=1&modificationDate=1701078336962&api=v2)\n\n### 2.2.2. API Platform\n\nAPI平台有两个主要功能：（1）存储可以访问的API 以及说明文档 （2）允许API开发人员或所有者注册、更新或删除API。\n\n为了帮助 MCFM更好地理解和使用 API，API 平台指定了一个统一的 API 文档模式，其由五个方面组成：\n\n*   API Name ， 对API功能的抽象描述，能够辅助MCFM查询，作者要求API不能和其他API的名字冲突\n*   Parameter List， 包含API 输入参数和返回参数的描述\n*   API Description，包含API的定义、工作原理、输入和输出描述以及可能的错误或异常等详细信息\n*   Usage Example（Optional），API使用示例，简单的API可以不需要，但是复杂的最好写一下，能更好的指导模型使用\n*   Composition Instruction（Optional），可以提供一些组合API的指令，从而指导模型更好的理解用户指令，并组合相关的API\n\n### 2.2.3. API Selector\n\nAPI 选择器的目标是从 API 平台识别和选择最合适的 API，其输入是MCFM 根据用户指令所产生的solution outline，输出是选择的API。\n\n### 2.2.4. Action Executor\n\n动作执行器即执行生成的动作代码，完成API调用链路。为了提高准确性和可靠性，动作执行器还需要一个验证机制来确认生成的代码或结果是否满足用户的需求。\n\n2.3. HuggingGPT 解析\n------------------\n\n### 2.3.1. 前言\n\nHuggingGPT是由浙江大学和微软亚研的研究者提出的一种让LLM充当控制器的新方法，使用语言作为通用接口，来管理现有的AI模型以解决复杂的AI任务的框架。其实现思路与我们的需求较为相似，故本节对[HuggingGPT论文](/download/attachments/114661101/HuggingGPT.pdf?version=1&modificationDate=1700618329123&api=v2)中涉及的技术进行详细解析。\n\nHuggingGPT 一端连接着ChatGPT，一端连接着众多领域专精的AI模型，当用户输入自然语言时，可结合ChatGPT将用户的意图拆解，并按需调用对应意图的AI模型，最后再结合生成结果，如下图所示，**主要流程可以分为四个阶段：**\n\n*   **任务规划：**使用 ChatGPT 分析用户请求，将其分解为多个子任务，规划任务顺序和依赖关系。\n*   **模型选择：**对于子任务，ChatGPT 将根据模型描述来选择 HuggingFace 上的专家模型。\n*   **任务执行：**每个专家模型执行所分配的子任务，返回执行结果。\n*   **响应生成：**最后由 ChatGPT 集成所有专家模型的结果，并为用户生成答案。\n\n![](/download/attachments/114661101/image2023-11-22_9-57-9.png?version=1&modificationDate=1700618229740&api=v2)\n\n这种设计使 HuggingGPT 能够使用外部模型，从而可以集成多模态感知能力并处理多个复杂的人工智能任务。此外，这种架构还使 HuggingGPT 能够不断引入特定的专家模型，实现可增长和可扩展的人工智能能力。论文还指出任务规划在HuggingGPT中起着非常重要的作用，它直接决定了后续工作流的成功。因此，如何进行规划也是反映LLM能力的一个维度。\n\n截至目前，HuggingGPT 已经基于 ChatGPT 在 HuggingFace 上集成了数百个模型，涵盖了文本分类、对象检测、语义分割、图像生成、问答、文本到语音、文本到视频等 24 项任务。\n\nHuggingGPT采用LLM作为控制器，在给定用户请求的情况下，自动部署整个工作流，从而协调和执行专家模型来完成目标。这依赖于下图所示详细的prompt设计：\n\n![](/download/attachments/114661101/image2023-11-22_15-41-38.png?version=1&modificationDate=1700638899134&api=v2)\n\n### 2.3.2. 任务规划\n\n任务规划是HuggingGPT 的第一个阶段，目的是将用户的请求分解为一系列结构化的任务。复杂的请求通常涉及多个任务，并且LLM需要确定这些任务的依赖关系和执行顺序。为了指引LLM进行有效的任务规划，HuggingGPT 在其prompt设计中采用了**基于规范的指令和基于演示的解析**。\n\n**基于规范的指令**为任务解析提供了统一的模板，并指导LLM通过属性填充进行任务解析。每个任务都有任务类型（task）、任务ID（task\\_id）、任务依赖项（dep）和任务参数（args）四个属性，模板格式如下：\n\n* * *\n\n\\[{\"task\": task, \"id\", task\\_id, \"dep\": dependency\\_task\\_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}\\]\n\n* * *\n\n属性含义如下：\n\n*   **任务类型：**涵盖语言、视觉、视频、音频等不同任务。HuggingGPT当前支持的任务列表如下表所示。\n*   **任务 ID：** 为任务规划提供了一个唯一的标识符，用于引用相关任务及其生成的资源。\n*   **任务依赖项：**定义了执行所需的先决条件任务。只有在完成所有先决条件相关任务后，才会启动该任务。\n*   **任务参数：**包含执行任务所需的参数列表。它包含三个子字段，根据任务类型填充文本、图像和音频资源，它们是从用户的请求或相关任务的生成资源中解析的。不同任务的相应参数类型如下表所示。\n\n![](/download/attachments/114661101/image2023-11-22_15-50-52.png?version=1&modificationDate=1700639452228&api=v2)\n\n**基于演示的解析**使得LLM能更好地理解任务规划的意图和标准。HuggingGPT在prompt中包含多个demo，每个demo由一个用户请求及预期输出组成，帮助LLM理解任务之间的逻辑连接，确定执行顺序和识别资源依赖关系。\n\n此外，可以将聊天历史记录融入prompt中，这样HuggingGPT 可以利用上下文信息进行任务规划。\n\n### 2.3.3. 模型选择\n\n模型选择即为任务列表中的每个任务选择最佳的模型。HuggingGPT 通过**上下文任务模型分配机制**为任务选择合适的模型。\n\n**上下文任务模型分配机制**，将任务和模型的匹配视为单选问题，候选模型作为给定上下文中的选项。由于上下文长度的限制，不可能在prompt中包含所有的模型信息。因此，首先要根据任务类型筛选出匹配的模型。然后，根据下载次数对模型进行排序（下载次在某种程度上可以反映模型的质量），选择“Top-K”的模型。此策略可以大大减少prompt中token的使用，并有效地为每个任务提供候选模型。\n\nLLM基于用户请求和模型描述的相关性，从候选模型中选出最合适的模型，并输出严格的JSON格式：{“id”: “模型ID”, “reason”: “选择该模型的详细原因”}。\n\n### 2.3.4. 任务执行\n\n任务执行阶段，HuggingGPT会自动将任务参数输入到LLM选定的专家模型中，并运行这些模型来获得推理结果，然后将其发送回LLM。\n\n尽管HuggingGPT能够通过任务规划来确定任务执行顺序，但在任务执行阶段有效管理任务之间的**资源依赖性**仍然具有挑战性。原因是HuggingGPT无法在任务规划阶段为任务指定未来生成的资源。为了解决这个问题，论文使用一个唯一的符号“＜resource＞”来管理资源依赖关系。具体来说，HuggingGPT将先决任务生成的资源标识为<resource>-task\\_id，其中task\\_id是先决任务的任务id。在任务规划阶段，如果存在依赖于task\\_id任务生成的资源的任务，则HuggingGPT将此符号设置为任务参数中相应的资源子字段。然后在任务执行阶段，HuggingGPT将此符号动态替换为先决任务生成的资源。此策略使HuggingGPT能够在任务执行期间有效地处理资源依赖关系。\n\n为了进一步提高推理效率，可以对不具有资源依赖性的模型并行化处理，这意味着可以同时启动多个满足先决条件的任务。\n\n### 2.3.5. 响应生成\n\n在所有任务执行完成后，HuggingGPT 进入响应生成阶段。在这个阶段，HuggingGPT 将前三个阶段（任务规划、模型选择和任务执行）的信息集成为摘要：用户输入：{{用户输入}}，任务规划：{{任务}}，模型选择：{{分配的模型}}，任务执行：{{预测结果}}。\n\n其中最重要的是预测结果，这是 HuggingGPT 做出最终决策的关键。这些推理结果以结构化格式出现，例如目标检测模型中具有检测概率的边界框、问答模型中的答案分布等。HuggingGPT 允许 LLM 接收这些推理结果作为输入，并基于用户请求给出具有置信度的可靠响应。\n\n### 2.3.6. 存在的问题\n\nHuggingGPT 目前能解决一定的问题，但在应用上还存在一些不足。\n\n*   **效率：**效率的瓶颈在于LLM的推理。对于每一轮用户请求，HuggingGPT 都需要在任务规划、模型选择和响应生成阶段与大型语言模型进行至少一次的交互，这导致响应延迟，并影响用户体验。\n\n*   **最大上下文长度的限制：**受 LLM 可以接受的最大token数的限制，HuggingGPT 面临着最大上下文长度的限制。论文中通过使用会话窗口，在任务规划阶段只跟踪会话上下文来解决。\n\n*   **系统稳定性：**一是在LLM的推理过程发生的“反叛行为”。大型语言模型在推理时偶尔会不符合指令，并且输出格式可能会超出预期，从而导致程序工作流中出现异常。二是 HuggingFace 的推理端点上托管的专家模型的状态不可控。HuggingFace 上的专家模型可能会受到网络延迟或服务状态的影响，导致任务执行阶段出现错误。\n\n### 2.3.7. 快速体验\n\n可以在此[体验HuggingGPT](https://huggingface.co/spaces/microsoft/HuggingGPT)，需要输入openai api key和HuggingGPT token。\n\n  \n\n![](/download/attachments/114661101/image2023-11-22_15-20-28.png?version=1&modificationDate=1700637628431&api=v2)\n\nquery：请画一只可爱的猫\n\nresult：结果如上图所示，虽然准确的理解了画图的任务，并成功的选择模型执行任务，但是画出来的图片内容不符合要求。\n\n![](/download/attachments/114661101/image2023-11-22_15-7-33.png?version=1&modificationDate=1700636853517&api=v2)\n\nquery：写一首“日落”相关的诗，并给出对应情境的图片\n\nresult：结果如上图所示，准确的理解了作诗和画图的任务，并成功的选择模型执行任务，相关参数如下。\n\n{  \n\"0\": {  \n\"task\": {  \n\"task\": \"text-generation\",  \n\"id\": 0,  \n\"dep\": \\[  \n\\-1  \n\\],  \n\"args\": {  \n\"text\": \"写一首“日落”相关的诗\"  \n}  \n},  \n\"inference result\": {  \n\"response\": \"诗：\\\\n\\\\n日落西山画卷开，\\\\n残阳如血洒江台。\\\\n金桥挂梭照不足，\\\\n月上柳梢夜已垂。\\\\n\\\\n一片霞光照峡谷，\\\\n金色河流向海流。\\\\n渔歌断绝乌鸦归，\\\\n温暖稍短光年流。\\\\n\\\\n日落了，轮回常在，\\\\n明月之下归人在。\\\\n断桥边，落日熔金，\\\\n心中的诗，不被遗忘。\\\\n\\\\n夜幕低垂街灯亮，\\\\n人间烟火起微光。\\\\n日落西山我未返，\\\\n心仍悬于那霞光。\"  \n},  \n\"choose model result\": {  \n\"id\": \"ChatGPT\",  \n\"reason\": \"ChatGPT performs well on some NLP tasks as well.\"  \n}  \n},  \n\"1\": {  \n\"task\": {  \n\"task\": \"text-to-image\",  \n\"id\": 1,  \n\"dep\": \\[  \n0  \n\\],  \n\"args\": {  \n\"text\": \"写一首“日落”相关的诗\"  \n}  \n},  \n\"inference result\": {  \n\"generated image\": \"/images/74e4.jpg\"  \n},  \n\"choose model result\": {  \n\"id\": \"runwayml/stable-diffusion-v1-5\",  \n\"reason\": \"Only one model available.\"  \n}  \n}  \n}\n\n3\\. 大模型中控实现方案思考\n===============\n\n从技术调研情况来看，大模型作为对话中控的实现流程如下：\n\n![](/download/attachments/114661101/image2023-11-28_14-43-12.png?version=1&modificationDate=1701153793130&api=v2)\n\n中控实现方案基本包含以下四个阶段：\n\n*   **任务识别：**分析用户query和上下文信息，将其分解为多个子任务（一个子任务对应一个技能或意图）。\n*   **技能选择：**对于每个子任务，LLM根据用户query和技能描述来选择对应的技能，并规划出技能的执行顺序和依赖关系。若有多个技能可选，则根据设定的规则，规划出多个技能的串并行执行方案；若无法决定采用哪个技能，则进行澄清或给出负反馈。\n*   **任务执行：**按LLM规划的方案，应用层调用每个技能执行所分配的子任务，并返回执行结果。\n*   **响应生成（可选）：**最后由LLM集成所有技能的结果，为用户生成最终答复。\n\n其中，大模型主要参与任务识别、技能选择和响应生成三个环节。考虑到整体性能和效果，响应生成阶段其实可以不用走大模型，应用层直接给出对应技能的答复就行。任务识别阶段初步判定用户query的类型、领域和意图，这样在技能选择阶段，应用层可以先过滤掉不符合要求的技能，筛选出一部分候选技能供大模型选择，从而减少token的使用。技能选择依赖于技能描述，且大模型或许可以协助解析出技能运行所需的参数，因此，有必要建立一个技能平台，使用统一的技能文档规范来描述每个技能的类型、领域、适用场景、输入输出参数等内容，方便大模型进行工具学习，同时，方便技能的注册、更新和删除，具体设计可以参考2.2.2节的API Platform内容。\n\n结合业务需求和大模型相关技术的应用情况，认为对话中控可行的实现方案有以下三种：\n\n*   **指令引导方案：**这种方案与HuggingGPT的实现思路基本一致，通过在任务识别、技能选择和响应生成阶段设定对应的prompt，指引大模型完成任务。因此方案未利用领域数据，高度依赖于大模型的基础能力，且要求很高的技能描述质量，实现效果大概率不太好。\n    \n*   **知识库检索+指令引导方案：**这种方案在技能选择阶段，引入知识库检索技术，从而能筛选出与用户query相似度较高的技能；改进了基于任务类型、领域和意图直接筛选候选技能的方案。因使用了技能内的语料数据，能提高技能选择的准确性；同时，更少的候选技能也能进一步减少大模型token的使用。\n    \n*   **领域数据微调+指令引导方案：**这种方案使用技能相关的领域数据微调大模型，从而提高大模型的意图识别能力，使得任务识别结果更精准。这样，技能选择阶段可以基于任务识别结果，直接选出置信度较高的候选技能，无需二次筛选。虽然实现难度和成本较高，但是效果也会是最好的。\n    \n\n知识库检索的实现思路如下：\n\n（1）解析相关语料为文本  \n（2）将所有文本转化为embedding（这一步目前处理的方式大都是根据长度截断），并存储至数据库  \n（3）将用户输入转换为embedding，并在数据库中召回相关性最高的句子集合  \n（4）根据召回的句子，选出对应的技能\n\n上述思路虽然直观，但要获取更好的结果，每一步都有探索优化的空间：\n\n（1）文本解析可以针对不同类型的数据针对性解析，且不一定要穷举所有的语料  \n（2）句子embedding有很多可选的方法  \n（3）需要确定如何根据召回的句子选出候选技能，可设定召回阈值或直接召回topK句子\n\n接下来进一步介绍大模型对话中控各阶段的具体内容。\n\n3.1. 任务识别\n---------\n\n任务识别阶段的目的是初步判定用户query的类型、领域和意图，并将用户的请求分解为结构化的子任务。参考HuggingGPT的prompt设计，采用**基于规范的指令和基于演示的解析**。\n\n基于规范的指令为任务解析提供统一的模板，除了任务类型（task）、任务ID（task\\_id）、任务依赖项（dep）和任务参数（args）四个属性外，对话系统还需要解析出任务领域（domain）和意图（intent），各属性含义如下：\n\n*   **任务类型：**涵盖基础问答、基础指令、表格问答、任务型、闲聊等不同任务。\n*   **任务领域：**涵盖食谱、炉操作、商品购买、闲聊等不同领域。\n*   **任务意图：**用户query的最终意图，若大模型能直接确定一个意图，则可以跳过技能选择阶段。\n*   **任务 ID：** 为任务规划提供了一个唯一的标识符，用于引用相关任务及其生成的资源。\n*   **任务依赖项：**定义了执行所需的先决条件任务。只有在完成所有先决条件相关任务后，才会启动该任务。\n*   **任务参数：**包含任务相关的参数列表，对话系统中主要指技能对应的词槽。\n\n基于演示的解析在promt中融入一些精细化设计的demo，使得LLM能利用上下文信息，更好地解析任务。\n\n此阶段实现难度较高，且是对话中控能否实现的关键，光靠prompt难以达到较好的效果，最好能结合领域数据微调。\n\n因对话系统涉及技能内多轮对话，比如词槽填充和任务型对话中间节点等，这些情况由大模型做中控难度太大，且执行过程不太可控，故可能还需要结合上下文信息判断是否技能内多轮对话，若是，则不再走大模型中控的流程。\n\n3.2. 技能选择\n---------\n\n技能选择参考HuggingGPT的实现思路，只是对话系统的技能选择是多选问题，且要求能输出严格的JSON格式：{“id”: “技能ID”, “reason”: “选择该技能的详细原因”, “置信度”: “选择该技能的置信度”, “优先级”: “执行该技能的优先级”}。不同实现方案对应的内容如下：\n\n*   **指令引导方案：**首先，应用层根据任务类型、领域和意图筛选出候选技能；然后，大模型基于用户请求和候选技能描述的相关性，进一步选出必要的技能，并规划出串并行执行方案（通过优先级判断）。\n*   **知识库检索+指令引导方案：**首先，应用层利用知识库检索技术，召回与用户query相似度较高的候选技能；然后，大模型基于用户请求和候选技能描述的相关性，参考向量计算的相似度，进一步选出必要的技能，并规划出串并行执行方案。\n*   **领域数据微调+指令引导方案：**直接根据任务识别的置信度，筛选出必要的技能，并规划出串并行执行方案。\n\n3.3. 任务执行\n---------\n\n任务执行阶段由应用层按照大模型规划的执行方案，依次调用对应的技能执行并获得相关结果。若任务识别阶段大模型能解析出任务执行所需要的全部参数（一般指词槽），则可以直接调用技能应答API，从而大大缩短对话链路。否则，需要走一遍技能内的nlp流程，必然导致响应延迟。当然，技能参数解析难度较高，需要参照上文提到的工具学习技术，单独构造数据集，训练大模型的参数解析能力。\n\n3.4. 响应生成（可选）\n-------------\n\n在所有任务执行完成后，LLM汇总多个技能的执行结果，并生成最终答复。用大模型来生成答复，可以使得答复内容更灵活多样，但必然会导致响应延迟，当前采用规则处理的方案也是可接受的，所以此阶段对大模型对话中控来说其实是可选的。\n\n4\\. 参考文章\n========\n\n*   [论文-Tool Learning with Foundation Models](/download/attachments/114661101/Tool%20Learning.pdf?version=1&modificationDate=1701082212372&api=v2)\n*   [大模型工具学习权威综述，BMTools 背后的论文！](https://zhuanlan.zhihu.com/p/624459759)\n*   [论文-TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs](/download/attachments/114661101/TaskMatrix.pdf?version=1&modificationDate=1701082149831&api=v2)\n*   [ChatGPT Plugins背后技术解读](https://zhuanlan.zhihu.com/p/618321882)\n*   [ChatGPT plugin的插件功能是如何实现的？](https://www.zhihu.com/question/594369824)\n*   [论文-HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HugingFace](/download/attachments/114661101/HuggingGPT.pdf?version=1&modificationDate=1700618329123&api=v2)\n*   [HuggingGPT 开源代码](https://github.com/microsoft/JARVIS)\n*   [ToolLLM=LLM+tool use--大模型的高级玩法](https://zhuanlan.zhihu.com/p/649573838)\n\n  \n\n[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)\n\n[Configure buttons visibility](/users/tfac-settings.action)"
}