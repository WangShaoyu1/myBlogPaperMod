{
	"title": "2.2、意图设计&对话设计",
	"author": "王宇",
	"publishTime": "六月25,2023",
	"readTime": "12s",
	"tags": "[\"2、语音交互设计知识\"]",
	"description": "2、语音交互设计知识",
	"article": "*   1[3.4 语音交互框架、意图设计](#id-2.2、意图设计&对话设计-3.4语音交互框架、意图设计)\n    *   1.1[唤醒状态](#id-2.2、意图设计&对话设计-唤醒状态)\n    *   1.2[聆听状态](#id-2.2、意图设计&对话设计-聆听状态)\n    *   1.3[网络等待状态](#id-2.2、意图设计&对话设计-网络等待状态)\n    *   1.4[语音播报状态](#id-2.2、意图设计&对话设计-语音播报状态)\n    *   1.5[长连接通信状态](#id-2.2、意图设计&对话设计-长连接通信状态)\n    *   1.6[结束至默认状态](#id-2.2、意图设计&对话设计-结束至默认状态)\n*   2[3.5 对话设计原则](#id-2.2、意图设计&对话设计-3.5对话设计原则)\n    *   2.1[任务型对话设计原则](#id-2.2、意图设计&对话设计-任务型对话设计原则)\n    *   2.2[· 设计对话脚本需要关注的点：](#id-2.2、意图设计&对话设计-·设计对话脚本需要关注的点：)\n    *   2.3[修复对话设计原则](#id-2.2、意图设计&对话设计-修复对话设计原则)\n    *   2.4[谷歌语音交互设计走查表](#id-2.2、意图设计&对话设计-谷歌语音交互设计走查表)\n\n3.4 语音交互框架、意图设计\n---------------\n\n· **四种语音交互模式**：\n\n1.  单轮交互：指智能语音助手被唤醒后只能完成一项任务，不管是否完成了任务，智能语音助手都会进入休眠状态，用户要继续使用智能重新唤醒它。绝大部分的智能语音助手和语音任务都属于单轮。\n2.  多轮交互：一些相对复杂的语音任务很难一句话说清楚，多轮对话指不用多次唤醒，双方可以通过多轮交流的方式完成一项任务，当任务完成后会自动进入休眠状态。多轮交互的缺点在于，智能语音助手在播报时麦克风处于关闭，要播报完才会打开麦克风聆听用户的声音（不能中途插话），除非再次唤醒，但再次唤醒就会将前面几轮的对话过程清空。\n3.  持续监听：指一旦唤醒后，智能语音助手就会把麦克风一直打开，用户可以一直说。持续监听依然存在问题，假设上一轮对话未结束，这时智能语音助手听到其他人说的话，会误以为时新的语音任务，就会直接结束上一轮并播报新的内容或停止播报。\n4.  全双工语音交互：拥有更强的抗噪能力和上下文理解能力，不会像持续监听一样容易被噪声打断整个对话过程。可以理解每一句话是否跟当前任务有关，并猜测当前任务的下一轮对话是什么，做到真正的“边听边说”。\n\n· **四种“唤醒+识别”方式**：在语音交互设计时应该根据它们的优劣势进行选择并综合使用。\n\n1.  “唤醒+在线意图识别”：在线意图识别的好处是云端有较强的算力支持将语音转换成文字和自然语言进行理解，弊端是任何操作都要云端处理，一旦信号不好，网络延迟变长，就会影响体验。\n2.  “唤醒+离线意图识别”：离线意图识别就是为了解决信号不好导致指令无法执行的问题，一般离线意图识别主要服务于常用的简单指令。\n3.  “免唤醒”：免唤醒也用了唤醒词技术，只不过把默认唤醒词改为了指令，新的唤醒词被命中后会直接执行相关指令。但不能把所有指令设置为免唤醒。\n4.  “one-shot”：也被称为“唤醒连说”技术，意思是“唤醒词+意图识别”一体化，支持用户在说出唤醒词后不停顿，立刻说出后续需求。\n\n· **语音交互状态设计**：整个语音交互框架会围绕各种语音状态进行设计，但仅靠声音的反馈用户很难知道现在交互流程处于哪个状态，对用户来说体验不好，因此在设计语音交互框架时需要考虑更全面。\n\n#### 唤醒状态\n\n· 设计唤醒状态前需要考虑当前设备采用的是那种语音交互方式（包括前述的四种语音交互模式与四种“唤醒+识别”方式），还需要考虑该设备使用的是近场语音交互还是远场语音交互。近场语音交互：指人距离机器不超过30cm，一般近场会通过按键或唤醒词的方式唤醒智能语音助手，由于设备就在眼前，可以通过视觉反馈的方式告知用户已被唤醒。远场语音交互：指人距离机器0.3~5m，由于用户距离设备较远，可能看不清当前设备的状态，因此需要通过听觉反馈告知用户是否被唤醒。\n\n#### 聆听状态\n\n· 在唤醒状态之后，具体分为等待用户响应状态和ASR状态。前者为等待用户说话的过程，后者为将用户说的话自动转成文字的过程。\n\n· 等待用户响应状态需要设置一个时间上限，如果用户一直不说话，到达时间上限后会自动退出或发起二次询问，然后进入下一轮的等待状态。时间不是越长越好，如果没有很好的抗噪能力，可能会突然执行无关的指令，影响用户体验。\n\n· 在单轮交互和多轮交互模式下，亚马逊的智能音箱Echo设置的等待时间上限为8s，8s内如果一直没有说话Echo会二次寻味，再不说话就会自动休眠。持续监听与全双工语音交互的设计相对复杂，等待用户响应时间分为初次唤醒聆听、二次询问、持续聆听，建议初次唤醒聆听与二次询问的等待时间上限设置为8s，而持续聆听是指上一轮对话结束后的等待时间，用户随时可能发起新一轮语音任务，所以建议设置长一些（20~30s）。\n\n#### 网络等待状态\n\n· 绝大部分语音交互的识别和处理都在云端进行，返回语音结果需要一段时间，因此网络等待状态必须反馈给用户，因为用户不知道该状态何时会结束。\n\n#### 语音播报状态\n\n· 不同产品在处理语音播报状态方面有着不一样的反馈设计，比如呼吸灯效、动态表情、直接显示播报的文字内容等。还要考虑到是否会对用户产生干扰（驾驶时占用视觉通道等）。\n\n#### 长连接通信状态\n\n· 持续监听和全双工依赖长连接通信质量，即指客户端和云端保持一段时间的通信，如果长连接通信质量时好时坏，就会导致云端接收到的信息缺失和意图识别有误。如果不将长连接通信状态的通信质量突出显示，则当因为通信问题导致意图识别不准确时，用户就会认为是智能语音助手的问题。建议在设计这个状态时，可以优先考虑音效设计，比如加入微小的“滋滋滋”电流声，让用户知道当前的通话质量受到了干扰。\n\n#### 结束至默认状态\n\n· 任务结束或用户在规定的时间内没有说话，设备的麦克风停止拾音，语音交互到此结束。可以通过音箱的一系列动作（摄像头回正等）、动态表情等来表现。\n\n· 由于语音交互涉及的状态很多，因此设计师应该全局考虑如何通过一套设计覆盖所有的状态和场景。\n\n· 天猫精灵IN糖的体验设计师为了拉近用户和智能音箱的距离，用PAD（Pleasure - Arousal - Dominance，即愉悦度-唤醒度-优势度）情绪状态模型对天猫精灵IN糖进行人格化情绪引擎设计，并围绕语音交互语料、表情分组和语音技能屏显这三个要素，设计出一系列更自然、更符合用户对话语境的情绪表达。\n\n· **意图设计术语介绍**：计算机听懂人说话得益于意图识别和实体提取的能力，在设计语音意图之前，需要了解与意图设计相关的术语。\n\n*   _技能（Skill）_：可以简单理解为一个应用。David J. Major发现，大多数Alexa用户无法分辨亚马逊官方和第三方厂商开发的技能之间的区别，很有可能是因为每种技能都用了同一种声音播报，用户呼喊触发词会加深用户对该品牌的记忆，因此第三方应用更需要通过触发词及其他方式提升用户对该品牌的印象。\n*   _意图（Intent）_：可以简单理解为某个应用的功能或流程，主要满足用户的请求或目的。有些意图隶属于某项技能，如果用户脱离技能输入意图，则系统就无法理解并执行；有些意图可以忽略技能而直接执行，默认属于系统技能（比如查天气）。做语音交互更多的是在设计意图怎样被理解并执行相关操作。\n*   _词典（Dictionary）_：可以理解为某个领域内词汇的集合。有些词语会存在于不同的词典中，不同词典的调用也会影响意图的识别。比如“刘德华”“张学友”既属于“男歌星”这个词典，又属于“电影男演员”这个词典，当用户说“我要看刘德华的电影”时，匹配到的是“电影男演员”的词典；当用户说“我要听刘德华的歌”时，匹配到的是“男歌星”的词典；如果用户说“打开刘德华”，就不知道是要匹配哪个词典了（需要人为设计相关策略来匹配）。\n*   _词槽（Slot）和槽位_：词槽可以理解为一句话中所包含的参数是什么。槽位是指这句话里有多少个参数，它们直接决定系统能否匹配到正确的技能和意图。词槽和词典时强相关的。在设计前，需要了解清楚语音智能平台是否支持词槽状态选择（可选、必选）、是否具备泛化能力、槽位是否支持通配符。\n*   _泛化（Generalize）_：指同一个意图有不同的表达方式，泛化能力会直接影响系统能否听懂用户在说什么以及设计师的工作量，同时也反映出该平台的人工智能水平如何。当前大部分平台的泛化能力较弱，需要设计师源源不断地将不同的表达方式写入系统，不同的表达方式可以通过“无意义词”这个词槽来实现（类似百度AI平台上的“特征词”词槽）。词槽和槽位的设计也会影响泛化能力。\n*   _通配符（Wildcard Character）_：主要用来进行模糊搜索和匹配。在意图设计中，当缺少数据导致某些词典数据不全时，通配符能够直接简化制作词典的工作量。比如，“XXX”是一个通配符，在“视频播放”这个意图增加“我想看XXX电影”这个表达后，无论XXX是什么，都能打开视频应用搜索XXX电影。通配符使用一定要合理，用得越多，越会影响词槽和槽位的设计，导致系统识别意图时不知道如何对众多匹配到的意图进行排序。\n*   _实体（Entity）_：获取意图中的关键信息是通过实体提取实现的。实体提取是信息抽取、信息检索、机器翻译、问答系统等多种自然语言处理必不可少的组成部分。前述的词典、泛化和通配符都是为了让系统更好地提取出实体。\n*   Bot：可以简单理解为意图识别的执行方，是一个功能合集，包含了很多技能。\n\n· 决定你的产品能否听懂用户说的大部分内容，主要由智能语音平台决定，在做产品设计前，需要了解智能语音平台的以下7个方面：\n\n1.  了解智能语音平台的NLU能力如何，是否具备较好的泛化能力。NLU是每个智能语音平台的核心。一般来说计算机会通过文本分析和文本匹配两种方法实现意图识别。\n2.  了解系统的意图匹配规则是完全匹配还是模糊匹配。只支持词槽完全匹配的智能语音平台几乎没有任何泛化能力，这需要设计师考虑通过构建词典、词槽和槽位的方式实现意图泛化。如果智能语音平台支持词槽模糊匹配，说明系统采用了识别关键词的方式，对“请帮我把声音调高一点”的指令，能识别出“声音调高一点”分别属于操作对象、调整、状态三个词槽，而其他文字“请帮我把”将被忽略。\n3.  了解智能语音平台对语言的支持程度如何。不同的语言都不同的语法和特点，会影响到NLU。\n4.  了解智能语音平台的系统词典数量是否足够多、每个词典拥有的词汇量是否齐全。词典收集不完整的结果是系统很有可能不知道用户说的内容是什么意思。\n5.  了解智能语音平台是否支持客户端和服务端自定义参数的传输，类似5W1H这类场景化的参数如果不支持传输，那在设计时就只能考虑多轮对话的上下文，而不能结合当前的位置和时间等参数进行设计。尤其是带屏幕的语音设备，因为用户有可能说完一句话就直接操作屏幕，然后又继续语音对话，如果语音设备不知道用户在屏幕上进行什么操作，那智能语音平台就不知道用户整个使用流程是怎样的。\n6.  了解智能语音平台是否支持意图的自定义排序。意图匹配很可能匹配到多个意图，只是每个意图都有不同的匹配概率，最终系统只召回概率最大的意图，而意图应该根据当前的场景进行匹配，而不只是根据词槽。意图自定义排序很重要，因为它能根据特定参数匹配某些低概率的意图，实现场景化的理解。\n7.  了解智能语音平台是否支持声纹识别。一台设备多人使用，声纹识别可以区分当前使用者十四黑，有助于针对不同用户提供个性化回答。\n\n· 以“给带屏设备设计一款智能语音系统”为例，使用的智能语音平台不具备泛化能力，但可以自定义参数传输和意图自定义排序。设计内容分为系统全局设计和意图设计：\n\n1.  **系统全局设计**：\n    \n    1.  以多种形式告知用户系统暂时无法理解用户的语义，比如“抱歉，目前还不能理解你的意思”。这种兜底策略成本最低，但出现频率过高，会让用户觉得产品没什么用，很不智能。\n    2.  将听不懂的语句传给第三方搜索功能。提取用户输入的关键词到搜索网站上找答案，但是答案过多，导致用户操作成本有点高。\n    3.  将听不懂的语句传给第三方闲聊机器人。闲聊机器人需要第三方API支持，成本最高，但效果也是最好的，让产品看起来更人性化。\n    4.  将听不懂的语句传给Q&A。根据目标人群和使用场景建立一套问答系统，比如驾驶场景可能问的更多的是关于如何驾驶的，家里的智能音箱问的最多的是小朋友的十万个为什么。可以通过“为什么”“怎么”等关键词识别并匹配相应的Q&A。\n    \n    1.  词汇的覆盖面决定了词典质量，词汇量越多越好。\n    2.  是否考虑动态更新，比如名人、视频、音乐等都需要支持动态更新。\n    3.  该词汇是否有同义词，考虑其他常用叫法。\n    4.  该词汇是否是多音字，是否会有常见的错误叫法。\n    \n    1.  保持互动语言简短，避免重复的短语。\n    2.  写出人们是如何交谈的，而不是如何阅读和写作的。\n    3.  当需要用户提供信息时，给出相应的指示。\n    4.  不要假设用户知道该做什么。\n    5.  问问题时一次只问一个问题。\n    6.  在让用户做选择时，一次提供不超过三个选项。\n    7.  学会使用话轮转换（Turn-taking），指会话中说话人和听话人角色的不断相互变换。若缺少有效的轮回，就有可能出现对话的双方同事说话或对话内容不同步并且难以被理解的情况。\n    8.  对话中的所有元素应该可以被绑定在一起，成为简单的一句话，这些元素是意图设计中最重要的参数。\n\n1.  赋予产品一个固定的人物形象。首先明确我们的用户群体，再根据用户群体的画像设计一个虚拟角色，对角色进行描述，包括采用的音色。\n2.  考虑设计产品的目的是什么、将为用户提供哪些技能（应用）、这些技能的目的是什么、用户为什么要使用它、用户通过这些技能能做什么和不能做什么、用户可以用哪些方式调用该技能，以及产品将会应用在哪个垂直领域。对自己提供的技能进行先后排序。\n3.  建立合理的兜底方案，即当语音完全匹配不上意图时提供的最后解决方案。兜底方案有以下四种，它们之间是互斥的，可以通过语法识别、关键词匹配等方式建立置信度，从而选择合适的兜底方案——匹配上关键词后，可以交由Q&A模块或第三方搜索功能来解决；如果没匹配上关键词且语法分析没太大问题，则可以交由闲聊模块解决；如果问题很大，则告知用户“抱歉没理解”（大部分语句中语法有严重问题都是噪声导致的）。\n4.  查看智能语音平台是否提供了与技能相关的垂直领域官方词典，如果没有，考虑手动建立自己的词典。需要注意以下几点：\n5.  在场景的帮助下，可以更好地理解用户的意图。由于大部分设备都使用了开源的安卓系统，而且语音应用和其他应用相互独立，信息几乎不能传输，所以可以通过安卓官方的API获取栈顶应用信息，了解用户当前处于哪个应用中。如果用户当前使用的应用是由自己设计开发的，那么可以将用户的一系列操作流程及相关参数传输给服务器进行分析，这样有助于更好地判断用户的想法是什么，并前置最相关的意图。\n6.  可以使用脚本来帮助确认可能没考虑到的情况，撰写脚本需要考虑以下几点（可参看3.5节）：\n7.  将脚本转化为决策树，类似信息架构，通过决策树可以发现整个技能是否设计得不严谨，从而知道如何优化；还能帮助我们考虑任务的跳出机制问题，如果不允许用户跳出任务，则应该友好地告诉用户当前的情况或询问是否退出任务并进行新的任务。\n\n3.  **意图设计**：\n\n1.  意图设计并不是槽位越多越好，要根据实际情况而定，设计者在设计词槽和槽位时，可以结合当前语言的语法和词性一起考虑，比如每句话需要考虑主、谓、宾结构，还有各种名词、动词、副词、量词和形容词。\n2.  当智能语音平台泛化能力较弱时，可以考虑手动提升整体的泛化能力：将常用的表达方式抽离出来成为独立的词典，然后让每个意图都匹配该词典。\n3.  如果设计的是系统产品，应该考虑全局意图的设计，比如带屏智能音箱、投影仪都是由实体按键的，可以考虑通过语音命令的方式模拟按键操作，从而达到全局操作的目的。（所见即所得）\n\n· 完成整个全局设计和意图设计后，应该邀请用户进行实践和测试，用户可能会用我们意想不到的话术进行对话，从而可以尽可能地完善意图及对话设计。\n\n3.5 对话设计原则\n----------\n\n· 为用户解决问题、创建有温度的对话流程是智能交互平台设计师的愿景。\n\n· 设计对话前需要了解的事项：\n\n1.  考虑计算机的局限：在设计前要考虑技术的优势和不足。技术的局限性引入了人与人对话中不会发生的场景，这些局限性应该提前提示用户。另外，当语音系统还达不到很聪明、随意交流的程度时，就不应该让用户误认为它可以达到。\n2.  确定用户场景：为了实现个性化和场景化设计，可以通过技术手段获取用户定位、时间和用户身份（包括声纹、用户注册信息）等信息，在设计对话脚本前需要考虑以下几个与场景相关的问题：\n\n1.  Where：用户在哪里？所处的环境是怎样的？\n2.  What：用户正在做什么？\n3.  How：用户使用的是什么设备？\n4.  What：用户要完成什么任务？目标是什么？\n5.  Why：用户的期望和意图是什么？\n\n4.  明确要设计的技能是什么：不同类型的技能面向不同的用户群体和用户场景。所有的技能都可以分为：\n\n1.  播报型：为用户提供内容服务，例如音乐、新闻、百科、食谱、故事等；\n2.  指令型：在用户和生活服务之间建立一座桥梁，帮助用户解放双手，通过语音就能控制家居、发送短信、叫外卖等；\n3.  互动型：用户通过多轮对话的方式与设备交互，主要用于娱乐领域，如问答测试、情景探险、识图对话、听音唱歌等。\n\n6.  明确要设计的对话类型是什么：不同的技能对应着不同的对话类型，从应用场景的覆盖面看，对话类型可以分为开放域（Open-domain）和封闭域（Closed-domain）。开放域对话类型没有太多限定的主题或明确的目标，需要大量的知识库和复杂的模型，一般用于闲聊场景；封闭域对话类型通常会限定在一定场景之下，需要一个垂直领域建立的模型和知识图谱，对对话的质量要求更高，对错误的容忍度更低，一般用于任务、问答或娱乐场景。据此，对话类型主要分为以下四种（见表格）：\n7.  提前定义好智能助手的人物设定。\n8.  了解对话的关键因素：谷歌的设计师通过解构那些我们习以为常的自然对话中的规则和管理挖掘出一个VUI对话的关键因素：（语音交互设计指南 Actions on Google Design）\n\n1.  话轮转换（Turn-taking）：当轮到用户说话时，智能语音助手应该发出清晰的信号，例如音效提醒。用户说话时，智能语音助手也不要贸然强行打断。\n2.  对话线索（Treading）：对话中的对话线索可以帮助我们更容易地跟上对话的节奏。\n3.  利用语音固有的效率：人们经常使用较为简短的口头表达方式，我们基本上可以感知对话中的“言外之意”，而VUI中的隐喻则必须能够弥补人类语言中看似不合逻辑、非理性的部分。\n4.  预测不同的用户行为：人们会用不同的词语和说话方式去描述同样的事情，这取决于他们自己的情景语境和自己的经验产生的对VUI的预期，VUI需要支持这些差异。\n\n10.  遵循会话“合作原则”：美国语言哲学家格莱斯（Paul Grice）认为，在人们交际的过程中，对话双方似乎在有意无意地遵循着某个原则，以求有效地配合，从而完成交际任务。语音交互可以考虑遵循对话的“合作原则”进行设计（如下）。但实际语言交际中，人们并非总是遵循这个原则，格莱斯把这种表面上故意违反“合作原则”而产生的言外之意成为“特殊会话含义”，需要依赖特殊语境才能推导出来的含义。设计者在设计脚本时应尽量避免使用这种对话方式，避免用户理解不了。\n\n1.  量的准则：所说的话应该满足且不超出交际所需的信息量。\n2.  质的准则：不要说自知是虚假的和缺乏足够证据的话。\n3.  关系准则：所说的话要贴切，要与交谈目的和交谈内容有关系，不说不相干的话。\n4.  方式准则：所说的话要简洁明了，不要拐弯抹角产生歧义。\n\n12.  对话不存在“出错”的概念：逻辑和准确性不是万能法则，用户的任何请求都是有目的的，即使没有明确说出来。不管用户说了什么，都不要把它当成是一个错误来处理，而是要考虑把它转变为一个机会，用新的方式来处理，从而进行更顺畅、更自然的沟通。有助于把“错误”转换成对话交互中自然的一部分的方法如下：\n\n1.  不要把技术上的“出错”当作用户的错误。\n2.  为不同类型的“出错”提供对应的、适合的处理方式。\n3.  通过提供帮助来避免出错。\n4.  知道在什么情况下放弃。\n5.  使完成任务的路径更短，从而掩盖错误。\n\n对话类型\n\n含义\n\n特点\n\n目标\n\n对话类型\n\n含义\n\n特点\n\n目标\n\n1、任务类型\n\n指在特定条件下为带有明确目的的用户提供信息或服务\n\n设计起来比较复杂，非常依赖意图识别技术，通常使用意图识别+多轮对话+对接内容提供商的API和知识图谱\n\n用最短的对话轮次来完成用户的任务，把在对话中获取的信息转换成需要的参数\n\n2、问答类型\n\n问题也是一种任务，问答类型与任务类型的对话有一定的相似性  \n一般用于客服机器人上，能和用户进行基本沟通并自动回复用户有关产品或服务的相关问题\n\n意图设计非常简单，一般抓住关键词“为什么”和“是什么”即可，然后通过FAQ+对接内容提供商的API和知识图谱回答用户的问题\n\n用最短的对话轮次来回答用户的问题\n\n3、闲聊类型\n\n开放域类型，没有明确目的的对话，主要根据用户对话中出现的关键词进行回复\n\n不精确，不可控，机器的回复都在闲聊库，通过检索给出响应的回复\n\n对话轮次越多越好\n\n4、游戏/娱乐类型\n\n结合了任务类型与闲聊类型的特点，还要考虑游戏类型、趣味性等因素进行设计\n\n脚本分支多，游戏类型还需考虑故事线，设计起来比较复杂\n\n让用户放轻松\n\n· 设计脚本的目的是让用户理解对话的内容，帮助用户快速完成任务。如果对话过程中需要多轮对话，则脚本能引导用户给出够用的、正确的信息，然后执行用户希望完成的任务。\n\n· 一个好的脚本应该是站在人们如何交谈的视角进行设计的，而不是通过阅读和写作视角进行刻板设计的。\n\n#### 任务型对话设计原则\n\n#### · 设计对话脚本需要关注的点：  \n\n1.  **提升对话内容的多样性**：尝试在固定回答上加入不同的对白，比如用户调用技能的时候，可以考虑丰富多变的欢迎语，还可以考虑提供关于技能基本功能的提示，设计固定回复时可以通过同义词为答案增加变化，然后从这些答案里随机选择一个作为回复。\n2.  **尊重用户的时间**：尽量在短时间内将必要的回复信息表达出来。在交谈中，说得太多与说得太少一样表现得不合作，从用户角度出发，保持简短和最佳相关性有助于用户理解。\n3.  **保持文案的一致性**：在写脚本时保持语句中动词、名词搭配的语法一致性，以及用户、智能语音助手的称呼的一致性。（写文案技巧，能用“咱”时就不用“你”，拉近与用户的距离）\n4.  **减轻用户的认知负担**：在编写脚本时，尽量避免使用“科技术语”“专业词汇”“方言用语”等。通过一致的称谓来称呼同一个事物，帮助用户降低对同一事物的认知负担。\n5.  **逐步向用户获取信息**：用户在进行语音交互的时间里，通常无法将所有完成意图所需的关键参数说出来，此时应避免垄断对话，不要一口气提出所有问题，而要将问题分解成多个独立问题，一个一个地提问，引导出所有答案。\n6.  **尽量提供少于三个的选项**：如果选项过多，则为用户找出与输入预期匹配度最高的三个选项，列表中的第一项应与用户刚刚采取的操作最相关。\n7.  **不要假设用户会准确地把设想的对白表达出来**：虽然有“合作原则”，但是用户经常会提供比智能语音助手真正需要的更多的信息（过度回答），这时智能语音助手要能够获取这些回答，不需要再问很多问题；除此之外，还要包容多种说话风格，把用户可能会说的句子、短语和单词最大范围地呈现出来；还有一种情况是，用户在说话时突然改变主意或立刻更正，这时候用户会在正确的意图前加上“不”“要不还是算了”等短语，这种情况非常依赖语音交互系统的泛化能力，在意图和词槽设计上没有较好的解决方法。\n8.  **不要假设用户知道该怎么做或会发生什么**：不要猜测用户的意思，提供事实信息让用户自己做决策，当用户需要时给出提示；用户回答的顺序也可能和脚本流程设计的顺序不一致，需要考虑全部情况。\n9.  **在追问过程中为用户提供指导**：在设计多轮交互的追问句时，建议包含“当前情景”和“需要进行的操作或选项”，这样的追问句能为用户通过继续对话的线索，并指导用户下一步该说什么。\n10.  **避免用户进行复杂或带来高歧义的输入**：通过语音填写邮箱、密码和网址等，多音字、同音异义词的识别等，这些对计算机来说都是很复杂和高歧义的输入，要避免用户进行此类输入。\n11.  **针对重要请求，向用户发出显式确认；针对风险较低的请求，可以采用隐式确认方式**：确认是语音界面与用户沟通的一种方式，用于检查用户的问题、命令和回复是否被正确理解，可以保证对话的流畅度和准确度，让用户知道系统已经理解了自己的话。根据不同的情境和置信区间选择合适的确认方式——对于某些难以撤销的操作，采用**显示确认方式**较为合适，例如资金转账的最终确认和免责协议的确认，通常要与用于核实其提供的输入是否被正确地处理，或者请求用户允许操作，在得到用户确认之前不会执行后续操作；对于识别准确率为中到高，且潜在的负面影响较小时，不想过分打扰用户，采用**隐式确认方式**较为合适，VUI在回复中融入了用户话语中的关键信息，以表明VUI理解了用户说的话，优点是效率高，但缺点是出错时用户通常不知道如何让对话重回正轨。\n12.  **尽量少用语气助词**：常见的有疑问语气、祈使语气、感叹语气、肯定语气和停顿语气，目前TTS技术很难通过文字和语境将正确的预期表达出来，仍只能用平调朗读出语气助词，因此要谨慎使用。\n13.  **检查对话内容是否符合人物设定**：不同性格的人说的话的特征是不一样的。切勿用高人一等的口吻和用户说话。\n14.  **在引起用户负面情绪的关键点上加入情感化设计**：在设计对话时可以引入用户体验地图，在引起用户负面情绪的关键点上加入情感化设计或转移话题；撒娇也是一种能缓解用户情绪低落的好方法，比如在语音助手没理解用户输入的意图时，不要说“我不知道你在说什么”，而是说“换一个问题嘛，不要为难人家好不好”。\n15.  **在合适的场景说合适的话**：设计对话时要结合用户对话时的时间和定位信息进行考虑。\n16.  **考虑多种交互的方式**：除了语音，还可以结合结构化的文字和图像进行表达，复杂的内容需要播放很长时间的语音，可以采用视觉可视化的方式让用户能够快速看完。\n17.  优**先撰写愉悦脚本**：愉悦脚本指的是可以完成任务并且完整、简单的对话脚本，从开始到结束，中间没有任何分支。完成愉悦脚本的撰写后，在考虑其他需要语音助手引导的分支或路线。\n\n· 设计师不能只将精力集中于所谓的“理想流程”和“预设逻辑”中，应该考虑如何解决对话过程中出现的错误，例如设计相关的对白告知用户当前的状况是什么、提供修复错误的说明引导，是整个人机对话流程基于对话流和“合作原则”重回正轨。修复对话的关键在于学会站在机器的视角来看待问题。\n\n· 导致对话失败的情况有：  \n\n1.  计算机没有获取到任何输入。可能是确实没有输入，也可能是系统没有检测到，获取信息超时。（无ASR）\n2.  虽然计算机获取到了信息，但是却不能识别或解析，这种情况可能是有背景噪音或多个用户一起说话。（有ASR但有误）\n3.  识别到了用户的输入信息，但系统不知道如何回应和处理。（NLP兜底）\n4.  错误地识别了用户输入的信息。（NLP有误）\n\n#### 修复对话设计原则\n\n· 针对上述的四种对话失败情况：  \n\n1.  当用户超时输入或无输入时，可以再次提示一遍刚才的问题，用较为简洁的句式变体对原有问题进行二次询问。\n2.  理解了内容跟但不能提供帮助，又具体分为四种情况：\n\n1.  不支持用户要求的功能，可以说“我目前还不能帮助你做XX，不过我可以帮你XXX”，告诉用户该功能不可用。设计师需要提前计划要做的功能的意图，然后跟踪用户何时请求不支持的功能，更好地确定功能的优先级。\n2.  用户说法不清导致意图识别信息缺失，通过询问引导用户再说一遍，完成必要槽位信息的补充。在询问时建议列举相关内容供用户参考，比如“一共找到两个XXX，请问您要打开第一个还是第二个？”\n3.  因阈值上下限导致语音助手不能提供完整的帮助（比如音量最高100%，用户还想再提高音量），需要告诉用户当前状况并推荐相关操作。\n4.  明确知道用户的指令是错误的，需要引导用户重回正轨或恢复默认状态。设计师应该提前想到用户的常用说法，并在意图设计和回复上体现出来，比如空调有1-4档，用户觉得4档开冷于是说“关闭4档”，但风量档位意图只有切换没有挂你的概念，这时应该回复“风量档位以为您调回1档”。\n\n4.  因各种原因导致语音识别不清晰，系统不知道用户说了什么，可以对内容进行语法分析和关键字匹配，匹配上关键字就可以交由FAQ模块或第三方搜索模块来解决，如果没匹配上关键字且语法分析问题较大，则通过兜底。\n5.  用户在多轮对话过程中没按照脚本走导致理解出问题，可以在多轮交互过程中提示用户目前支持的说法是什么，从而限制多轮交互中用户的说法；或者询问用户是否退出当前多轮并进入新一轮对话。\n\n#### 谷歌语音交互设计走查表\n\n· 包括问候语与结束语、设计自然流畅的对话、人物画像、对话修复/容错等。\n\n![](/download/thumbnails/105255115/1.png?version=1&modificationDate=1687657054792&api=v2)![](/download/attachments/105255115/2.png?version=1&modificationDate=1687657059330&api=v2)![](/download/attachments/105255115/3.png?version=1&modificationDate=1687657062032&api=v2)![](/download/thumbnails/105255115/4.png?version=1&modificationDate=1687657064288&api=v2)\n\n  \n\n[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)\n\n[Configure buttons visibility](/users/tfac-settings.action)"
}