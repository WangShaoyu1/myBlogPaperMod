{
	"title": "看了此文不要说你还不会微调大模型",
	"author": "王宇",
	"publishTime": "八月21,2023",
	"readTime": "12s",
	"tags": "[\"大模型系列\"]",
	"description": "大模型系列",
	"article": "*   1 [一、下载工程和环境准备](#id-看了此文不要说你还不会微调大模型-一、下载工程和环境准备)\n    *   1.1[1.1 ChatGLM-6B是什么？](#id-看了此文不要说你还不会微调大模型-1.1ChatGLM-6B是什么？)\n    *   1.2[1.2 安装虚拟的python环境](#id-看了此文不要说你还不会微调大模型-1.2安装虚拟的python环境)\n    *   1.3[1.3 克隆代码和安装依赖](#id-看了此文不要说你还不会微调大模型-1.3克隆代码和安装依赖)\n    *   1.4[1.4 运行](#id-看了此文不要说你还不会微调大模型-1.4运行)\n*   2[二、微调大模型](#id-看了此文不要说你还不会微调大模型-二、微调大模型)\n    *   2.1[2.1 整理数据集(官方数据集)](#id-看了此文不要说你还不会微调大模型-2.1整理数据集\\(官方数据集\\))\n    *   2.2[2.2 调整参数](#id-看了此文不要说你还不会微调大模型-2.2调整参数)\n    *   2.3[2.3 开始训练](#id-看了此文不要说你还不会微调大模型-2.3开始训练) \n    *   2.4[2.4 微调后结果](#id-看了此文不要说你还不会微调大模型-2.4微调后结果)\n\n一、下载工程和环境准备\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\n### 1.1 ChatGLM-6B是什么？\n\nChatGLM-6B是清华大学知识工程和数据挖掘小组（Knowledge Engineering Group (KEG) & Data Mining at Tsinghua University）发布的一个开源的对话机器人。根据官方介绍，这是一个千亿参数规模的中英文语言模型。并且对中文做了优化。本次开源的版本是其60亿参数的小规模版本，约60亿参数，本地部署仅需要6GB显存。\n\n### 1.2 安装虚拟的python环境\n\nChatGLM-6B 代码中有一些python3.7支持的语法，所以要有python3.7+ 的环境。我们使用conda来管理python环境  \nconda分为anaconda和miniconda。anaconda是包含一些常用包的版本，miniconda则是精简版.本文中我们将使用anaconda  \n  \n\n### 1.3 克隆代码和安装依赖\n\n[?](#)\n\n`git clone https:``//github.com/THUDM/ChatGLM-6B.git`\n\n`//加载模型到本地`\n\n`git clone https:``//huggingface.co/THUDM/chatglm-6b`\n\n`# 新建chatglm环境`\n\n`conda create -n chatglm python=``3.8`\n\n`# 激活chatglm环境`\n\n`conda activate chatglm`\n\n`nvidia-smi`\n\n`# 根据上一步找到的安装指令进行安装：`\n\n`pip install torch==``1.12``.``1``+cu113 torchvision==``0.13``.``1``+cu113 torchaudio==``0.12``.``1` `--extra-index-url https:``//download.pytorch.org/whl/cu113`\n\n`# 安装gradio用于启动图形化web界面`\n\n`pip install gradio`\n\n`# 安装运行依赖`\n\n`pip install -r requirement.txt`\n\n`import` `torch`\n\n`torch.cuda.is_available()  ## 输出应该是True`\n\n  \n\n### 1.4 运行\n\n![](/download/attachments/105279095/image2023-8-21_16-7-7.png?version=1&modificationDate=1692605228001&api=v2)\n\n  \n\n二、微调大模型\n-------\n\n### 2.1 整理数据集(官方数据集)\n\n从 [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing) 或者 [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) 下载处理好的 ADGEN 数据集，将解压后的 `AdvertiseGen` 目录放到本目录下。\n\n### 2.2 调整参数\n\n![](/download/attachments/105279095/image2023-8-21_16-9-7.png?version=1&modificationDate=1692605348136&api=v2)\n\n  \n\n### 2.3 开始训练 \n\n![](/download/attachments/105279095/image2023-8-21_16-13-8.png?version=1&modificationDate=1692605588954&api=v2)\n\n出现该结果则表示训练完毕。\n\n### 2.4 微调后结果\n\n**![](/download/attachments/105279095/image2023-8-21_16-14-13.png?version=1&modificationDate=1692605653219&api=v2)**\n\n![](/download/attachments/105279095/image2023-8-21_16-14-30.png?version=1&modificationDate=1692605670733&api=v2)\n\n  \n\n[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)\n\n[Configure buttons visibility](/users/tfac-settings.action)"
}