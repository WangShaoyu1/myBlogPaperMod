{
	"title": "NVIDIAChatWithRTXDemo测评、理解、拓展",
	"author": "王宇",
	"publishTime": "三月21,2024",
	"readTime": "12s",
	"tags": "[\"GPT相关\"]",
	"description": "GPT相关",
	"article": "1\\. 安装\n======\n\n类别\n\n详情\n\n备注\n\n下载地址\n\n[https://www.nvidia.cn/ai-on-rtx/chat-with-rtx-generative-ai/](https://www.nvidia.cn/ai-on-rtx/chat-with-rtx-generative-ai/)\n\n  \n\n  \n\n  \n\n  \n\n系统要求\n\n平台：Windows\n\n  \n\nGPU：NVIDIA GeForce® RTX 30 或 40 系列 GPU 或配备至少 8GB VRAM 的 NVIDIA RTX™ Ampere 或 Ada Generation GPU\n\n  \n\nRAM：16GB 或更高\n\n  \n\n操作系统：Windows 11\n\n  \n\n驱动：535.11 或更新版本驱动\n\n  \n\n文件大小：35 GB\n\n  \n\n参考资料\n\n[https://blogs.nvidia.cn/2024/01/08/generative-ai-rtx-pcs-and-workstations/](https://blogs.nvidia.cn/2024/01/08/generative-ai-rtx-pcs-and-workstations/)\n\n  \n\n2\\. 试用Demo\n==========\n\n        2024.1.8，NVIDIA 发布由 TRT-LLM 加速的 Chat with RTX 技术 Demo，让 AI 爱好者能与他们的笔记、文档和其他内容进行交互。\n\n3\\. 测评\n======\n\n3.1. 测评数据准备\n-----------\n\n       系统默认有两个大模型：Mistral 7B int4、Llama2 13B int4，对中文的支持程度较差。测评数据做了一定程度的变通，将知识库、问题翻译为英文，每回合的回答也是英文，这对判断其答案是否准确带来了一定的识别困难。同时对于翻译的准确性也要打一个折扣。\n\n**先将测试用例进行分类：**\n\n \n\n类别\n\n个数\n\nMistral 7B\n\n错误数\n\n百分百\n\nLlama2 13B\n\n错误数\n\n百分百\n\n备注\n\n类别\n\n个数\n\nMistral 7B\n\n错误数\n\n百分百\n\nLlama2 13B\n\n错误数\n\n百分百\n\n备注\n\n个人属性\n\n15\n\n  \n\n7\n\n9.2%\n\n  \n\n2\n\n5.1%\n\n  \n\n集团介绍\n\n16\n\n  \n\n14\n\n**18.4%**\n\n  \n\n5\n\n**12.8%**\n\n  \n\n影子介绍\n\n12\n\n  \n\n9\n\n**11.8%**\n\n  \n\n5\n\n**12.8%**\n\n  \n\n产品介绍\n\n19\n\n  \n\n15\n\n**19.7%**\n\n  \n\n10\n\n**25.6%**\n\n  \n\n解决方案\n\n12\n\n  \n\n8\n\n10.5%\n\n  \n\n4\n\n10.3%\n\n  \n\n秀博+饲料\n\n8\n\n  \n\n7\n\n9.2%\n\n  \n\n3\n\n7.7%\n\n  \n\n领导介绍\n\n6\n\n  \n\n3\n\n3.9%\n\n  \n\n2\n\n5.1%\n\n  \n\n闲聊\n\n15\n\n  \n\n7\n\n9.2%\n\n  \n\n4\n\n10.3%\n\n  \n\n常识问答\n\n17\n\n  \n\n6\n\n7.9%\n\n  \n\n4\n\n10.3%\n\n  \n\n  \n\n  \n\n  \n\n76\n\n100.0%\n\n  \n\n39\n\n100.0%\n\n  \n\n### 3.1.1. Mistral 7B int4\n\n**Mistral 7B**\n\n数据\n\n详情\n\n  \n\n  \n\n  \n\n  \n\n知识库\n\n[en\\_spring\\_festival\\_1\\_105\\_translate\\_20240223121931.doc](/download/attachments/119679388/en_spring_festival_1_105_translate_20240223121931.doc?version=1&modificationDate=1710120491714&api=v2)\n\n  \n\n  \n\n  \n\n  \n\n测评结果\n\n[春节知识库.xlsx](/download/attachments/119679388/%E6%98%A5%E8%8A%82%E7%9F%A5%E8%AF%86%E5%BA%93.xlsx?version=3&modificationDate=1710572488814&api=v2)\n\n\"测试结果-Mistral 7B\"页签\n\n问题总数\n\n正确\n\n错误\n\n部分对\n\n120\n\n31\n\n76\n\n13\n\n  \n\n25.8%\n\n63.3%\n\n10.8%\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n### 3.1.2. Llama2 13B int4\n\nLlama2 13B\n\n数据\n\n详情\n\n  \n\n  \n\n  \n\n  \n\n知识库\n\n[en\\_spring\\_festival\\_1\\_105\\_translate\\_20240223121931.doc](/download/attachments/119679388/en_spring_festival_1_105_translate_20240223121931.doc?version=1&modificationDate=1710120491714&api=v2)\n\n  \n\n  \n\n  \n\n  \n\n测评结果\n\n[春节知识库.xlsx](/download/attachments/119679388/%E6%98%A5%E8%8A%82%E7%9F%A5%E8%AF%86%E5%BA%93.xlsx?version=3&modificationDate=1710572488814&api=v2)\n\n“测试结果-Llama2 13B”页签\n\n问题总数\n\n正确\n\n错误\n\n部分对\n\n120\n\n58\n\n39\n\n23\n\n  \n\n48.3%\n\n32.5%\n\n19.2%\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n3.2. 分析\n-------\n\n        当前项目是一个演示Demo版本，实现的是于自己电脑上的文件进行AI对话，利用检索增强技术（RAG）、TensorRT-LLM和RTRX加速，基于项目[https://github.com/NVIDIA/trt-llm-rag-windows](https://github.com/NVIDIA/trt-llm-rag-windows) 构建而成\n\n### 3.2.1. 什么是RAG\n\n 概念版：【大型语言模型（LLM）的检索增强生成（RAG）旨在通过在推理过程中**利用外部数据存储**来提高预测的准确性。这种方法构建了一个包含上下文、历史数据和最新或相关知识的综合提示】\n\n分析：这是一种有效利用大预言模型LLM与我们专有数据之间的桥梁，一般的，要解决这个问题，有两个主流的思路，一个是微调（Fine-Tuning）和检索增强生成（Retrieval-Augmented Generation，简称RAG)，两种方法各有千秋。\n\n从问题出发：**让大模型适应特定的行业或私有信息**\n\n方案对比：\n\n  \n\n  \n\n备注\n\n  \n\n  \n\n备注\n\n  \n\n  \n\n概念\n\n**大模型LLM**\n\n        大模型LLM通过训练大量的数据来获得广泛的通用知识，这些知识被存储在神经网络的权重（参数记忆）中。但是，当需要LLM生成需要训练数据之外的知识（如最新的、专有或者特定领域的信息）就有可能导致事实上的不准确（“幻觉”）。\n\n**专有数据**\n\n        不在互联网的数据、行业独有数据、企业数据、个人非公开数据等等\n\n  \n\n【方法】\n\n  \n\n  \n\n*   微调\n\n1.  消耗大量计算资源\n2.  花费高\n3.  需技术高手操盘\n\n  \n\n*   检索增强生成\n\n亮点在于：将生成内容的模型（即是LLM）和一个能进行信息检索的模块结合在一起，这样，模型就可以直接从一个更新的外部知识源那里获得所需信息了\n\n1.  基本工作流如下：![](https://pic1.zhimg.com/v2-8e9aec4aa1da405f08a57b69b6e16d94_r.jpg)\n2.  检索、增强、生成。\n\n  \n\n  \n\n  \n\n4\\. 拓展~~~增加其他大模型\n================\n\n  \n\n  \n\n  \n\n5\\. 思考\n======\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)\n\n[Configure buttons visibility](/users/tfac-settings.action)"
}