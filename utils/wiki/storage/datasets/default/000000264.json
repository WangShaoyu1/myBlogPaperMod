{
	"title": "内部知识库GPT可以替我们做应用瓶颈的验证",
	"author": "王宇",
	"publishTime": "七月18,2023",
	"readTime": "12s",
	"tags": "[\"唐玮\"]",
	"description": "唐玮",
	"article": "企业内部智能知识库应用开发项目 可以替我们验证与收集目前大模型应用在虚拟人身上的**瓶颈**有哪些。识别瓶颈后，即可以更客观的探讨技术方案。\n----------------------------------------------------------------------\n\n#### 一、我们的客户是谁？我们解决他们的什么问题？\n\n1.  按当前的业务：我们的第一个客户是万得厨，我们辅助万得厨，完成万得厨“人人都有专享厨师”的使命。\n\n1.  万得厨宣传场景。虚拟人与客户沟通，宣传万得厨，或许可担任一些品牌宣传等工作\n2.  万得厨烹饪场景。推荐食谱、指导食材处理、推荐烹饪方案等\n\n#### 二、我们现在及未来的业务有哪些？\n\n1.  当前辅助万得厨。\n2.  未来要让人能够把自己的技能赋予给虚拟人，然后让虚拟人服务于他人。\n\n#### 三、大模型能够给我们的业务带来什么？（换句话：大模型在哪些方面，相比我们现有能力能够更好的解决问题？）\n\n1.  辅助食材处理。因现在还没有此类可以直接调用的技能。\n2.  FAQ工作量减少。通过向量数据库等技术可以实现接入万得厨APP的食谱数据库，或者其他的营养数据库，实现本地知识库的对话。这里不需要去编写大量的相似问，因大模型本身即具备一定的推理能力。大模型依据的是推理而不是相似度，所以不需要写相似问，相比工作量及工作时间就减少。\n3.  用户个性化。通过在prompt中插入食客信息，提供食客定制化的语音风格、个性推荐、历史记忆对话（例如：虚拟男/女友聊天软件replike，通过增加历史记忆的功能，让大模型能够基于这些历史记忆聊天）\n4.  多轮对话。大模型具备多轮对话能力。\n5.  让生产型虚拟人能够更简单的获取能力。例如相比用FAQ库写相似问的办法，大模型大大减轻工作量，减少了时间。\n\n#### 四、大模型要能够让我们部署到产品中至少得达成什么条件？\n\n1.  （重要）本地/云端计算资源。资源的成本、效率需要综合考虑\n\n1.  微调训练需要耗费GPU资源\n2.  用户调用需要消耗资源\n\n3.  （重要）大模型从输入到输出的整体运算速度。以万得厨为例，假设大模型部署于云端，因用户是和虚拟人交互，所以从输入到输出，可能必须得控制在1S、0.5S以内，甚至更短的时间。否则用户体验会很差。\n\n1.  需要评估大模型自身的推理速度和推理需要耗费的资源\n2.  需要评估使用向量数据库时的计算效率\n3.  云端传输的时间效率\n\n5.  大模型接入PTA、FTT平台可能需进行沟通与工作。大模型需要和已有平台能力进行融合\n6.  token数量。即能够输入的prompt长度。主要用于知识拼接。目前以chatGLM能够支持最长长度32K个字来看是能够满足当前烹饪场景的。\n\n#### 五、希望在搭建企业内部智能知识库GPT应用时，可以附带一些调研、测试、数据收集与验证工作：\n\n希望能够在开发的时候埋好数据点，做一些数据的收集，最好能够生成一些报告。\n\n1.  **资源耗费**\n\n1.  监测与收集每次用户调用时需要耗费的资源数量。\n2.  多用户调用时需要耗费的资源数量与服务器压力。\n3.  微调资源耗费、时间耗费。\n4.  微调模型时测试和生产环境如何稳定切换的方案\n\n3.  **运算速度**\n\n1.  大模型推理速度、耗费的资源\n2.  使用向量数据库计算相似度时的速度、资源耗费\n3.  云端传输的时间效率\n\n5.  **推理能力**\n\n1.  需要评估推理能力是否满足虚拟人场景的推理需求。\n\n7.  **对接API的能力（即GPT可以直接操控炉端或其他能力的能力）**\n\n  \n\n[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)\n\n[Configure buttons visibility](/users/tfac-settings.action)"
}