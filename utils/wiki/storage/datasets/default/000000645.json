{
	"title": "RAG数据处理实践经验分享",
	"author": "王宇",
	"publishTime": "六月27,2024",
	"readTime": "12s",
	"tags": "[\"知识插件\"]",
	"description": "知识插件",
	"article": "*   1[1\\. RAG数据处理的目标](#RAG数据处理实践经验分享-RAG数据处理的目标)\n*   2[2\\. 数据收集](#RAG数据处理实践经验分享-数据收集)\n    *   2.1[2.1. 数据收集领域判断](#RAG数据处理实践经验分享-数据收集领域判断)\n        *   2.1.1[2.1.1. 确定领域知识体系](#RAG数据处理实践经验分享-确定领域知识体系)\n        *   2.1.2[2.1.2. 确定知识来源](#RAG数据处理实践经验分享-确定知识来源)\n    *   2.2[2.2. 收集数据](#RAG数据处理实践经验分享-收集数据)\n*   3[3\\. 数据处理](#RAG数据处理实践经验分享-数据处理)\n    *   3.1[3.1. 标题标注](#RAG数据处理实践经验分享-标题标注)\n        *   3.1.1[3.1.1. 程序识别](#RAG数据处理实践经验分享-程序识别)\n        *   3.1.2[3.1.2. 人工审核](#RAG数据处理实践经验分享-人工审核)\n        *   3.1.3[3.1.3. 通配符标注](#RAG数据处理实践经验分享-通配符标注)\n        *   3.1.4[3.1.4. 其他情况](#RAG数据处理实践经验分享-其他情况)\n    *   3.2[3.2. 文本清洗](#RAG数据处理实践经验分享-文本清洗)\n        *   3.2.1[3.2.1. 目录、练习题、致谢、参考文献等大块文本清除](#RAG数据处理实践经验分享-目录、练习题、致谢、参考文献等大块文本清除)\n        *   3.2.2[3.2.2. 页尾页码删除](#RAG数据处理实践经验分享-页尾页码删除)\n        *   3.2.3[3.2.3. 引用、续表等特定文本删除](#RAG数据处理实践经验分享-引用、续表等特定文本删除)\n    *   3.3[3.3. 表格清洗](#RAG数据处理实践经验分享-表格清洗)\n        *   3.3.1[3.3.1. 表格转换](#RAG数据处理实践经验分享-表格转换)\n        *   3.3.2[3.3.2. 表格进一步清洗](#RAG数据处理实践经验分享-表格进一步清洗)\n        *   3.3.3[3.3.3. 表引用删除](#RAG数据处理实践经验分享-表引用删除)\n    *   3.4[3.4. 图片清洗](#RAG数据处理实践经验分享-图片清洗)\n        *   3.4.1[3.4.1. 图片内容识别为文本](#RAG数据处理实践经验分享-图片内容识别为文本)\n        *   3.4.2[3.4.2. 图片引用](#RAG数据处理实践经验分享-图片引用)\n    *   3.5[3.5. 公式清洗](#RAG数据处理实践经验分享-公式清洗)\n        *   3.5.1[3.5.1. 图片转latex](#RAG数据处理实践经验分享-图片转latex)\n\n1\\. RAG数据处理的目标\n==============\n\nRAG数据处理的目标是为大模型提供优质的、干净的、精简的可参考数据。\n\n**理想数据：**\n\n1.  优质：找到唯一的、最全、最新、全先进的对应领域知识。\n2.  干净：要清除无关数据。文本读起来逻辑通顺、无废字、无无用的符号。满足“未来第三人原则”。\n3.  精简：最好是陈述句，直接描述结论和论据。无过多无用的语气词。\n\n实际操作中，优质和干净是尽量满足。精简一般书籍都做的比较好。\n\n2\\. 数据收集\n========\n\n2.1. 数据收集领域判断\n-------------\n\n找到优质的领域知识的第一步是确定数据收集的范围和目标。从知识“唯一性”的优质数据目标出发，我们可以以这样一个策略执行：**先确定领域知识的知识体系，然后从体系出发找到每一个分支，最新最权威的数据源**。\n\n以养猪业为例，养猪领域的知识是很大的，同时描述猪的知识也肯定有很多本书。我们要找到哪些知识？到底要哪些书？从“全国图书馆参考联盟”网检索“家畜育种学”，就能找到60本左右的书籍。毫无疑问，我们无需对这60本全部收集和清洗。我们只需要选择一本最合适的书籍。\n\n### 2.1.1. 确定领域知识体系\n\n确定领域知识体系，可以让我们避免知识的缺漏。同时根据知识体系，可以引导我们去寻找更针对性的书籍。要找到优质的领域知识，可以从大学专业的培养计划、专业证书的考试范围等，找到一个知识尽量互相不重合、全面的领域知识体系。\n\n![](/download/attachments/129175181/image2024-6-27_9-38-59.png?version=1&modificationDate=1719452339206&api=v2)\n\n### 2.1.2. 确定知识来源\n\n从知识结构的每个分支里，找到尽量新的、权威的、被认可的书籍或者网站数据。\n\n1.  找知名厉害的学校采购的教材\n2.  专业机构指定的教材\n3.  尽量找到最新版本\n\n![](/download/attachments/129175181/image2024-6-27_9-39-50.png?version=1&modificationDate=1719452390241&api=v2)![](/download/attachments/129175181/image2024-6-27_9-43-52.png?version=1&modificationDate=1719452632701&api=v2)\n\n2.2. 收集数据\n---------\n\n以下是一部分常用的数据来源\n\n1.  **商业服务**\n    1.  **淘宝可定制的pdf书商（淘宝目前只发现有一家店具备定制能力）**\n2.  培训机构\n    1.  兽医培训机构\n    2.  营养师培训机构\n3.  学校\n    1.  校内二手交易群\n    2.  校内悬赏群\n4.  网上公开的图书馆\n    1.  [libgenesis.net](https://libgenesis.net/)\n    2.  [libgenesis.net (z-library.se)](https://zh.z-library.se/)\n5.  网站\n    1.  兽医类官网\n    2.  注册营养师官网\n\n  \n\n3\\. 数据处理\n========\n\n数据处理的目标主要是干净。实际操作上涉及以下的内容\n\n1.  标题标注\n2.  文本清洗\n3.  表格清洗\n4.  图片清洗\n5.  公式清洗\n\n目前能找到的书籍，几乎是PDF版。需要先将PDF转换成word，才能进行进一步数据处理，这一步使用的技术是OCR。经过试用和对比WPS、Paddlepaddle的OCR方案，结果是WPS的识别效果是最好的。但是即使是最好WPS，识别出来文档依旧有很多的问题。例如：\n\n1.  识别不准问题：\n    1.  图片中的符号被识别为文本\n    2.  表格识别不完整\n    3.  文本顺序错误\n    4.  。。。\n2.  OCR是无法识别标题，需要去重新标注一遍\n\n只能说，打开word看起来是好的，实际是比较乱的。\n\n同时为了进一步实现数据处理的目标，下面会介绍不同情况的处理经验办法。\n\n![](/download/thumbnails/129175181/image2024-6-27_11-3-33.png?version=1&modificationDate=1719457413978&api=v2)![](/download/attachments/129175181/image2024-6-27_11-6-17.png?version=1&modificationDate=1719457577865&api=v2)![](/download/thumbnails/129175181/image2024-6-27_11-6-59.png?version=1&modificationDate=1719457619844&api=v2)\n\n3.1. 标题标注\n---------\n\nOCR识别的PDF无法直接识别并标注标题。然而标题对于RAG文本块的切片具有重要的参考意义的，影响的是切片片段文本的关联性、逻辑性，最终影响的是大模型的回复效果。\n\n但是标题可以通过几种方式，结合起来快速标注。\n\n1.  标题一般是有一定规律的文本。可以识别具备这种规律的文本为标题。例如1.1 第一章 第一节 一、xxx 等\n2.  无法被程序识别的标题文本。只能手动标注。但是可以借助word的快捷键，提高效率。\n3.  使用word通配符标注标题\n\n![](/download/attachments/129175181/image2024-6-27_11-40-0.png?version=1&modificationDate=1719459600862&api=v2)\n\n### 3.1.1. 程序识别\n\n首先程序识别标题，然后人工筛选，并设置标题层级。程序判断的大致逻辑，如上述。由github上的项目借鉴来的算法，加上我们的改造。虽无法做到100%准确，但是基本做到98%识别。基于识别的结果，在excel中，可以快速定位标题，并判断和设置层级关系。\n\n![](/download/thumbnails/129175181/image2024-6-27_13-50-21.png?version=1&modificationDate=1719467421714&api=v2)![](/download/thumbnails/129175181/image2024-6-27_13-51-52.png?version=1&modificationDate=1719467512980&api=v2)\n\n### 3.1.2. 人工审核\n\n由于算法和人的失误，会造成部分的标题没有标注。但是在算法识别的基础上，人很容易识别剩余未标注的标题，补全完整。另，word可对样式设置快捷键。\n\n![](/download/attachments/129175181/image2024-6-27_13-53-35.png?version=1&modificationDate=1719467616057&api=v2)![](/download/thumbnails/129175181/image2024-6-27_13-56-11.png?version=1&modificationDate=1719467771628&api=v2)\n\n### 3.1.3. 通配符标注\n\n部分单纯文字的但是有规律的标题。编写的算法没有识别。可以通过word提供的查找替换功能，定位标题并标注。\n\n![](/download/thumbnails/129175181/image2024-6-27_14-7-50.png?version=1&modificationDate=1719468470920&api=v2)\n\n### 3.1.4. 其他情况\n\n其他情况一般很少，先手动标注。\n\n  \n\n3.2. 文本清洗\n---------\n\n一本书籍中，除了有用的正文，剩下的几本都是无用的内容。例如目录、练习题、参考文献、致谢、页尾、页码、引用、续表等等。保留这些信息，会让知识库充斥一部分的垃圾数据。影响最终大模型回复效果。\n\n### 3.2.1. 目录、练习题、致谢、参考文献等大块文本清除\n\n针对大块的文本。一般目录、练习题、参考文献等，这些都有特定的标题和内容。目前比较能防止误删，并且比较快速的方法，是在标题正确标注的基础上，通过识别目录、练习题、参考文献等特定文字，判断当前文本，是否处理这些区域，从而判断当前文字是否需要删除。\n\n![](/download/thumbnails/129175181/image2024-6-27_11-46-55.png?version=1&modificationDate=1719460015706&api=v2)![](/download/thumbnails/129175181/image2024-6-27_11-47-9.png?version=1&modificationDate=1719460029669&api=v2)![](/download/thumbnails/129175181/image2024-6-27_11-47-24.png?version=1&modificationDate=1719460044211&api=v2)![](/download/thumbnails/129175181/image2024-6-27_14-19-37.png?version=1&modificationDate=1719469177532&api=v2)\n\n### 3.2.2. 页尾页码删除\n\n页尾页码通常是“书名+页码”或者“章节+页码”的形式存在。根据其特点，实践上有效的办法是，通过计算这一文本与书名和章节名的相似度，当相似度很高时，说明当前文本是页尾页码，自动删除。相似度需要先使用embedding模型，将段落文本转成向量。经验上，使用一个很小的模型，当前使用的大概是200M左右大小的“bge-base-zh-v1.5”，即可完全满足页尾页码的清洗需求。模型小，运算速度比会比较快。\n\n![](/download/thumbnails/129175181/image2024-6-27_14-16-50.png?version=1&modificationDate=1719469010115&api=v2)\n\n### 3.2.3. 引用、续表等特定文本删除\n\n使用正则表达式删除。经验上，正则表达式的编写得具体，不能太泛化，否则会导致很多的误删。\n\n![](/download/thumbnails/129175181/image2024-6-27_14-30-29.png?version=1&modificationDate=1719469829361&api=v2)\n\n3.3. 表格清洗\n---------\n\n表格数据经常存在于书籍中，但是表格数据要被大模型所用、所理解，需要较为复杂的清洗和转换。\n\n### 3.3.1. 表格转换\n\n需要将表格转化为“文本表示的表格”。有效的做法，需要将表格转换成下面样式的文本。通过python的docx库，可编写代码实现。\n\n![](/download/thumbnails/129175181/image2024-6-27_11-6-59.png?version=1&modificationDate=1719457619844&api=v2)![](/download/thumbnails/129175181/image2024-6-27_14-42-3.png?version=1&modificationDate=1719470523503&api=v2)\n\n### 3.3.2. 表格进一步清洗\n\n若OCR识别的表格不规整，目前没办法程序处理，只能手动进行调整。例如\n\n1.  多行表头，转成一行表头\n2.  重复识别列，修改回正确数量的列\n3.  将表名和表备注合并成一行\n4.  将没识别成表的表，转成表\n5.  。。。\n\n![](/download/attachments/129175181/image2024-6-27_14-46-42.png?version=1&modificationDate=1719470802277&api=v2)![](/download/thumbnails/129175181/image2024-6-27_14-47-50.png?version=1&modificationDate=1719470871030&api=v2)\n\n这些情况多、有一些复杂度，人工审核的难度是比较高的。可以通过编写审核程序来，判断表格是否可能存在问题。\n\n### 3.3.3. 表引用删除\n\n由于文档会以切片形式作为一个知识单元。当一个知识单元中的某段话引用了某个表，而恰巧（大概论）这个表不在同一个切片内，就可能会造成大模型的误解。\n\n可以通过正则表达式，识别并清除\n\n![](/download/attachments/129175181/image2024-6-27_14-53-28.png?version=1&modificationDate=1719471208645&api=v2)\n\n  \n\n3.4. 图片清洗\n---------\n\n图片是肯定需要删除。因为图片对于大语言模型来说，不是可以输入的内容。所以当前对图片的清洗目标，就只有删除图片。然而由于OCR识别不准的问题，图片的删除依旧需要进一步的清洗。\n\n总的来说图片的清洗相对简单，一般来说有2种情况进行注意。\n\n1.  图片内容识别为文本\n2.  图片引用\n\n### 3.4.1. 图片内容识别为文本\n\n图片的一大问题是，OCR可能会把图片中的某个字识别为文本。若不删除这些文本，就会导致知识库里存在无意义的噪音文本。这部分通过异常识别器，可以清除一部分。但是考虑到误删，目前还是需要一部分的人为清除。\n\n![](/download/thumbnails/129175181/image2024-6-27_11-3-33.png?version=1&modificationDate=1719457413978&api=v2)![](/download/attachments/129175181/image2024-6-27_11-6-17.png?version=1&modificationDate=1719457577865&api=v2)\n\n### 3.4.2. 图片引用\n\n图片引用如表引用。引用文本会造成大模型的理解困难。\n\n这部分可根据图片引用的文本特征，通过正则表达式删除。\n\n3.5. 公式清洗\n---------\n\n公式是书籍里的重要知识。保留公式，能够保留书籍里的关键信息。但是OCR算法并不具备识别和转化公式的能力。若公式只是如 1+1=2，很简单的单行公式，没有上标下标，复杂符号之类的，OCR能够招架。若公式稍复杂，就会被转化成一张图片。\n\n图片无法提供给大模型，则必须将公式图片转化为公式文本，才能保留住这部分的知识。\n\n![](/download/attachments/129175181/image2024-6-27_15-13-22.png?version=1&modificationDate=1719472402278&api=v2)\n\n但是如何把这种有上标下标、有除号等复杂表示的公式，用一行文本表示出来？目前主流的办法有\n\n1.  Latex\n2.  MathML\n3.  MathType\n4.  ...\n\n当前用的是latex，因为讯飞有latex公式识别模型，可以帮助提高当前的清洗效率。\n\n### 3.5.1. 图片转latex\n\n我们实际的操作中，先训练了一个判断图片是否是公式的公式识别CNN模型。用模型先判断图片是否是公式，若是公式，则通过讯飞的公式识别算法，将图片中的公式转化为latex公式，这样可以避免识别额度被浪费掉。\n\n![](/download/attachments/129175181/image2024-6-27_15-16-12.png?version=1&modificationDate=1719472572098&api=v2)\n\n不过讯飞的公式识别模型效果并不好，从过去的经验看，60~70%左右的公式都或多或少有一点问题。还需要人工去审核这个公式是否完全正确。\n\n![](/download/attachments/129175181/image2024-6-27_15-9-5.png?version=1&modificationDate=1719472146041&api=v2)\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)\n\n[Configure buttons visibility](/users/tfac-settings.action)"
}