{
	"title": "chatGLM模型的FAQ能力测试",
	"author": "王宇",
	"publishTime": "八月23,2023",
	"readTime": "12s",
	"tags": "[\"唐玮\"]",
	"description": "唐玮",
	"article": "1\\. 模型介绍\n========\n\nchatGLM2-6B模型是由清华大学数据挖掘小组THUDM研发的开源大模型。在2023年这个模型引起了很大的关注，因为这是当前同时支持开源、可商用、耗费资源很少的大模型。chatGLM-6B可以部署在消费级的显卡上运行，也就是说只要拥有一台包含8G显存的GPU，就能本地部署大模型。8G的GPU当前的价位大概是3K左右。很多玩游戏用的中高端电脑都能运行。\n\nchatGLM2-6B有60亿的模型参数，相比chatGPT（1750亿参数）相差甚远，这是主动缩减的结果。模型参数减小，让运行模型所需的GPU资源变低。\n\n2\\. 测评\n======\n\n2.1. FAQ测试\n----------\n\n使用 [GLM模型对比测试.xlsx](/download/attachments/105272416/GLM%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94%E6%B5%8B%E8%AF%95.xlsx?version=1&modificationDate=1690859188207&api=v2) 数据进行测试。该数据集包含99条数据，有测试问句、期望问题、期望回答3个字段。通过输入测试问题，评估模型的回复与期望回答的意思是否一致。并与FTT系统的FAQ功能进行比对。\n\n对于大模型均统一使用一下prompt：\n\n你是一款名为小万的聊天机器人，您的工作是按照给定的指令回答用户的问题。\n\n上下文开始  \n{context}  \n上下文结束\n\n要求：不超过50字，完全根据上下文的回答指令回答，不允许在回答中添加编造成分”  \n问题：{question}  \n回答：\n\n*   **chatGLM2-6B（微调+知识库）**：使用“服务助手测试问句0529.xlsx”FAQ数据对chatGLM2-6B进行微调训练后的模型。同时基于Langchain框架嵌入知识库，相似度阈值为1.7，embedding模型为GanymedeNil/text2vec-large-chinese。\n*   **chatGLM2-6B（微调）**：使用“服务助手测试问句0529.xlsx”FAQ数据进行微调训练后的模型。\n*   **chatGLM2-6B（知识库）**：使用原生的chatGLM2-6B模型。同时基于Langchain框架嵌入知识库，相似度阈值为1.7，embedding模型为GanymedeNil/text2vec-large-chinese。\n\n  \n\nps. “服务助手测试问句0529.xlsx”FAQ数据去除了ASR同音数据，具体如下：\n\n万得厨-万得出、万能除、万德福；商城-山城、三成；预制菜-一只菜；APP-ab；blunch-brunch；微波-微博；扬翔-杨翔、杨祥；数影-素影、输赢；万得科技-万的科技；盈康-银康；新谊宾-心宜宾；港丰-港风；了解-了姐；计划-记划\n\n  \n\n模型\n\n准确率\n\n正确数量\n\n错误数量\n\n模型\n\n准确率\n\n正确数量\n\n错误数量\n\nchatGLM2-6B（微调+知识库）\n\n85%\n\n85\n\n14\n\nchatGLM2-6B（微调）\n\n69%\n\n69\n\n30\n\nchatGLM2-6B（知识库）\n\n64%\n\n64\n\n35\n\n**LLama2-13B（微调+知识库）**\n\n**82%**\n\n**82**\n\n**17**\n\nLLama2-13B（知识库）\n\n73%\n\n73\n\n26\n\nFTT\n\n71%\n\n71\n\n28\n\n测试结果数据：[20230807\\_GLM模型对比测试\\_99.xlsx](/download/attachments/105272416/20230807_GLM%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94%E6%B5%8B%E8%AF%95_99.xlsx?version=1&modificationDate=1691478654071&api=v2)\n\n3\\. 场景测试\n========\n\n3.1. 一阶段测试\n----------\n\n**场景**：模型部署于手机端，并接入虚拟人\n\n**场景的能力需求**：\n\n1.  关于基本信息的问答：万得厨、万得厨APP、影子公司\n2.  关于食谱信息的回答：食材、烹饪步骤、烹饪器材等\n3.  关于预制菜的回答：烹饪码、盒子的处理等\n4.  平台宣传\n5.  食材处理\n6.  美食推荐\n\n**要求**：\n\n1.  针对**1、2、3、4**回答准确率都要达到90%以上\n2.  知识库是结构化的知识，而不是问答对。方便后续知识变更以后，模型能够立即识别并正确回答。\n3.  总结探索大模型应用中 知识更新与模型更新 的流程步骤，并梳理其中的风险和规避风险的方法。（关注）\n\n**后续考虑实验的方向**：\n\n1.  要将多个能力集合成一个入口。而不是需要从多个入口去获取使用不同能力。\n2.  输出食谱食品图片。\n3.  直接操控、修改万得厨设备信息和动作。\n4.  当输出为长文本的时候，另提供一个50字的总结文本提供给虚拟人进行播报\n5.  **5**食材处理要具备和chatGPT3.5一样的效果\n\n  \n\n  \n\n  \n\n参考文献\n\n1.  [GitHub - THUDM/ChatGLM-6B: ChatGLM-6B: An Open Bilingual Dialogue Language Model | 开源双语对话语言模型](https://github.com/THUDM/ChatGLM-6B)\n2.  [清华大学开源中文版ChatGPT模型——ChatGLM-6B发布 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/614331448)\n3.  [ChatGLM](https://chatglm.cn/blog)\n\n[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)\n\n[Configure buttons visibility](/users/tfac-settings.action)"
}