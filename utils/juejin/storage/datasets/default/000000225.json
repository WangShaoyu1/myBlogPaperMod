{
	"title": "源码分析|ClickHouse和他的朋友们（9）MySQL实时复制与实现",
	"author": "dbkernel",
	"publishTime": "2020-08-13",
	"readTime": "阅读11分钟",
	"tags": "[\"数据库\",\"MySQL\"]",
	"description": "很多人看到标题还以为自己走错了夜场，其实没有。ClickHouse可以挂载为MySQL的一个从库，先全量再增量的实时同步MySQL数据，这个功能可以说是今年最亮眼、最刚需的功能，基于它我们可以轻松的打造一套企业级解决方案，让OLTP和OLAP的融合从此不再…",
	"article": "> 本文转自我司大神 [BohuTANG的博客](https://link.juejin.cn?target=https%3A%2F%2Fbohutang.me%2F2020%2F07%2F26%2Fclickhouse-and-friends-mysql-replication \"https://bohutang.me/2020/07/26/clickhouse-and-friends-mysql-replication\") 。\n\n![](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cd3d16ce0d88455b8a08a81c913e0808~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)\n\n很多人看到标题还以为自己走错了夜场，其实没有。\n\nClickHouse 可以挂载为 MySQL 的一个从库 ，先全量再增量的实时同步 MySQL 数据，这个功能可以说是今年最亮眼、最刚需的功能，基于它我们可以轻松的打造一套企业级解决方案，让 OLTP 和 OLAP 的融合从此不再头疼。\n\n目前支持 MySQL 5.6/5.7/8.0 版本，兼容 Delete/Update 语句，及大部分常用的 DDL 操作。 [代码](https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2FClickHouse%2FClickHouse%2Fpull%2F10851 \"https://github.com/ClickHouse/ClickHouse/pull/10851\")已经合并到 upstream master 分支，预计在20.8版本作为experimental 功能发布。\n\n毕竟是两个异构生态的融合，仍然有不少的工作要做，同时也期待着社区用户的反馈，以加速迭代。\n\n### 代码获取\n\n获取 [clickhouse/master](https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2FClickHouse%2FClickHouse \"https://github.com/ClickHouse/ClickHouse\") 代码编译即可，方法见 [ClickHouse和他的朋友们（1）编译、开发、测试](https://link.juejin.cn?target=https%3A%2F%2Fbohutang.me%2F2020%2F06%2F05%2Fclickhouse-and-friends-development%2F \"https://bohutang.me/2020/06/05/clickhouse-and-friends-development/\")…\n\n### MySQL Master\n\n我们需要一个开启 binlog 的 MySQL 作为 master:\n\njavascript\n\n 代码解读\n\n复制代码\n\n`docker run -d -e MYSQL_ROOT_PASSWORD=123 mysql:5.7 mysqld --datadir=/var/lib/mysql --server-id=1 --log-bin=/var/lib/mysql/mysql-bin.log --gtid-mode=ON --enforce-gtid-consistency`\n\n创建数据库和表，并写入数据:\n\nsql\n\n 代码解读\n\n复制代码\n\n`mysql> create database ckdb; mysql> use ckdb; mysql> create table t1(a int not null primary key, b int); mysql> insert into t1 values(1,1),(2,2); mysql> select * from t1; +---+------+ | a | b    | +---+------+ | 1 |    1 | | 2 |    2 | +---+------+ 2 rows in set (0.00 sec)`\n\n### ClickHouse Slave\n\n目前以 database 为单位进行复制，不同的 database 可以来自不同的 MySQL master，这样就可以实现多个 MySQL 源数据同步到一个 ClickHouse 做 OLAP 分析功能。\n\n首先开启体验开关:\n\nsql\n\n 代码解读\n\n复制代码\n\n`clickhouse :) SET allow_experimental_database_materialize_mysql=1;`\n\n创建一个复制通道：\n\nsql\n\n 代码解读\n\n复制代码\n\n`clickhouse :) CREATE DATABASE ckdb ENGINE = MaterializeMySQL('172.17.0.2:3306', 'ckdb', 'root', '123'); clickhouse :) use ckdb; clickhouse :) show tables; ┌─name─┐ │ t1   │ └──────┘ clickhouse :) select * from t1; ┌─a─┬─b─┐ │ 1 │ 1 │ └───┴───┘ ┌─a─┬─b─┐ │ 2 │ 2 │ └───┴───┘ 2 rows in set. Elapsed: 0.017 sec.`\n\n看下 ClickHouse 的同步位点： cat ckdatas/metadata/ckdb/.metadata\n\nyaml\n\n 代码解读\n\n复制代码\n\n`Version:\t1 Binlog File:\tmysql-bin.000001 Binlog Position:\t913 Data Version:\t0`\n\n### Delete\n\n首先在 MySQL Master 上执行一个删除操作：\n\nsql\n\n 代码解读\n\n复制代码\n\n`mysql> delete from t1 where a=1; Query OK, 1 row affected (0.01 sec)`\n\n然后在 ClickHouse Slave 侧查看记录：\n\nsql\n\n 代码解读\n\n复制代码\n\n`clickhouse :) select * from t1; SELECT * FROM t1 ┌─a─┬─b─┐ │ 2 │ 2 │ └───┴───┘ 1 rows in set. Elapsed: 0.032 sec.`\n\n此时的 metadata 里 Data Version 已经递增到 2:\n\nsql\n\n 代码解读\n\n复制代码\n\n`cat ckdatas/metadata/ckdb/.metadata  Version:\t1 Binlog File:\tmysql-bin.000001 Binlog Position:\t1171 Data Version:\t2`\n\n### Update\n\nMySQL Master:\n\nsql\n\n 代码解读\n\n复制代码\n\n`mysql> select * from t1; +---+------+ | a | b    | +---+------+ | 2 |    2 | +---+------+ 1 row in set (0.00 sec) mysql> update t1 set b=b+1; mysql> select * from t1; +---+------+ | a | b    | +---+------+ | 2 |    3 | +---+------+ 1 row in set (0.00 sec)`\n\nClickHouse Slave:\n\nsql\n\n 代码解读\n\n复制代码\n\n`clickhouse :) select * from t1; SELECT * FROM t1 ┌─a─┬─b─┐ │ 2 │ 3 │ └───┴───┘ 1 rows in set. Elapsed: 0.023 sec.`\n\n### 性能测试\n\n#### 测试环境\n\narduino\n\n 代码解读\n\n复制代码\n\n`MySQL          8C16G 云主机, 192.168.0.3，基础数据 10188183 条记录 ClickHouse     8C16G 云主机, 192.168.0.4 benchyou       8C8G  云主机,  192.168.0.5, 256并发写, https://github.com/xelabs/benchyou`\n\n性能测试跟硬件环境有较大关系，这里使用的是云主机模式，数据供参考。\n\n#### 全量性能\n\nsql\n\n 代码解读\n\n复制代码\n\n`8c16G-vm :) create database sbtest engine=MaterializeMySQL('192.168.0.3:3306', 'sbtest', 'test', '123'); 8c16G-vm :) watch lv1; WATCH lv1 ┌─count()─┬───────────────now()─┬─_version─┐ │       0 │ 2020-07-29 06:36:04 │        1 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │ 1113585 │ 2020-07-29 06:36:05 │        2 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │ 2227170 │ 2020-07-29 06:36:07 │        3 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │ 3340755 │ 2020-07-29 06:36:10 │        4 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │ 4454340 │ 2020-07-29 06:36:13 │        5 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │ 5567925 │ 2020-07-29 06:36:16 │        6 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │ 6681510 │ 2020-07-29 06:36:18 │        7 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │ 7795095 │ 2020-07-29 06:36:22 │        8 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │ 8908680 │ 2020-07-29 06:36:25 │        9 │ └─────────┴─────────────────────┴──────────┘ ┌──count()─┬───────────────now()─┬─_version─┐ │ 10022265 │ 2020-07-29 06:36:28 │       10 │ └──────────┴─────────────────────┴──────────┘ ┌──count()─┬───────────────now()─┬─_version─┐ │ 10188183 │ 2020-07-29 06:36:28 │       11 │ └──────────┴─────────────────────┴──────────┘ ← Progress: 11.00 rows, 220.00 B (0.16 rows/s., 3.17 B/s.)`\n\n在这个硬件环境下，全量同步性能大概是 **424507/s**，**42w** 事务每秒。 因为全量的数据之间没有依赖关系，可以进一步优化成并行，加速同步。 全量的性能直接决定 ClickHouse slave 坏掉后重建的速度，如果你的 MySQL 有 **10 亿**条数据，大概 **40 分钟**就可以重建完成。\n\n#### 增量性能(实时同步)\n\n在当前配置下，ClickHouse slave 单线程回放消费能力大于 MySQL master 256 并发下生产能力，通过测试可以看到它们保持**实时同步**。\n\nbenchyou 压测数据，**2.1w** 事务/秒(MySQL 在当前环境下TPS上不去):\n\ncss\n\n 代码解读\n\n复制代码\n\n`./bin/benchyou --mysql-host=192.168.0.3 --mysql-user=test --mysql-password=123 --oltp-tables-count=1 --write-threads=256 --read-threads=0 time            thds               tps     wtps    rtps [13s]        [r:0,w:256,u:0,d:0]  19962    19962   0     time            thds               tps     wtps    rtps [14s]        [r:0,w:256,u:0,d:0]  20415    20415   0  time            thds               tps     wtps    rtps [15s]        [r:0,w:256,u:0,d:0]  21131    21131   0 time            thds               tps     wtps    rtps [16s]        [r:0,w:256,u:0,d:0]  21606    21606   0 time            thds               tps     wtps    rtps [17s]        [r:0,w:256,u:0,d:0]  22505    22505   0`\n\nClickHouse 侧单线程回放能力，**2.1w** 事务/秒，实时同步：\n\nsql\n\n 代码解读\n\n复制代码\n\n`┌─count()─┬───────────────now()─┬─_version─┐ │  150732 │ 2020-07-30 05:17:15 │       17 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │  155477 │ 2020-07-30 05:17:16 │       18 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │  160222 │ 2020-07-30 05:17:16 │       19 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │  164967 │ 2020-07-30 05:17:16 │       20 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │  169712 │ 2020-07-30 05:17:16 │       21 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │  174457 │ 2020-07-30 05:17:16 │       22 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │  179202 │ 2020-07-30 05:17:17 │       23 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │  183947 │ 2020-07-30 05:17:17 │       24 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │  188692 │ 2020-07-30 05:17:17 │       25 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │  193437 │ 2020-07-30 05:17:17 │       26 │ └─────────┴─────────────────────┴──────────┘ ┌─count()─┬───────────────now()─┬─_version─┐ │  198182 │ 2020-07-30 05:17:17 │       27 │ └─────────┴─────────────────────┴──────────┘`\n\n### 实现机制\n\n在探讨机制之前，首先需要了解下 MySQL 的 binlog event ，主要有以下几种类型：\n\nlua\n\n 代码解读\n\n复制代码\n\n`1. MYSQL_QUERY_EVENT　　　　-- DDL 2. MYSQL_WRITE_ROWS_EVENT　-- insert数据 3. MYSQL_UPDATE_ROWS_EVENT -- update数据 4. MYSQL_DELETE_ROWS_EVENT -- delete数据`\n\n当一个事务提交后，MySQL 会把执行的 SQL 处理成相应的 binlog event，并持久化到 binlog 文件。\n\nbinlog 是 MySQL 对外输出的重要途径，只要你实现 MySQL Replication Protocol，就可以流式的消费MySQL 生产的 binlog event，具体协议见 [Replication Protocol](https://link.juejin.cn?target=https%3A%2F%2Fdev.mysql.com%2Fdoc%2Finternals%2Fen%2Freplication-protocol.html \"https://dev.mysql.com/doc/internals/en/replication-protocol.html\")。\n\n由于历史原因，协议繁琐而诡异，这不是本文重点。\n\n对于 ClickHouse 消费 MySQL binlog 来说，主要有以下３个难点：\n\n*   DDL 兼容\n*   Delete/Update 支持\n*   Query 过滤\n\n#### DDL\n\nDDL 兼容花费了大量的代码去实现。\n\n首先，我们看看 MySQL 的表复制到 ClickHouse 后会变成什么样子。\n\nMySQL master:\n\nsql\n\n 代码解读\n\n复制代码\n\n``mysql> show create table t1\\G; *************************** 1. row ***************************        Table: t1 Create Table: CREATE TABLE `t1` (   `a` int(11) NOT NULL,   `b` int(11) DEFAULT NULL,   PRIMARY KEY (`a`) ) ENGINE=InnoDB DEFAULT CHARSET=latin1``\n\nClickHouse slave:\n\nsql\n\n 代码解读\n\n复制代码\n\n``ATTACH TABLE t1 (     `a` Int32,     `b` Nullable(Int32),     `_sign` Int8,     `_version` UInt64 ) ENGINE = ReplacingMergeTree(_version) PARTITION BY intDiv(a, 4294967) ORDER BY tuple(a) SETTINGS index_granularity = 8192``\n\n可以看到：\n\n*   默认增加了 2 个隐藏字段：\\_sign(-1删除, 1写入) 和 \\_version(数据版本)\n*   引擎转换成了 ReplacingMergeTree，以 \\_version 作为 column version\n*   原主键字段 a 作为排序和分区键\n\n这只是一个表的复制，其他还有非常多的DDL处理，比如增加列、索引等，感兴趣可以观摩 Parsers/MySQL 下代码。\n\n#### Update和Delete\n\n当我们在 MySQL master 执行：\n\nsql\n\n 代码解读\n\n复制代码\n\n`mysql> delete from t1 where a=1; mysql> update t1 set b=b+1;`\n\nClickHouse t1数据（把 \\_sign 和 \\_version 一并查询）：\n\nsql\n\n 代码解读\n\n复制代码\n\n`clickhouse :) select a,b,_sign, _version from t1; SELECT      a,     b,     _sign,     _version FROM t1 ┌─a─┬─b─┬─_sign─┬─_version─┐ │ 1 │ 1 │     1 │        1 │ │ 2 │ 2 │     1 │        1 │ └───┴───┴───────┴──────────┘ ┌─a─┬─b─┬─_sign─┬─_version─┐ │ 1 │ 1 │    -1 │        2 │ └───┴───┴───────┴──────────┘ ┌─a─┬─b─┬─_sign─┬─_version─┐ │ 2 │ 3 │     1 │        3 │ └───┴───┴───────┴──────────┘`\n\n根据返回结果，可以看到是由 3 个 part 组成。\n\npart1 由 `mysql> insert into t1 values(1,1),(2,2)` 生成：\n\ncss\n\n 代码解读\n\n复制代码\n\n`┌─a─┬─b─┬─_sign─┬─_version─┐ │ 1 │ 1 │     1 │        1 │ │ 2 │ 2 │     1 │        1 │ └───┴───┴───────┴──────────┘`\n\npart2 由 `mysql> delete from t1 where a=1` 生成：\n\ncss\n\n 代码解读\n\n复制代码\n\n`┌─a─┬─b─┬─_sign─┬─_version─┐ │ 1 │ 1 │    -1 │        2 │ └───┴───┴───────┴──────────┘ 说明： _sign = -1表明处于删除状态`\n\npart3 由 `update t1 set b=b+1` 生成：\n\ncss\n\n 代码解读\n\n复制代码\n\n`┌─a─┬─b─┬─_sign─┬─_version─┐ │ 2 │ 3 │     1 │        3 │ └───┴───┴───────┴──────────┘`\n\n使用 final 查询：\n\nsql\n\n 代码解读\n\n复制代码\n\n`clickhouse :) select a,b,_sign,_version from t1 final; SELECT      a,     b,     _sign,     _version FROM t1 FINAL ┌─a─┬─b─┬─_sign─┬─_version─┐ │ 1 │ 1 │    -1 │        2 │ └───┴───┴───────┴──────────┘ ┌─a─┬─b─┬─_sign─┬─_version─┐ │ 2 │ 3 │     1 │        3 │ └───┴───┴───────┴──────────┘ 2 rows in set. Elapsed: 0.016 sec.`\n\n可以看到 ReplacingMergeTree 已经根据 \\_version 和 OrderBy 对记录进行去重。\n\n#### Query\n\nMySQL master:\n\nsql\n\n 代码解读\n\n复制代码\n\n`mysql> select * from t1; +---+------+ | a | b    | +---+------+ | 2 |    3 | +---+------+ 1 row in set (0.00 sec)`\n\nClickHouse slave:\n\nsql\n\n 代码解读\n\n复制代码\n\n`clickhouse :) select * from t1; SELECT * FROM t1 ┌─a─┬─b─┐ │ 2 │ 3 │ └───┴───┘ clickhouse :) select *,_sign,_version from t1; SELECT      *,     _sign,     _version FROM t1 ┌─a─┬─b─┬─_sign─┬─_version─┐ │ 1 │ 1 │    -1 │        2 │ │ 2 │ 3 │     1 │        3 │ └───┴───┴───────┴──────────┘ 说明：这里还有一条删除记录，_sign为-1`\n\nMaterializeMySQL 被定义成一种存储引擎，所以在读取的时候，会根据 \\_sign 状态进行判断，如果是-1则是已经删除，进行过滤。\n\n### 并行回放\n\n为什么 MySQL 需要并行回放？\n\n假设 MySQL master 有 1024 个并发同时写入、更新数据，瞬间产生大量的 binlog event ，MySQL slave 上只有一个线程一个 event 接着一个 event 式回放，于是 MySQL 实现了并行回放功能！\n\n那么，MySQL slave 回放时能否完全(或接近)模拟出 master 当时的 1024 并发行为呢？\n\n要想并行首先要解决的就是依赖问题：我们需要 master 标记出哪些 event 可以并行，哪些 event 有先后关系，因为它是第一现场。\n\nMySQL 通过在 binlog 里增加:\n\n*   last\\_committed，相同则可以并行\n*   sequece\\_number，较小先执行，描述先后依赖\n\nini\n\n 代码解读\n\n复制代码\n\n`last_committed=3   sequece_number=4   -- event1 last_committed=4   sequece_number=5   -- event2 last_committed=4   sequece_number=6   -- event3 last_committed=5   sequece_number=7   -- event4`\n\nevent2 和 event3 则可以并行，event4 需要等待前面 event 完成才可以回放。 以上只是一个大体原理，目前 MySQL 有３种并行模式可以选择：\n\n1.  基于 database 并行\n2.  基于 group commit 并行\n3.  基于主键不冲突的 write set 并行\n\n最大程度上让 MySQL slave加速回放，整套机制还是异常复杂的。\n\n回到 ClickHouse slave 问题，我们采用的单线程回放，延迟已经不是主要问题，这是由它们的机制决定的： MySQL slave 回放时，需要把 binlog event 转换成 SQL，然后模拟 master 的写入，这种逻辑复制是导致性能低下的最重要原因。 而 ClickHouse 在回放上，直接把 binlog event 转换成 底层 block 结构，然后直接写入底层的存储引擎，接近于物理复制，可以理解为把 binlog event 直接回放到 InnoDB 的 page。\n\n### 读取最新\n\n虽然 ClickHouse slave 回放非常快，接近于实时，如何在ClickHouse slave上总是读取到最新的数据呢？\n\n其实非常简单，借助 MySQL binlog GTID 特性，每次读的时候，我们跟 ｍaster 做一次 executed\\_gtid 同步，然后等待这些 executed\\_gtid 回放完毕即可。\n\n### 数据一致性\n\n对一致性要求较高的场景，我们怎么验证 MySQL master 的数据和 ClickHouse slave 的数据一致性呢？\n\n这块初步想法是提供一个兼容 MySQL checksum 算法的函数，我们只需对比两边的 checksum 值即可。\n\n### 总结\n\nClickHouse 实时复制同步 MySQL 数据是 upstream 2020 的一个 roadmap，在整体构架上比较有挑战一直无人接单，挑战主要来自两方面：\n\n*   对 MySQL 复制通道与协议非常熟悉\n*   对 ClickHouse 整体机制非常熟悉\n\n这样，在两个本来有点遥远的山头中间架起了一座高速，这条 [10851号](https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2FClickHouse%2FClickHouse%2Fpull%2F10851 \"https://github.com/ClickHouse/ClickHouse/pull/10851\") 高速由 zhang1024(ClickHouse侧) 和 BohuTANG(MySQL复制) 两个修路工联合承建，目前已经合并到 upstream 分支。\n\n关于同步 MySQL 的数据，目前大家的方案基本都是在中间安置一个 binlog 消费工具，这个工具对 event 进行解析，然后再转换成 ClickHouse 的 SQL 语句，写到 ClickHouse server，链路较长，性能损耗较大。\n\n[10851号](https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2FClickHouse%2FClickHouse%2Fpull%2F10851 \"https://github.com/ClickHouse/ClickHouse/pull/10851\") 高速是在 ClickHouse 内部实现一套 binlog 消费方案，然后根据 event 解析成 ClickHouse 内部的 block 结构，再直接回写到底层存储引擎，几乎是最高效的一种实现方式，实现与 MySQL 实时同步的能力，让分析更接近现实。\n\n基于 database 级的复制，实现了多源复制的功能，如果复制通道坏掉，我们只需在 ClickHouse 侧删掉 database 再重建一次即可，非常快速、方便，OLTP+OLAP 就是这么简单！\n\n要想富，先修路！\n\n* * *\n\n欢迎关注我的微信公众号【数据库内核】：分享主流开源数据库和存储引擎相关技术。\n\n标题\n\n网址\n\nGitHub\n\n[dbkernel.github.io](https://link.juejin.cn?target=https%3A%2F%2Fdbkernel.github.io \"https://dbkernel.github.io\")\n\n知乎\n\n[www.zhihu.com/people/dbke…](https://link.juejin.cn?target=https%3A%2F%2Fwww.zhihu.com%2Fpeople%2Fdbkernel%2Fposts \"https://www.zhihu.com/people/dbkernel/posts\")\n\n思否（SegmentFault）\n\n[segmentfault.com/u/dbkernel](https://link.juejin.cn?target=https%3A%2F%2Fsegmentfault.com%2Fu%2Fdbkernel \"https://segmentfault.com/u/dbkernel\")\n\n掘金\n\n[juejin.im/user/5e9d3e…](https://juejin.im/user/5e9d3ed251882538083fed1f/posts \"https://juejin.im/user/5e9d3ed251882538083fed1f/posts\")\n\nCSDN\n\n[blog.csdn.net/dbkernel](https://link.juejin.cn?target=https%3A%2F%2Fblog.csdn.net%2Fdbkernel \"https://blog.csdn.net/dbkernel\")\n\n博客园（cnblogs）\n\n[www.cnblogs.com/dbkernel](https://link.juejin.cn?target=https%3A%2F%2Fwww.cnblogs.com%2Fdbkernel \"https://www.cnblogs.com/dbkernel\")"
}