[
  {
    "modelName": "internlm2:20b-chat-v2.5-q3_K_M",
    "modelSize": 9932.8,
    "modelSizeInMb": "9932.8MB"
  },
  {
    "modelName": "gemma2:9b-instruct-q8_0",
    "modelSize": 10035.2,
    "modelSizeInMb": "10035.2MB"
  },
  {
    "modelName": "deepseek-coder-v2:16b-lite-base-q4_1",
    "modelSize": 10137.6,
    "modelSizeInMb": "10137.6MB"
  },
  {
    "modelName": "gemma2:27b-instruct-q2_K",
    "modelSize": 10240,
    "modelSizeInMb": "10240MB"
  },
  {
    "modelName": "qwen2.5:14b-instruct-q5_1",
    "modelSize": 11264,
    "modelSizeInMb": "11264MB"
  },
  {
    "modelName": "gemma2:27b-instruct-q3_K_S",
    "modelSize": 12288,
    "modelSizeInMb": "12288MB"
  },
  {
    "modelName": "gemma2:27b-instruct-q3_K_M",
    "modelSize": 13312,
    "modelSizeInMb": "13312MB"
  },
  {
    "modelName": "qwen2.5:32b-instruct-q3_K_S",
    "modelSize": 14336,
    "modelSizeInMb": "14336MB"
  },
  {
    "modelName": "gemma2:27b-instruct-q3_K_L",
    "modelSize": 15360,
    "modelSizeInMb": "15360MB"
  },
  {
    "modelName": "llama3.1:8b-instruct-fp16",
    "modelSize": 16384,
    "modelSizeInMb": "16384MB"
  },
  {
    "modelName": "gemma2:27b-instruct-q4_1",
    "modelSize": 17408,
    "modelSizeInMb": "17408MB"
  },
  {
    "modelName": "gemma2:9b-instruct-fp16",
    "modelSize": 18432,
    "modelSizeInMb": "18432MB"
  },
  {
    "modelName": "gemma2:27b-instruct-q5_0",
    "modelSize": 19456,
    "modelSizeInMb": "19456MB"
  }
]