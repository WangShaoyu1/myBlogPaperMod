---
author: "字节跳动技术团队"
title: "乘云向未来  算力基础设施护航业务平稳上云实践"
date: 2024-01-23
description: "数字时代，云始终是企业实现数字化转型和增长的关键底座。随着新一轮公共云竞争的日渐火热，新的基于算力和基础设施的需求蓬勃生长。在这场上云热潮中，什么样的基础设施产品能够打出优势，竞得一方“云上天空”？ "
tags: ["云原生中文技术社区","前端开发社区","前端技术交流","前端框架教程","JavaScript 学习资源","CSS 技巧与最佳实践","HTML5 最新动态","前端工程师职业发展","开源前端项目","前端技术趋势"]
ShowReadingTime: "阅读7分钟"
weight: 1
selfDefined:"likes:1,comments:1,collects:0,views:23895,"
---
> 火山引擎公共云城市分享会，精彩回顾

数字时代，云始终是企业实现数字化转型和增长的关键底座。随着新一轮公共云竞争的日渐火热，新的基于算力和基础设施的需求蓬勃生长。在这场上云热潮中，什么样的基础设施产品能够打出优势，竞得一方“云上天空”？

2023年11月10日-24日，“乘云·向未来”火山引擎公共云·城市分享会先后走进北京、上海、深圳，会上火山引擎以“**算力基础设施护航业务平稳上云实践**”为题，分享了火山引擎算力基础设施在高性能计算和存储集群、云原生和计算协同调度、资源池化和在离线融合等方面的优势，为企业业务平稳上云保驾护航。

以下为演讲实录：

从字节跳动内部业务演变看底层技术演进
------------------

一直以来，火山引擎都在认真做“云”。

作为云计算的“后来者”，火山引擎笃定“帮助客户做业务和客户的增长是很重要的事情”。在2021年底，火山引擎正式发布了云产品。从那时起，CPU、GPU等算力的大规模增长及配套存储规模的提升，成为火山引擎基础设施产品发展的“第一要义”。

回顾历史，2003年到2010年期间，基础网络连接速度为10G。随着AI的发展，如今的基础网络速度已经达到了200G甚至400G。这种增长无疑是惊人的。面对网络的“提速”，为了更好地服务客户，火山引擎始终在努力提炼和优化自身能力。

在过去的五六年里，火山引擎进行了大规模的服务器部署和深度系统建设，在IT成本、硬件服务器成本和运营成本等方面进行了系统、全面的优化。例如，在上百万台服务器上进行了强大的供应链备货和组装，并建立了硬件优化体系。这使得火山引擎的供应体系和硬件测试优化能力都达到了极致——无论是云服务器、GPU服务器、弹性裸金属，都打出了性价比优势。

基于这样的先发优势，火山引擎在内部和外部都采用了云原生架构，使得整个系统实现了同步和较高利用率。在这基础之上，通过内外复用技术提高资源利用率，从而实现优化运行。如此一来，在冷启动阶段，火山引擎便处于行业领先水平。

![](/images/jueJin/9743ee21e19c483.png)

几年间，经过三代架构演进和大规模内部实践，火山引擎有了非常大的进步。在资源覆盖方面，公有云产品已经服务到了华北、华东、华南、东南亚等地区，基于性价比优势和安全合规的基础设施，与字节跳动业务等进行了深度融合。

而在这过程中，每一步的复制都不是简单的“复制粘贴”，火山引擎要做的，是回归到提高区域内的使用率和售卖率的目标上来。在满足客户需求的同时，也锤炼自身强劲的竞争力。

算力基础设施进化之道
----------

算力基础设施具有系统工程优化、大规模训练和推理优化、全天候技术支持、供应链稳定等特性。这些特性虽然在大体上相似，但每家供应商都有其独特点。其中，供应链的稳定性是提升竞争力的关键要素之一。

![](/images/jueJin/d1e5d994b465483.png)

当前，人工智能技术的推动，以及由此产生的对高性能计算和存储能力的需求，使得整个供应链的不稳定性有所增加。因此，风险管理和对风险的容忍度成了至关重要的因素。

要应对这种不确定性，算力基础设施需要支持各种不同体系架构的高性能算力单元，保持集群的稳定运行是一项极其重要的任务。我们现在所使用的机器，每台都配备了两颗CPU、8张GPU卡、4-8张网卡，这比传统的服务器复杂度要高出一个数量级甚至更多。

正是这种硬件配置的复杂性，导致整个系统故障率是传统CPU的10倍以上。当一个集群拥有上千张甚至上万张GPU时候，故障的影响范围将以指数形式增长。因此，如何确保百卡、千卡和万卡规模的集群能够长期稳定运行，成为了亟待解决的问题。

为了解决这一难题，火山引擎提出进行硬件的冷迁移。当发生故障时，可以保留现场，将状态存储在云端，并快速进行机器的冷迁移。这种做法能够最大限度地优化加载和存储过程。此外，还可以对网络进行实时监控，包括对GPU故障码进行区分等，都是有效措施。

从汽车行业和制造行业应用居多的算力组网来看，行业需要处理的数据往往是多模态的，因此除了对算力有高要求外，在存储和带宽方面需求也随之升高。为了更好地监控网络性能，火山引擎提供了毫秒级的网络监控能力。200G的网络和400G的网络在数据传输过程中可能会出现峰值突发的情况，这种情况会持续1至2秒。而毫秒级的监控能够有效解决这一难题。

![](/images/jueJin/596932f486d0464.png)

对于万卡规模的集群，火山引擎采用了三层架构的设计。通过使用自主研发的优势，尽量消除了在计算方面可能出现的问题。同时，火山引擎在集群上挂载了400个存储节点，运行文件系统的集群可以很好地提供存储和带宽能力。

针对存储需求较高的任务，火山引擎在底层构建了独立的存储系统；而对于那些对性能要求较高且计算较为简单的任务，火山引擎提供了更优化的方案——通过使用GPU本地盘以及后端缓存分离的技术实现分布式缓存架构。这种方法对于容量不大但带宽需求较大的任务，可以提供性价比更高的解决方案。

总体而言，充分利用这些算力资源是AI开发体系中的关键所在。在训练过程中，不同的任务可能需要从几十卡到数千卡的不同计算资源。如果能够通过云原生的能力将这些任务融合在一起，并将底层资源利用到最佳状态，那么整个资源的利用率将会更加高效。

![](/images/jueJin/23d459c7ad5c46c.png)

在此过程中，值得一提的是火山引擎自研的DPU卡。从2018年开始研发的DPU，至今已经可以实现几千万pps的性能，能够完整地将虚拟化和存储网络能力卸载到卡上来，增强虚拟化的同时，很好地解决实际问题。

目前，火山引擎所有的GPU都已实现统一配置，并且接入到云上，以便实现更好的弹性。

灵活组网撬动云上增长杠杆
------------

除了算力资源之外，火山引擎在网络服务方面也取得了较好的进展。从功能上看，火山引擎公共云面向企业全面上云的网络需求，能够提供形态完整的网络服务，帮助企业灵活组网，构建符合企业要求的高效、可控、合规的云上网络环境。

同时，火山引擎将致力于实现异构机密可信，以及解决授信问题等技术挑战，真正做到“将复杂的问题留给火山引擎，将更好的服务带给客户”。