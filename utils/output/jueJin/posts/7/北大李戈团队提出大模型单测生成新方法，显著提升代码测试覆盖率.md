---
author: "机器之心"
title: "北大李戈团队提出大模型单测生成新方法，显著提升代码测试覆盖率"
date: 2024-09-03
description: "单元测试是软件开发流程中的一个关键环节，主要用于验证软件中的最小可测试单元，函数或模块是否按预期工作。单元测试的目标是确保每个独立的代码片段都能正确执行其功能，对于提高软件质量和开发效率具有重要意义。"
tags: ["人工智能","Android中文技术社区","前端开发社区","前端技术交流","前端框架教程","JavaScript 学习资源","CSS 技巧与最佳实践","HTML5 最新动态","前端工程师职业发展","开源前端项目","前端技术趋势"]
ShowReadingTime: "阅读7分钟"
weight: 1
selfDefined:"likes:0,comments:0,collects:1,views:85,"
---
单元测试是软件开发流程中的一个关键环节，主要用于验证软件中的最小可测试单元，函数或模块是否按预期工作。单元测试的目标是确保每个独立的代码片段都能正确执行其功能，对于提高软件质量和开发效率具有重要意义。

然而，大模型自身无力为复杂待测函数（环复杂度大于 10）生成高覆盖率的测试样例集。为了解决该痛点，北京大学李戈教授团队提出一种全新的提升测试用例覆盖率的方法，该方法借助程序分片思想（Method Slicing)，将复杂待测函数依据语义拆解为若干简单片段，进而让大模型为各个简单片段分别生成测试样例。生成单个测试样例时，大模型只需分析原待测函数的一个片段，分析难度减小，生成覆盖该片段的单元测试难度随之减小。由此推广，提升整体测试样例集代码覆盖率。

相关论文《HITS: High-coverage LLM-based Unit Test Generation via Method Slicing》近期被 ASE 2024（at the 39th IEEE/ACM International Conference on Automated Software Engineering）顶会接受。

![](/images/jueJin/881e92c1c579456.png)

论文地址：[www.arxiv.org/pdf/2408.11…](https://link.juejin.cn?target=https%3A%2F%2Fwww.arxiv.org%2Fpdf%2F2408.11324 "https://www.arxiv.org/pdf/2408.11324")

接下来看看北大团队论文研究的具体内容：

**HITS 使用大模型进行程序分片**

程序分片指将一个程序依据语义划分为若干解决问题的阶段。程序是对一个问题解决方案的形式化表述。一个问题解决方案通常包含多个步骤，每个步骤对应着程序中的一片（slice）代码。如下图所示，一个色块对应着一片代码，也对应着一个问题解决的步骤。

![](/images/jueJin/4ceff5580897491.png)

HITS 要求大模型分别为每个代码片设计可以高效覆盖它的单元测试代码。以上图为例，当我们得到如图的分片后，HITS 要求大模型为 Slice 1（绿色），Slice 2（蓝色），Slice 3（红色）分别生成测试样例。为 Slice 1 生成的测试样例要尽可能覆盖 Slice 1，不用考虑 Slice 2 和 Slice 3，其余代码片同理。

HITS 起效的原因有二。其一，大模型要考虑覆盖的代码量降低。以上图为例，为 Slice 3 生成测试样例，则只需考虑 Slice 3 中的条件分支。要覆盖 Slice 3 中的某些条件分支，只需在 Slice 1 和 Slice 2 中找寻一条执行路径即可，无需考虑该执行路径对 Slice 1 和 Slice 2 覆盖率的影响。其二，依据语义（问题解决步骤）分割的代码片有助于大模型掌握代码执行中间状态。为顺序靠后的代码块生成测试样例，需要考虑先前代码对程序状态的改变。由于代码块依据实际问题解决步骤分割，因此可以用自然语言对先前代码块的操作进行描述（如上图中注释部分）。由于当前大语言模型多为自然语言与程序语言混合训练产物，良好的自然语言概括可帮助大模型更精准掌握代码对程序状态的改变。

HITS 使用大模型进行程序分片。问题的解决步骤通常为带有程序员主观色彩的自然语言表述，因而可以直接利用自然语言处理能力超群的大模型。具体而言，HITS 使用上下文学习方法（In-context learning) 调用大模型。团队利用过往在真实场景实践的经验，手工编写若干程序分片样例，经若干次调整后使大模型对程序分片的效果达到了研究团队的预期。

**对代码片生成测试样例**

给定要覆盖的代码片段，要生成对应测试样例，需经历以下 3 个步骤：1. 对片段的输入进行分析；2. 构造 prompt 指示大模型生成初始测试样例；3. 使用规则后处理和大模型 self-debug 调整测试样例使之可以正确运行。

对片段的输入进行分析，指提取要覆盖的片段所接受的一切外部输入，以备后续 prompt 使用。外部输入，指该片段所应用到的先前片段定义的局部变量，待测方法的形参，片段内调用的方法以及外部变量。外部输入的值直接决定了要覆盖的片段的执行情况，因此将该信息提取出来提示给大模型有助于有针对性地设计测试样例。研究团队在实验中发现大模型拥有良好的提取外部输入的能力，因此在 HITS 中由大模型来完成该任务。

接下来，HITS 构建思维链（Chain-of-thought）形式的 prompt 引导大模型生成测试样例。推理步骤如下。第一步，给定外部输入，分析要满足待覆盖代码片内的各种条件分支的排列组合，外部输入都分别需要满足哪些性质，如：组合 1，字符串 a 需要包含字符’x’，整数变量 i 需要非负；组合 2，字符串 a 需要非空，整数变量 i 需要为质数。第二步，对上一步中的每一种组合，分析相对应的待测代码执行时所处环境的性质，包括但不限于实参的特性，全局变量的设置。第三步，为每一种组合生成一个测试样例。研究团队为每一步手工构建了样例，以便于大模型能够正确理解并执行指令。

最后，HITS 通过后处理和 self-debug 使大模型生成的测试样例得以正确运行。大模型生成的测试样例往往难以直接使用，会出现各式各样的编译错误和来自于错误编写测试样例导致的运行时错误。研究团队根据自身观察及已有论文的总结，设计了若干规则和常见错误的修复案例。首先尝试依据规则修复。如果规则无法修复，则使用大模型 self-debug 的功能进行修复，在 prompt 中提供了常见错误的修复案例以供大模型参考。

![](/images/jueJin/09873156b5264ee.png)

_HITS 的整体图解_

**实验验证**

研究团队使用 gpt-3.5-turbo 作为 HITS 调用的大模型，分别在大模型学习过和未学习过的 Java 项目中的复杂函数（环复杂度大于 10）上对比 HITS，其他基于大模型的单元测试方法和 evosuite 的代码覆盖率。实验结果显示 HITS 相较于被比较的诸方法有较明显的性能提升。

![](/images/jueJin/1c90ec81ebcb46d.png)

![](/images/jueJin/3c17405892ce44c.png)

![](/images/jueJin/37ecc0b48bb745b.png)

_研究团队通过样例分析展示分片方法如何提升代码覆盖率。如图所示。_

该案例中，基线方法生成的测试样例未能完全覆盖 Slice 2 中的红色代码片段。然而，HITS 由于聚焦于 Slice 2，对其所引用的外部变量进行了分析，捕捉到 “如果要覆盖红色代码片段，变量’arguments’ 需要非空 “的性质，根据该性质构建了测试样例，成功实现了对红色区域代码的覆盖。

提升单元测试覆盖率，增强系统的可靠性和稳定性，进而提高软件质量。HITS 使用程序分片实验证明，该技术不仅能大幅提升整体测试样例集代码覆盖率，且实施方法简洁直接，未来有望在真实场景实践中，帮助团队更早发现并修正开发中的错误，提升软件交付质量。