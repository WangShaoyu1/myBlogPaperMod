---
author: "机器之心"
title: "当大模型 Scaling Law 继续，万卡集群算力释放在「百舸」这里找到一条通途"
date: 2024-09-25
description: "在电影《天下无贼》中，葛优扮演的黎叔有这样一句经典的台词，「二十一世纪什么最贵？人才！」而随着人工智能行业进入到大模型时代，这一问题的答案已然变成了「算力」。"
tags: ["人工智能","Android中文技术社区","前端开发社区","前端技术交流","前端框架教程","JavaScript 学习资源","CSS 技巧与最佳实践","HTML5 最新动态","前端工程师职业发展","开源前端项目","前端技术趋势"]
ShowReadingTime: "阅读13分钟"
weight: 1
selfDefined:"likes:0,comments:0,collects:0,views:39,"
---
在电影《天下无贼》中，葛优扮演的黎叔有这样一句经典的台词，「二十一世纪什么最贵？人才！」而随着人工智能行业进入到大模型时代，这一问题的答案已然变成了「算力」。

随着模型规模急剧扩张，参数已经飙升到了千亿甚至万亿级，业界开启了千模大战，AI 算力需求不可避免迎来爆炸式增长，无论是前期训练还是后期推理，都是如此。

在训练层面，OpenAI 曾在 2018 年做过估算，自 2012 年以来，AI 模型训练算力需求每 3.5 个月翻一番，每年所需算力增幅高达 10 倍，增速远远超出了芯片产业长期存在的摩尔定律（性能每 18 个月翻一番）。同时随着大模型及应用越来越多地部署到企业实际业务场景中，推理算力需求也水涨船高。

因此，指数级增长的算力需求对 GPU 等硬件提出了更高要求，大规模 GPU 算力集群成为必然选择。这也是为什么近年来国内外科技厂商纷纷布局 AI 算力基础设施，死磕万卡甚至 10 万卡集群。此外，大规模算力集群也越来越凸显训推一体的重要性，寻求在同一个集群中无缝切换大模型的训练和推理，简化用户部署流程。

虽然 GPU 集群可以满足大模型时代的算力需求，但面临的挑战也不少，比如多类型芯片混合训练、数据中心电力消耗、网络通信和负载、单卡算力效率、多卡并行计算、设施稳定性等。加之当前集群算力利用率不高且成本高昂，这些都要求厂商在集群系统、框架和算法层面进行技术突破。

国内一些厂商已经在面向万卡集群的 AI 基础设施方面积累了丰富的经验，并催生了覆盖广泛的「多芯混合训练时代」。我们以百度为例，其**基于文心大模型训练的经验沉淀，推出了 AI 异构计算平台「百舸」，打造业界领先的多芯混合训练 AI 集群**，并正在帮助客户更快、更稳、更省地落地大模型应用。

从 2021 年的 1.0 版本到去年的 3.0 版本，我们发现，连续三年，百舸围绕系统性提升 GPU 集群的整体算力利用率不断深入优化。在今日举办的 2024 百度云智大会上，再度升级的百舸 4.0 带给了客户更多惊喜，也给同行们带来了一点小小的震撼。

![](/images/jueJin/6ab378aecbbf4e4.png)

**算力浪费降至 1/10**

**万卡集群下的大模型训推更快、更省**

对于国内云厂商来说，面对 AI 大模型时代的巨量算力需求，归根到底要解决好两个核心诉求：一是如何在算力资源供应短缺的大环境下扩大算力来源，二是如何在大模型产生的高昂计算成本压力下极致高效地利用算力。从已有进展来看，百舸 AI 异构计算平台做到了「两手抓、两手都要硬」。

在去年 12 月的 2023 百度云智大会・智算大会上，百舸 3.0 已经展现了业界领先的万卡集群算力释放能力，集群有效训练时长达到了 98%、网络带宽有效利用率达到了 95%。如今，9 个多月过去了，百舸 4.0「百尺竿头更进一步」，在一些集群算力指标上又有所提升。

此次，百舸 4.0 在整体架构上相较 3.0 版本有了略微调整，**从底层硬件往上依次分为资源层、组件层、大模型加速层和工具层**。四层架构，各司其职，针对大模型的训推、部署和调优等全流程进一步优化。

具体来讲，资源层提供了包括异构芯片、高速互联、高效存储等在内的算力资源，组件层主要解决大规模集群的稳定性和性能问题，大模型加速层专为大模型训推提速而设计，工具层则通过一套管理界面提供了更便捷的操作体验。

![](/images/jueJin/b7de1ab64b8a419.png)

_百度集团执行副总裁、百度智能云事业群总裁沈抖_

依托四层架构，**百舸 4.0 对集群算力调用的各个环节做到了精准把控，并具备了「多、快、稳、省」四大特性**，形成了其作为 AI 异构计算平台的核心竞争力。

首先是**多芯异构**。我们观察到，一云多芯已经成为算力集群的主流选择，既可以屏蔽硬件之间的差异，利用弹性更强的供应链体系摆脱对单一芯片的依赖；又能够根据用户特定业务场景灵活调配算力资源并提高利用率。

百舸 4.0 构建了 GPU 和多类型 AI 芯片组成的单一智算集群，兼容了昆仑芯、昇腾、海光 DCU、英伟达、英特尔等国内外主流 AI 芯片的混合训练，并全面适配。同时通过「控制台」轻松一键发起，易用性很高。百舸 4.0 还通过大模型训推加速套件 AIAK 支持了更多使用场景、多种模型架构和主流训推方式，全能属性拉满。

当然，对于不同规模的多芯混合训练任务，百舸 4.0 将性能损失拉到业界最低，其中百卡性能损失控制在 3%，万卡性能损失在 5% 以内。

**如果说多芯混训是走出算力卡脖子的关键一步，那么接下来就要集中精力考虑如何围绕集群部署、大模型训推和效果调优来更充分地释放万卡集群的算力潜能**。

现在，百舸 4.0 帮助客户省去了大量复杂和琐碎的配置和调试工作，最快 1 小时便能创建万卡规模集群，这要比行业通常需要的数天甚至数周快得多。

然后便又是 AIAK 发挥了用武之地，针对主流开源大模型在并行策略、显存、算力等层面进行了深度优化，为万卡集群下的大模型训推加速注入新的驱动力。

一方面，百舸 4.0 在大模型加速层全新升级了 AIAK 训练加速，万卡集群下支持万亿参数 MoE 模型训练。不仅如此，单个芯片的效能也发挥到了极致，配合使用优化后的通信和并行策略，整体训练效率提升了 30%。这些都预示着集群实力的大增。

另一方面，百舸 4.0 同样升级了 AIAK 推理加速，尤其在速度和成本两个客户最关心的方面加码，效果较以往版本有了质的提升。对于长文本推理任务，模型如今可以做到「极速生成」与「秒回」，效率提升了一倍。同时，投机式推理策略的引入可以先让成本低的小模型生成多个预选结果，然后交给成本高的大模型验证并给出最终结果，从而调动更多便宜的小模型来承担计算负担，由此降低了成本。

当然实际运行中需要面对数据清洗、生成、格式对齐等重复性工作，百舸 4.0 具备的数据工程能力可以调用大模型来处理这些工作。此外提供了数据增强、效果评估和 Prompt 优化等功能，以便进一步调优。

**大模型调用全流程尤其是训练阶段不单单要求速度快，稳定性同样重要。如果一个集群无法保证稳定的训练时长，易出错、难纠错、诊断慢、恢复时间长，则会对整体效率和成本造成不利影响**。目前，百舸 4.0 在万卡规模 AI 任务上的有效训练时长占比已经达到 99.5%，这意味着昂贵的计算资源可以得到最大化利用，浪费更少，成本效益更高。

最后，**算力资源利用率的高低一定程度上决定了集群能不能为客户省钱，当前行业平均水平仅能达到 50%，一半的算力被浪费了**。借助自研的训推一体技术，百舸 4.0 让集群同时支持在线推理服务部署和离线训练任务，训推之间的算力自由切换，训推场景在不同时间复用相同的 GPU 资源，并在推理时将高算力高显存的训练卡分配给多个业务应用，最终将算力资源利用率提升到了 90%。

可以说，从支持多芯混训到加速大模型训推、逼近 100% 的有效训练时长和远超行业的算力资源利用率，百舸 4.0 交出了一份亮眼的「成绩单」，为客户当前的大模型落地实践尽最大可能解除算力层面的后顾之忧，势必更能赢得他们的青睐。

**背后的路线思考**

**五大维度完成算力破局**

如何在大模型时代发挥出大集群的有效算力，这是一个重大而急迫的命题。当前有能力提供万卡集群的云厂商都在力争脱颖而出，这就要求他们在优化架构、降低成本、提供差异化服务、构建智算生态等各个方面出击，找到算力破局关键点。

全新升级的百舸 4.0，提供了当前万卡集群的最优解。 

我们发现，**百舸已经形成自己的一套成熟打法，针对能耗有效率、单卡算力有效率、并行扩展有效率、有效训练时长和资源利用率等五大行业痛点问题，对症下药，用技术突破为算力释放保驾护航**。

针对大模型训练产生的巨大电力消耗，百度云通过在自建的数据中心采用自研的液冷方案，使得机器性能提升 10% 的同时故障率降低了 60%-70%，从而令数据中心能源效率指标 PUE（Power Usage Effectiveness）平均值小于 1.1，优于业界平均水平。

为了提升集群内单卡算力有效率，百舸 4.0 依托 AIAK 训练加速方案，通过显卡、算力等层面的深度优化，在主流开源大模型训练任务中将 GPU 有效利用率 MFU（Model FLOPS Utilization）提升到了行业领先水平，达到 70% 以上。

单卡算力效能极致「压榨」的同时，多卡并行计算效率也要跟上。现阶段大模型往往采用多个计算资源同时训练的并行方式，并发展出了计算资源利用率高、效率高、开发难度小的自动并行策略，使训练任务在多个计算单元上的分配更为合理和高效。百舸 4.0 通过 AIAK 进一步优化了并行策略，较开源方案实现了 30% 的性能提升。同时模型并行策略调优时间也大幅降低，从小时级缩短至如今的分钟级，加快了训练和优化速度。

此外如上所述，百舸 4.0 在万卡任务上实现了 99.5% 的有效训练时长，最大程度避免因频繁故障而导致的训练任务中断、资源浪费、模型收敛速度慢、运维成本增加等问题，集群稳定性得到前所未有地加强。达成这一效果主要得益于以下几大能力的共同加持：

*   全方位的可观测能力，对资源池、队列、节点、任务、实例、加速卡等多个维度实现了无死角的覆盖。
    
*   自动容错能力，百舸 Flash Checkpoint 故障恢复机制实现秒级 Checkpoint 和近乎无损的 Step 粒度容错。此外为 PyTorch 大模型训练场景开发的 Checkpoint 框架 FlashCKPT 可以实现 1 秒千亿大模型 Checkpoint 写入。
    
*   故障诊断和快速恢复能力，通过快速筛查、召回集群硬件故障并隔离自愈，避免在故障芯片上分配工作负载，有效降低任务故障发生频次。故障恢复时间从小时级降至分钟级。
    
*   百舸集群级集合通信库 BCCL 不仅可以在故障发生时做到秒级感知和定位，提高故障处理效率。同时快速定位训练慢的节点，提升整体训练效率。
    

同样地，百舸 4.0 算力资源利用率突破 90%，除了自研的训推一体技术，还要归功于弹性伸缩机制、弹性层级队列等技术，可以根据训练任务的变化来自动分配和布局算力，从而将利用率拉到了行业最高水平。

在我们看来，五大维度不仅巩固了百舸 4.0 在万卡集群时代的行业领先地位，也为其他云厂商在算力资源管理以及智算集群的设计、调度、容错等方面提供了一定的借鉴。

**写在最后**

今年 9 月初，马斯克宣布旗下 xAI 打造的由 10 万块 Nvidia H100 组成的超级训练集群 Colossus 正式上线，并将在未来几个月另外增加 10 万块 GPU（一半为 H200）。这释放出了一种很明显的信号：不止万卡，更大规模的 10 万、数十万卡集群的建设「时不我待」。

可以看到，无论是为现阶段超大规模模型的训练提供算力支撑，还是推动大模型技术的进一步落地普及、以及加速未来 AGI 时代的更快到来，集群的作用似乎已经无可取代，对于企业依托大模型的智能化转型也至关重要。

显然，百度早在 2021 年就意识到了这一点，通过全方位布局百舸 AI 异构计算平台来建设大模型时代的 AI 基础设施，并在算力、通信、能效等方面的持续优化中构筑起更坚实的 AI 生态发展基石。

百舸 4.0 的全新发布，既有助于增强百度 AI 基础设施的可持续性与领先性，还会为客户在业务场景中落地大模型应用尽可能地降本增效，更对大模型引领的 AIGC 爆发以及 AI 普惠铺平道路。

未来，随着集群规模的继续扩大，还会出现更复杂的软硬件协同、算力调度等问题，这些都需要通过持续的技术突破来一一克服。面对挑战更大的算力之争，百舸已经做好了准备。

© THE END