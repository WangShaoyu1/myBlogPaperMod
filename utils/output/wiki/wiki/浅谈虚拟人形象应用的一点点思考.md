---
author: "王宇"
title: "浅谈虚拟人形象应用的一点点思考"
date: 十一月09,2023
description: "李梦阳"
tags: ["李梦阳"]
ShowReadingTime: "12s"
weight: 355
---
*   1[1\. 写作背景](#id-浅谈虚拟人形象应用的一点点思考-写作背景)
*   2[2\. 产品现状](#id-浅谈虚拟人形象应用的一点点思考-产品现状)
*   3[3\. 问题本质](#id-浅谈虚拟人形象应用的一点点思考-问题本质)
*   4[4\. 如何打造拟人化设计](#id-浅谈虚拟人形象应用的一点点思考-如何打造拟人化设计)
    *   4.1[4.1. 视觉化设计](#id-浅谈虚拟人形象应用的一点点思考-视觉化设计)
    *   4.2[4.2. 个性化语音](#id-浅谈虚拟人形象应用的一点点思考-个性化语音)
    *   4.3[4.3. 情感化交互](#id-浅谈虚拟人形象应用的一点点思考-情感化交互)
    *   4.4[4.4. 个性化服务和推荐](#id-浅谈虚拟人形象应用的一点点思考-个性化服务和推荐)
    *   4.5[4.5. 互动娱乐性](#id-浅谈虚拟人形象应用的一点点思考-互动娱乐性)
*   5[5\. 拟人化的风险与挑战](#id-浅谈虚拟人形象应用的一点点思考-拟人化的风险与挑战)
*   6[6\. 对未来的一些展望](#id-浅谈虚拟人形象应用的一点点思考-对未来的一些展望)
*   7[7\. 总结](#id-浅谈虚拟人形象应用的一点点思考-总结)

1\. 写作背景
========

从3月份虚拟人在炉端上的第一个版本，到7月16日全面推向种子用户，五个月的打磨，虚拟人成功完成内部从0~1的过程。然而，虽然在万得厨上搭载虚拟人已成为现实，但许多用户以及很多公司同仁只是**将其视为一个普通的语音助手**，缺乏对其虚拟人形象的充分认知。因此，如何成功的突出虚拟人形象，让用户真切的**感受到虚拟人的存在**，成为了我们面临的一个重要产品设计挑战。如果说我们过去的五个月致力于通过虚拟人解放双手，那么接下来我们虚拟人的发展就不仅是解放双手，应该是**解放双手的同时，也解放了大脑。**

2\. 产品现状
========

优点：

1）语音指令丰富，现已支持指令37条，相似指令3000+条，能做到解放双手、一语即答的良好体验效果

2）丰富的虚拟人知识问答，现有知识问答1800+条，涵盖服务助手、商品知识、美食推荐、万得厨硬件等多个方面

3）丰富的闲聊技能，支持查天气、查股票、热点新闻等18个闲聊技能

缺点：

1）指令、问答不够口语化

2）虚拟人形象应用不够丰富，更像是一个聚焦操控类的语音助手

3）拟人化程度不够

4）应用场景不够丰富

上面所列举的这四个缺点，也在种子用户那里得到了**“强有力”**的数据支撑，日活堪忧。如果说指令、知识问答的口语化是我们不可控的，需要第三方公司提供稳定的能力才能得以从根源上改进这个问题，那么虚拟人形象应用、应用场景不够丰富、拟人化程度不够则是我们当下所能控制的，因此在接下来的篇幅里，我会主要针对这三个问题进行设计分析

3\. 问题本质
========

每当遇到问题的出现，我们时常会说需要透过现象看本质，那么当前在万得厨上搭载了虚拟人，为什么会出现大家始终把它生硬的理解为一个语音助手、语音产品？其实问题的本质还是在**当前虚拟人不够像“人”**，我们深析一下虚拟人这三个字，将这三个字做一个拆分，我们可以发现，最重要的是“人”这个字，以及“拟人”这个词，虚拟数字人行业发展主要受技术驱动和需求指引，核心其实就是**拟人化**。虚拟人物在现实生活中表现出**与人的互动性**，是数字虚拟人区别于影视作品形象的重要特征。虚拟人的发展方向在于**交互能力**的提升和**形象呈现**的进步，拟人化是发展的核心，表现为**对真人的替代能力**。因此如果抓住其拟人化的本质，虚拟人在万得厨应用端有望迎来全面催化。那么如何让我们影子虚拟人更像人呢？下面娓娓道来

4\. 如何打造拟人化设计
=============

拟人化的打造，并非只是形象上的拟人，不能只是长的像人，我们需要将虚拟人赋予拟人的特征和行为，使其更加接近真实人类的形象和行为方式。拟人化是指将非人类的事物或概念赋予人类的特征和属性，使其具备人类的思维、情感和行为能力。基于此，我将从视觉化设计、情感化交互、个性化服务和推荐、互动娱乐性、个性化语音5个方面展开叙述

4.1. 视觉化设计
----------

这一块的工作主要是虚拟人公司去做设计，我们主要负责在炉端界面的设计，下面是我们可以进行的需求设计：

1）外貌和形象设计：

*   外貌特征：当前万得安与万得美完全是以卡通化的形象所出现，以后考虑设计一个与人类相似但又不过于真实的外貌特征，可以选择使用简化的人形图像或者卡通形象（区别于现在的万得安和万得美），以避免**过于逼真**而引起用户的不适感。
*   色彩和造型：选择鲜明的色彩和独特的造型，以增加虚拟人的可辨识性和吸引力。
*   动画效果：为虚拟人设计一些动画效果，例如眨眼、微笑、摇头等，以增加互动感和生动性。

2）表达和交流设计： 

*   面部表情：设计一组**表情符号或图标**，用于表达虚拟人的情感，例如笑脸、惊讶、生气等，可以通过简单的线条和颜色来呈现。
*   肢体语言：后期考虑为虚拟人设计更多的肢体动作，例如举手、点头、鞠躬等，以增加交流的多样性和可视化效果。
*   文字和图像：虚拟人可以通过在显示屏上展示文字或图像的方式，与用户进行信息交流和提示。这一块在接下来的规划中会迭代上去，使用A+编辑器可以实现多模态的信息输出。

3）用户界面设计：

*   显示屏设计：在最新的万得厨炉端设计中，界面是以主题的形式供用户进行选择，在虚拟人的主题设置页面中，为虚拟人提供了显示屏，用于展示虚拟人的形象、表情和交流内容。显示屏的尺寸和分辨率根据万得厨的实际情况进行了设计。
*   用户界面布局：需要设计一个简洁、直观的用户界面，让用户可以方便地与虚拟人进行互动。界面上应包括虚拟人的形象和交互元素（形象切换、动作切换等），以及与万得厨相关的操作按钮和显示信息。

4.2. 个性化语音
----------

在智能家居设备上进行个性化的语音设计，是一个重要且复杂的任务，这里需要涉及到多方面的考量，避免由于思考不清而造成的突兀感，甚至恐怖感，从而导致用户流失，下面是一些设计思考：

1）**定义目标用户和画像**：进行深入的用户研究，包括调查、访谈、人机交互分析等，从而了解目标用户的特征、偏好和需求。我们可以根据这些数据，创建用户画像，明确目标用户的年龄、性别、职业、文化背景等细节，以便为他们设计合适的个性化语音。

2）**声音选择和品牌定位**：根据用户画像和产品定位，选择适合的声音特点。可以考虑声音的音调、音色、节奏等因素。例如，对于家庭使用的万得厨，可能更适合选择一种温暖、友好和亲切的声音。

3）**剧本和对话设计**：编写剧本（场景、类多轮）和**对话流程**，考虑用户的常见操作和需求，这一块需要跟内容组进行深度合作，使用简洁、清晰和自然的语言，避免使用复杂或晦涩的术语。同时，确保语音提示和指令易于理解和执行。我们可以进行用户测试和评估，以验证对话流程的有效性和可理解性。

4）**情感表达和语音特效**：根据用户情绪和使用场景，设计虚拟人的情感表达和语音特效。例如，在烹饪完成时，可以使用愉悦的语气和音效来提醒用户。这些情感表达和特效可以增加用户的参与感和情感连接，提升用户体验。

4）**语音合成技术选择**：选择适用的语音合成技术，以确保语音的自然度和流畅性。当前只能使用科大的语音，后期有必要我们可以预研一下思必驰、云知声、百度等。同时，继续从埋点数据上关注**语音合成的速度和实时性**，以便在用户操作时能够及时响应。

5）**用户测试和反馈收集**：我们继续小范围的进行测试，比如团队内部，进行用户测试，观察用户的反应和行为。收集用户的反馈和意见，例如通过问卷调查、用户访谈或用户行为分析等方式。根据用户反馈，进行改进和优化，以提供更符合用户期望的语音体验。

6）**持续改进和更新**：我们继续通过神策埋点数据，通过各类语音指标，持续改进和更新虚拟人的个性化语音设计。定期收集用户数据和反馈，分析用户行为和使用模式，以便进行相应的优化和更新。

4.3. 情感化交互
----------

其实当前一款前沿的AI产品，除了自身成熟的应用功能、个性化功能这些基础条件外，往往打动用户使用这样一款前沿产品的，其实是用户对于产品第一眼的视觉冲击反应，也就是我们所说的情感化需求里面的第一层，即：本能层。对于本能层，设计师需要在符合功能需求的前提下，尽可能的给用户带来**听觉、视觉、触觉的感官刺激**，极力去促成用户与产品的 “一见钟情”。好比我们看见一个漂亮的女孩，还没有了解她的人品，但是就已经被抓住了眼球，单纯的被外貌所深深吸引，然后就有了进一步了解的欲望。所以一个产品给到用户的第一眼感官刺激很重要。

情绪价值需要结合场景化的情感设计去提供。那情感化设计有哪些核心要点呢？

**本能层：表象的直接反应（感官刺激）**

是用户对产品的视觉和第一印象的本能直接反应。比如用户第一眼被产品的外观所吸引，从而对产品产生想要了解和触碰的冲动。本能层次是**先于思考和逻辑判断**的。

**行为层：交互的行为关系（细节引导）**

用户与产品在行为上产生的交互关系，**具备一定的理性和逻辑感**。比如用户在使用这个产品会从操作流程中产生评价，也会产生因为操作设计不合理而产生负面情绪。

**反思层：情感的反思共鸣（认知共鸣）**

体现在产品的独特内涵、品牌差异性在用户的心中根植下**独有的记忆**，用户因为这份记忆会**触发情感共鸣**，从而忠实于产品。用户会产生有意识的考虑和基于经验的反思。

关注不同的人群在情感化需求上到底需要什么？怎么能做到恰到好处，关键点有以下几个方面考虑:

*   研究用户需求和场景: 了解用户在不同场景下的需求和情绪状态，可以从宏观和微观的角度去洞察不同人群细分情绪状态，比如: 一个单身的在外漂泊的独居女性，面对很大的工作压力，无人倾诉她需要什么？
*   设计人性化的界面和交互: 通过界面设计和交互设计来传递情感和情绪。例如: 使用温暖、舒适的色彩和图像，采用流畅、自然的动态和过渡，创造亲切、友好的界面和体验，让用户感到愉悦和舒适。
*   提供更多个性化的服务和反馈：根据用户的兴趣、偏好和行为习惯，提供个性化的服务和反馈。例如: 推荐个性化商品，打造专享虚拟人，用最熟悉的语言和声音进行交互对话。
*   引入情感化的语言表达话术: 在产品的语言和表达上，运用情感化的元素，例如使用幽默、温情、鼓励等方式来与用户进行互动，增加用户的情感共鸣和参与度，减少冷漠、机械的语言。
*   关注用户体验的细节: 细节决定成败，注意产品各个环节和细节，为用户提供细致入微的关怀，关注性能体验、交互体验、视觉体验。例如: 出错提示时，给予用户友好和理解的反馈，避免让用户感到沮丧和困惑。

  

当前我们将万得厨定义为一款AI智能家用设备，搭载虚拟人，那么作为一款AI产品，我们必须要考虑到情感化的设计，它可以提升用户体验，增加产品亲和力，改善沟通效果，促进用户的情感参与，从而让用户对我们的产品产生一定的依赖性，**提高设备在线率。**从虚拟人的角度看，我们也需要让我们的虚拟人有情感、有温度，更加的拟人化。那么我们如何去进行情感化的交互设计？从情感上的闭环来讲，主要从以下五个方面进行设计，且看下图：

[Edit Edit](/plugins/namymap/shownamymapeditor.action?mindmapName=%E6%83%85%E6%84%9F%E5%8C%96%E4%BA%A4%E4%BA%92%E8%AE%BE%E8%AE%A1&lastPage=%2Fpages%2Fviewpage.action%3FpageId%3D109249969&pageId=109249969&isViewMode=false) [Show Show](/plugins/namymap/shownamymapeditor.action?mindmapName=%E6%83%85%E6%84%9F%E5%8C%96%E4%BA%A4%E4%BA%92%E8%AE%BE%E8%AE%A1&lastPage=%2Fpages%2Fviewpage.action%3FpageId%3D109249969&pageId=109249969&isViewMode=true) Remove Remove //<!\[CDATA\[ jQuery("#84003").mousedown(function(e) { var parameters = {width: 700, height: 180, id: "remove-dialog", closeOnOutsideClick: false}; var dialog = new AJS.Dialog(parameters); var originalPopupHide = dialog.popup.hide; dialog.popup.hide = function() { anyDialogVisible = false; originalPopupHide.apply(this, arguments); AJS.trigger("hide.dialog", {dialog: dialog}); }; dialog.addHeader("Map remove confirmation"); dialog.addPanel("Confirmation", "<p>Your map will be deleted from the page and from attachments. Do you really want to remove your map?</p>", "remove-dialog-body"); dialog.addButton("Yes", function (dialog) { var url = "/plugins/namymap/removenamymap.action?mindmapName=%E6%83%85%E6%84%9F%E5%8C%96%E4%BA%A4%E4%BA%92%E8%AE%BE%E8%AE%A1&amp;lastPage=%2Fpages%2Fviewpage.action%3FpageId%3D109249969&amp;pageId=109249969"; window.location.href = url.replace(/&amp;/g, "&"); }); dialog.addCancel("No", function (dialog) { dialog.hide(); }); dialog.show(); }); //\]\]>

[![](/download/attachments/109249969/%E6%83%85%E6%84%9F%E5%8C%96%E4%BA%A4%E4%BA%92%E8%AE%BE%E8%AE%A1.png?version=3&amp;modificationDate=1693292228437&amp;api=v2)](/plugins/namymap/shownamymapeditor.action?mindmapName=%E6%83%85%E6%84%9F%E5%8C%96%E4%BA%A4%E4%BA%92%E8%AE%BE%E8%AE%A1&lastPage=%2Fpages%2Fviewpage.action%3FpageId%3D109249969&pageId=109249969&isViewMode=true)

1）用户情感识别：

*   语音情感识别：使用语音识别技术，将用户的语音输入转换为文本，并应用情感分析算法，如基于深度学习的情感分类模型，来识别用户的情感状态，这一块需要跟语音厂商或者虚拟人公司进行洽谈。
*   面部表情识别：通过摄像头捕捉用户的面部表情，然后应用计算机视觉技术，如面部表情分类模型，来分析用户的情感状态。这一块国内商汤科技、旷世科技做的比较好。

2）情感反馈：

*   音频反馈：根据用户的情感状态，虚拟人可以播放相应的音频来改善用户体验。例如，当用户感到焦虑或生气时，虚拟人可以播放舒缓的音乐或提供温和的语音提示，以帮助用户放松情绪。
*   触觉反馈：我们可以设想，虚拟人可以通过震动或触觉反馈提供额外的情感反馈。例如，当用户感到兴奋或快乐时，虚拟人可以通过轻微的震动或触觉提示来增强用户的情感体验。

3）个性化推荐：

*   基于情感状态的推荐：通过分析用户的情感状态和偏好，虚拟人可以提供个性化的烹饪建议和食物推荐。例如，当用户感到疲倦时，虚拟人可以推荐健康的食物选项，或提供烹饪建议以提高用户的精力和情绪。
*   基于用户历史数据的推荐：虚拟人可以通过分析用户的历史烹饪数据和偏好，提供更准确的推荐。例如，根据用户过去的喜好和评价，虚拟人可以推荐特定的烹饪时间和功率设置，以满足用户的口味和需求。

这一块会在下一部分进行详细阐述

4）情感交流：

*   对话系统：集成现有科大、虚拟人公司的自然语言处理技术和对话系统（这一块还需要继续预研），使虚拟人能够与用户进行语音或文字对话。通过理解用户的问题和需求，虚拟人可以提供相关的回答和建议，并与用户进行情感化交流。
*   情感表达：虚拟人可以通过语音、音调和语气等方式来表达情感，以更好地与用户进行情感化交流。例如，当用户感到寂寞时，虚拟人可以通过温暖而友好的语音表达和关心的对话内容，提供陪伴和安慰。

5）情感化设计：

*   色彩和界面设计：选择温暖和舒适的色彩主题，如柔和的蓝色或温暖的橙色，来营造积极的情感氛围。界面设计应简洁、直观，并注重用户友好性。
*   图标和动画：使用可爱、引人入胜的图标和动画，以增加虚拟人的亲和力和趣味性。这些图标和动画可以与用户的情感状态相匹配，以增强用户的情感体验。

**需要注意的是，情感化交互应该是可选的，并且尊重用户的隐私和个人喜好。用户可以自由选择是否启用情感化功能，并有权控制其情感数据的收集和使用。因此这一块我们可做成配置项。**

4.4. 个性化服务和推荐
-------------

承接上一部分的情感设计里面提到的第三点，个性化推荐。个性化服务和推荐除了能使我们的虚拟人更加拟人化，变的有温度的同时还可以使我们的产品更加智能化，下面是相关的设计思考：

1）用户数据收集：

*   通过虚拟人与用户的互动，收集用户的偏好、习惯、饮食偏好、烹饪喜好等数据。这一块需要与万得厨团队进行深入合作、交流。
*   可以设计用户注册表单，要求用户填写基本信息和偏好，以及允许用户授权收集历史交互数据。
*   通过用户调研和问卷调查，获取更具体的用户偏好和需求信息。
*   与数据中台合作，对用户数据进行收集、清洗和存储，以建立用户偏好数据库。

2）个性化偏好建模：

*   基于收集到的用户数据，进行个性化偏好建模。
*   使用机器学习和数据挖掘技术，对用户数据进行分析和建模，以了解用户的喜好、习惯和特征。
*   可以采用聚类算法将用户分组，或者使用分类算法对用户进行标签化和个性化分类。

3）推荐算法设计：

*   设计个性化推荐算法，根据用户个性化偏好模型，为用户提供个性化的服务和推荐。
*   可以采用协同过滤算法，通过用户相似度或项目相似度进行推荐。
*   结合内容推荐算法，根据用户的历史数据和实时交互，为用户推荐适合他们口味和需求的食谱、烹饪方法等。
*   优化算法，考虑推荐结果的多样性、新颖性和可解释性，以提高用户满意度和推荐效果。

4）实时反馈和调整：

*   通过虚拟人与用户的实时互动，收集用户的反馈和评价。当前神策埋点数据能支持。
*   利用这些反馈数据，不断优化个性化服务和推荐算法，提高推荐准确性和用户满意度。
*   可以使用A/B测试和用户调研等方法，评估和改进推荐算法的效果。

5）多渠道推广：

*   将个性化服务和推荐功能与万得厨的其他功能紧密结合，提供全方位的用户体验。
*   在产品宣传和推广中，突出个性化服务和推荐的独特价值，吸引用户的注意和兴趣。后续我们需要与运营团队保持频次较高的沟通。
*   可以通过社交媒体、广告、公众号等渠道，传播产品的个性化服务和推荐功能。

6）数据保护与隐私：

*   在收集和处理用户数据时，应遵守相关隐私政策和法规。
*   确保用户数据的安全性和隐私保护，采取适当的数据加密和存储措施。
*   建立用户信任，明示用户数据的使用目的，并提供用户选择和控制的机制。

7）持续改进和创新：

*   我们紧跟用户需求和市场变化，不断改进和创新个性化服务和推荐功能。
*   通过不断学习和应用新的技术和算法，提升产品竞争力。
*   可以跟踪用户反馈和市场趋势，进行产品迭代和改进，以满足用户的不断变化的需求。

4.5. 互动娱乐性
----------

从我们当前的运营反馈来看，有很多“爱幼”场景我们考虑的不是很周全，小孩子无法跟我们的虚拟人进行娱乐互动，**久而久之会觉得有一种生疏感，甚至觉得恐怖**，使得我们产品的**用户黏性不足**。除此之外，烹饪也是一个相对耗时的一项任务，因此我们也可以利用烹饪的这一段时间，去设计一些娱乐互动功能帮助用户去消磨度过这一段时间，从而**提升用户体验、建立品牌形象以及增加用户黏性，并提供差异化的销售点**。具体的设计思考如下：

1）**音乐播放功能**：在万得厨上搭载一个音乐播放器，用户可以通过语音指令或控制面板选择喜欢的音乐，从而在烹饪过程中享受音乐。

2）**互动游戏功能**：开发一系列简单而有趣的游戏，用户可以与虚拟人一起玩耍。例如，猜谜游戏、拼图游戏或记忆游戏等，以增加烹饪时的娱乐性。

3）**食谱分享和推荐**：提供用户分享和浏览其他用户分享的食谱的功能。用户可以通过虚拟人的指导，获取其他用户的烹饪经验和创意，从而获得更多的烹饪灵感和娱乐，这一部分相对长远，但也可以纳入考虑范围之类。

4）**音效和互动反馈**：通过添加音效和互动反馈，增强用户与虚拟人的互动体验。例如，虚拟人可以用幽默的语言回应用户的指令或操作，提供更加生动和有趣的互动。

5）**故事讲述功能**：提供一些有趣的故事或短篇小说，用户可以在烹饪过程中聆听。这可以为用户带来娱乐和放松的体验。

6）**聊天功能**：让虚拟人具备一定的聊天的能力，用户可以与其进行简单的对话。这可以包括问候、打趣或提问等，为用户提供一种轻松和有趣的互动方式，这一块需要丰富一下我们的娱乐知识问答。

7）**互动提示和技巧**：在烹饪过程中，虚拟人可以提供实用的烹饪提示和技巧，例如烹饪时间、食材搭配建议等。这可以帮助用户提升烹饪技能并增加娱乐性。

娱乐互动这一块经过前期的预研调研，可以接入科大闲聊技能做以支持，具体可见文档：[科大闲聊技能体验测试](/pages/viewpage.action?pageId=105273222)。上面提到的7点娱乐方案，除了第3点，其他皆可接入科大闲聊，涉及到新源接入的需要商务做谈判。那么在这一块会有一个瓶颈，就是在**烹饪中我们万得厨的噪音较大，具体带来的娱乐互动体验有多好，还需要打个问号。**

5\. 拟人化的风险与挑战
=============

我们整篇文章都在提拟人化，那么需要做到拟人化，必将会带来巨大的挑战，无论是产品设计还是技能挑能力，都将面临巨大挑战，除此，我们当前需要在虚拟人拟人化这一块发力，那么拟人化就一定好吗？或者说如果过于拟人化了，会带来什么样的风险呢？这里就需要提一下恐怖谷效应，**什么是恐怖谷效应，简单解释一下：恐怖谷效应是一种人类心理学现象，指当人类感知到某种程度的不寻常或威胁性的刺激时，会引起一种强烈的情感反应，通常表现为恐惧、不安、紧张等。这种现象最初由日本机器人专家森政弘提出，用于解释人类对于机器人和类人生物的恐惧感。**

因此当人类面对**过度拟人化但又不完全达到真实人类外貌或行为的人工智能、机器人或虚拟角色时**，会在情感上感到不适或抵触。这种不适感随着拟人化程度的增加而逐渐加深，形成一个“谷底”，然后随着拟人化程度的提高而逐渐减弱。以虚拟人为例，当虚拟人的外貌和行为与真实人类相似度较低但又足够接近时，人们可能会感到不舒服、恐惧甚至恐慌。这是因为虚拟人在外貌和行为上与真实人类存在微小的差异，足够引起人们的注意和不适感。

这种不适感可能源于人类的本能反应和社会认知。人类在进化过程中，**对于与自己相似但又不完全相同的人类外貌和行为会产生警觉和不信任感**。此外，人们通常会将人工智能、机器人或虚拟角色归类为非生物体，因此在其过度拟人化时可能引发人们的不适感。 虚拟人拟人化程度的提高可以缓解恐怖谷效应。当虚拟人的外貌和行为足够接近真实人类，使人们能够轻松地将其视为“人类”，不再感到不适或抵触。这种情况下，虚拟人更容易获得用户的接受和情感连接，提高产品的可用性和用户满意度。

那么我们作为产品经理，在设计虚拟人时需要注意恐怖谷效应。避免过度拟人化，尽量让虚拟人的外貌和行为与真实人类保持一定的差异，以减少用户的不适感。同时，通过用户研究和反馈来了解用户对虚拟人的接受度和舒适度，及时进行调整和改进。最终目标是在虚拟人的设计中找到一个平衡点，既能满足用户的期望，又能避免恐怖谷效应的影响。当前阶段，我们主要存在以下的挑战和风险：

1）**技术挑战**：实现高度拟人化的虚拟人需要先进的人工智能和自然语言处理技术。这些技术在目前可能还无法完全满足高度拟人化的需求，包括语音识别的准确性、自然语言理解的广度和深度以及情感分析的准确度等方面。因此，技术挑战是一个需要克服的问题。

2）**用户隐私保护**：虚拟人过于拟人化可能会引发用户隐私保护的问题。当虚拟人与用户进行对话时，可能会涉及用户的个人信息和隐私，如饮食习惯、食物偏好等。因此我们产品经理需要确保虚拟人的设计和实现符合相关隐私法规，同时提供透明的隐私政策和明确的用户控制权限，以保护用户的隐私。

3）**用户依赖和沉迷**：过度拟人化的虚拟人可能会导致用户对其过度依赖和沉迷，从而影响用户自主思考和判断能力。用户可能会将虚拟人的建议和决策视为绝对正确，而忽略其他信息来源和自身的判断能力。所以我们产品经理需要在设计中平衡虚拟人的角色和权威性，强调它只是一个辅助工具，而非替代人类的思考和决策能力

4）**用户接受度和舒适度**：某些用户可能对虚拟人过于拟人化感到不舒服或抵触。他们可能不希望与虚拟人建立过于亲密的关系，或者担心虚拟人的存在和行为会侵犯他们的隐私。产品经理需要通过用户研究和反馈来了解用户的需求和偏好，以确保虚拟人的设计符合用户的接受度和舒适度。

5）**法律和伦理问题**：过于拟人化的虚拟人可能会引发一些法律和伦理问题。例如，如果虚拟人被误导或滥用，导致用户受到伤害或经济损失，那么我们产品经理可能会面临法律责任。此外，虚拟人的行为和决策也需要符合道德和伦理的标准，不能误导用户或违背用户的价值观。

6\. 对未来的一些展望
============

谈到未来，当前我们永远离不开大模型这个时代产物，那么我们虚拟人如何与大模型进行结合呢？我们可以结合并发力的一个点是：**虚拟人多模态交互能力的提升**。我们先看下图：

**多种唤醒方式**

**图像**

**语音**

**空间感知**

**肢体感知**

**表情感知**

**......**

**语气**

**语义**

**......**

**输入**

%3CmxGraphModel%3E%3Croot%3E%3CmxCell%20id%3D%220%22%2F%3E%3CmxCell%20id%3D%221%22%20parent%3D%220%22%2F%3E%3CmxCell%20id%3D%222%22%20value%3D%22%22%20style%3D%22shape%3DflexArrow%3BendArrow%3Dclassic%3Bhtml%3D1%3Bwidth%3D4%3BendSize%3D7.33%3B%22%20edge%3D%221%22%20parent%3D%221%22%3E%3CmxGeometry%20width%3D%2250%22%20height%3D%2250%22%20relative%3D%221%22%20as%3D%22geometry%22%3E%3CmxPoint%20x%3D%22-170%22%20y%3D%22-160%22%20as%3D%22sourcePoint%22%2F%3E%3CmxPoint%20x%3D%22-130%22%20y%3D%22-160%22%20as%3D%22targetPoint%22%2F%3E%3C%2FmxGeometry%3E%3C%2FmxCell%3E%3C%2Froot%3E%3C%2FmxGraphModel%3E%3CmxGraphModel%3E%3Croot%3E%3CmxCell%20id%3D%220%22%2F%3E%3CmxCell%20id%3D%221%22%20parent%3D%220%22%2F%3E%3CmxCell%20id%3D%222%22%20value%3D%22%22%20style%3D%22shape%3DflexArrow%3BendArrow%3Dclassic%3Bhtml%3D1%3Bwidth%3D4%3BendSize%3D7.33%3B%22%20edge%3D%221%22%20parent%3D%221%22%3E%3CmxGeometry%20width%3D%2250%22%20height%3D%2250%22%20relative%3D%221%22%20as%3D%22geometry%22%3E%3CmxPoint%20x%3D%22-170%22%20y%3D%22-160%22%20as%3D%22sourcePoint%22%2F%3E%3CmxPoint%20x%3D%22-130%22%20y%3D%22-160%22%20as%3D%22targetPoint%22%2F%3E%3C%2FmxGeometry%3E%3C%2FmxCell%3E%3C%2Froot%3E%3C%2FmxGraphModel%3E

**多模态分析模型**

**动作信息**

**表情信息**

**情感信息**

**重音位置**

**激动程度**

**语言学特征**

**......**

**分析思考**

**输出**

**AI大脑**

**自主学习能力**

**记忆**

**推理和决策能力**

**面部表情**

**声音**

**口型**

**声唇同步**

**肢体动作**

虚拟人未来发展方向

![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij48cGF0aCBkPSJNMjEuOTkgNGMwLTEuMS0uODktMi0xLjk5LTJINGMtMS4xIDAtMiAuOS0yIDJ2MTJjMCAxLjEuOSAyIDIgMmgxNGw0IDQtLjAxLTE4ek0xOCAxNEg2di0yaDEydjJ6bTAtM0g2VjloMTJ2MnptMC0zSDZWNmgxMnYyeiIvPjxwYXRoIGQ9Ik0wIDBoMjR2MjRIMHoiIGZpbGw9Im5vbmUiLz48L3N2Zz4= "Show Comments")

//<!\[CDATA\[ (function() { $ = AJS.$; var graphContainer = document.getElementById('drawio-macro-content-d9b091b1-6a15-4d3c-bf2b-45e56481fdbd'); DrawioProperties = { contextPath : AJS.contextPath(), buildNumber : 8401 }; var readerOpts = {}; readerOpts.loadUrl = '' + '/rest/drawio/1.0/diagram/crud/%E8%99%9A%E6%8B%9F%E4%BA%BA%E6%9C%AA%E6%9D%A5%E5%8F%91%E5%B1%95%E6%96%B9%E5%90%91/109249969?revision=3'; readerOpts.imageUrl = '' + '/download/attachments/109249969/虚拟人未来发展方向.png' + '?version=3&api=v2'; readerOpts.editUrl = '' + '/plugins/drawio/addDiagram.action?ceoId=109249969&owningPageId=109249969&diagramName=%E8%99%9A%E6%8B%9F%E4%BA%BA%E6%9C%AA%E6%9D%A5%E5%8F%91%E5%B1%95%E6%96%B9%E5%90%91&revision=3'; readerOpts.editable = true; readerOpts.canComment = true; readerOpts.stylePath = STYLE\_PATH; readerOpts.stencilPath = STENCIL\_PATH; readerOpts.imagePath = IMAGE\_PATH + '/reader'; readerOpts.border = true; readerOpts.width = '1171'; readerOpts.simpleViewer = false; readerOpts.tbstyle = 'top'; readerOpts.links = 'auto'; readerOpts.lightbox = true; readerOpts.resourcePath = ATLAS\_RESOURCE\_BASE + '/resources/viewer'; readerOpts.disableButtons = false; readerOpts.zoomToFit = true; readerOpts.language = 'zh'; readerOpts.licenseStatus = 'OK'; readerOpts.contextPath = AJS.contextPath(); readerOpts.diagramName = decodeURIComponent('%E8%99%9A%E6%8B%9F%E4%BA%BA%E6%9C%AA%E6%9D%A5%E5%8F%91%E5%B1%95%E6%96%B9%E5%90%91'); readerOpts.diagramDisplayName = ''; readerOpts.aspect = ''; readerOpts.ceoName = '浅谈虚拟人形象应用的一点点思考'; readerOpts.attVer = '3'; readerOpts.attId = '109707647'; readerOpts.lastModifierName = '未知用户 (limengyang)'; readerOpts.lastModified = '2023-08-30 15:21:19.926'; readerOpts.creatorName = '未知用户 (limengyang)'; //Embed macro specific info readerOpts.extSrvIntegType = '$extSrvIntegType'; readerOpts.gClientId = '$gClientId'; readerOpts.oClientId = '$oClientId'; readerOpts.service = '$service'; readerOpts.sFileId = '$sFileId'; readerOpts.odriveId = '$odriveId'; readerOpts.diagramUrl = '$diagramUrl'; readerOpts.csvFileUrl = '$csvFileUrl'; readerOpts.pageId = '$pageId' || Confluence.getContentId(); readerOpts.aspectHash = '$aspectHash'; readerOpts.useExternalImageService = '$useExternalImageService' == 'true'; readerOpts.isTemplate = '$isTemplate' == 'true'; if (readerOpts.width == '') { readerOpts.width = null; } // LATER: Check if delayed loading of resources can be used for image placeholder mode var viewerPromise = createViewer(graphContainer, readerOpts); if(readerOpts.editable) { $(graphContainer).data('viewerConfig', readerOpts); $(graphContainer).on('drawioViewerUpdate', updateDrawioViewer); } viewerPromise.done(function(viewer) { updateCachedDiagram(graphContainer, readerOpts, viewer); }); })(); //\]\]>

当前数字人对语言理解仍以文本为主，接入大模型仍需进行技术转化。AI 驱动数字人是指数字人的语音表达、面部表情和动作形态等通过深度学习模型进行运算，将其结果实时或者离线驱动，并进行渲染。目前我们虚拟人接入大模型以文本交互为主，本质是通过 ASR-NLP-TTS 等 AI 技术进行转化，实现数字人感知、决策、表达等层面的交互，自然语言大模型与虚拟人的融合还需进一步完善。

因此大模型多模态生成能力对虚拟人发展推动潜力巨大，驱动虚拟人“思想”更像人。根据腾讯《数字人产业发展趋势报告（2023）》这篇资料看，**未来 AI 技术的重点方向是在输入端实现多模态感知输入，在输出端提升多模态交互能力**，综合提升数字人的表现力。当前 AI 虚拟人的交互主要表现为文本的交互，未来发展为基于语义的交互，强化对人情绪的感知和表达。

7\. 总结
======

未来已来，唯变不变，行而不辍，未来可期！

  

[Filter table data]()[Create a pivot table](#)[Create a chart from data series](#)

[Configure buttons visibility](/users/tfac-settings.action)