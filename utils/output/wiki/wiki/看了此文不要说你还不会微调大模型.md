---
author: "王宇"
title: "看了此文不要说你还不会微调大模型"
date: 八月21,2023
description: "大模型系列"
tags: ["大模型系列"]
ShowReadingTime: "12s"
weight: 430
---
*   1 [一、下载工程和环境准备](#id-看了此文不要说你还不会微调大模型-一、下载工程和环境准备)
    *   1.1[1.1 ChatGLM-6B是什么？](#id-看了此文不要说你还不会微调大模型-1.1ChatGLM-6B是什么？)
    *   1.2[1.2 安装虚拟的python环境](#id-看了此文不要说你还不会微调大模型-1.2安装虚拟的python环境)
    *   1.3[1.3 克隆代码和安装依赖](#id-看了此文不要说你还不会微调大模型-1.3克隆代码和安装依赖)
    *   1.4[1.4 运行](#id-看了此文不要说你还不会微调大模型-1.4运行)
*   2[二、微调大模型](#id-看了此文不要说你还不会微调大模型-二、微调大模型)
    *   2.1[2.1 整理数据集(官方数据集)](#id-看了此文不要说你还不会微调大模型-2.1整理数据集\(官方数据集\))
    *   2.2[2.2 调整参数](#id-看了此文不要说你还不会微调大模型-2.2调整参数)
    *   2.3[2.3 开始训练](#id-看了此文不要说你还不会微调大模型-2.3开始训练) 
    *   2.4[2.4 微调后结果](#id-看了此文不要说你还不会微调大模型-2.4微调后结果)

一、下载工程和环境准备
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### 1.1 ChatGLM-6B是什么？

ChatGLM-6B是清华大学知识工程和数据挖掘小组（Knowledge Engineering Group (KEG) & Data Mining at Tsinghua University）发布的一个开源的对话机器人。根据官方介绍，这是一个千亿参数规模的中英文语言模型。并且对中文做了优化。本次开源的版本是其60亿参数的小规模版本，约60亿参数，本地部署仅需要6GB显存。

### 1.2 安装虚拟的python环境

ChatGLM-6B 代码中有一些python3.7支持的语法，所以要有python3.7+ 的环境。我们使用conda来管理python环境  
conda分为anaconda和miniconda。anaconda是包含一些常用包的版本，miniconda则是精简版.本文中我们将使用anaconda  
  

### 1.3 克隆代码和安装依赖

[?](#)

`git clone https:``//github.com/THUDM/ChatGLM-6B.git`

`//加载模型到本地`

`git clone https:``//huggingface.co/THUDM/chatglm-6b`

`# 新建chatglm环境`

`conda create -n chatglm python=``3.8`

`# 激活chatglm环境`

`conda activate chatglm`

`nvidia-smi`

`# 根据上一步找到的安装指令进行安装：`

`pip install torch==``1.12``.``1``+cu113 torchvision==``0.13``.``1``+cu113 torchaudio==``0.12``.``1` `--extra-index-url https:``//download.pytorch.org/whl/cu113`

`# 安装gradio用于启动图形化web界面`

`pip install gradio`

`# 安装运行依赖`

`pip install -r requirement.txt`

`import` `torch`

`torch.cuda.is_available()  ## 输出应该是True`

  

### 1.4 运行

![](/download/attachments/105279095/image2023-8-21_16-7-7.png?version=1&modificationDate=1692605228001&api=v2)

  

二、微调大模型
-------

### 2.1 整理数据集(官方数据集)

从 [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing) 或者 [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) 下载处理好的 ADGEN 数据集，将解压后的 `AdvertiseGen` 目录放到本目录下。

### 2.2 调整参数

![](/download/attachments/105279095/image2023-8-21_16-9-7.png?version=1&modificationDate=1692605348136&api=v2)

  

### 2.3 开始训练 

![](/download/attachments/105279095/image2023-8-21_16-13-8.png?version=1&modificationDate=1692605588954&api=v2)

出现该结果则表示训练完毕。

### 2.4 微调后结果

**![](/download/attachments/105279095/image2023-8-21_16-14-13.png?version=1&modificationDate=1692605653219&api=v2)**

![](/download/attachments/105279095/image2023-8-21_16-14-30.png?version=1&modificationDate=1692605670733&api=v2)

  

[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)

[Configure buttons visibility](/users/tfac-settings.action)