---
author: "王宇"
title: "2023.05.11~现有人工智能大模型使用调研"
date: 五月17,2023
description: "郑小涵"
tags: ["郑小涵"]
ShowReadingTime: "12s"
weight: 366
---
  

*   1[1\. 调研目的](#id-2023.05.11~现有人工智能大模型使用调研-调研目的)
*   2[2\. 大模型简介](#id-2023.05.11~现有人工智能大模型使用调研-大模型简介)
    *   2.1[2.1. 概念与特征](#id-2023.05.11~现有人工智能大模型使用调研-概念与特征)
    *   2.2[2.2. 相关概念](#id-2023.05.11~现有人工智能大模型使用调研-相关概念)
    *   2.3[2.3. 其他相似概念](#id-2023.05.11~现有人工智能大模型使用调研-其他相似概念)
*   3[3\. 现有大模型的分类](#id-2023.05.11~现有人工智能大模型使用调研-现有大模型的分类)
    *   3.1[3.1. 文本生成图像 Text-to-Image](#id-2023.05.11~现有人工智能大模型使用调研-文本生成图像Text-to-Image)
    *   3.2[3.2. 文本生成三维模型 Text-to-3D](#id-2023.05.11~现有人工智能大模型使用调研-文本生成三维模型Text-to-3D)
    *   3.3[3.3. 图像生成文本（看图说话） Image-to-Text](#id-2023.05.11~现有人工智能大模型使用调研-图像生成文本（看图说话）Image-to-Text)
    *   3.4[3.4. 文本生成视频 Text-to-Video](#id-2023.05.11~现有人工智能大模型使用调研-文本生成视频Text-to-Video)
    *   3.5[3.5. 文本生成音频 Text-to-Audio](#id-2023.05.11~现有人工智能大模型使用调研-文本生成音频Text-to-Audio)
    *   3.6[3.6. 文本生成文本（聊天机器人） Text-to-Text](#id-2023.05.11~现有人工智能大模型使用调研-文本生成文本（聊天机器人）Text-to-Text)
    *   3.7[3.7. 文本生成代码 Text-to-Code](#id-2023.05.11~现有人工智能大模型使用调研-文本生成代码Text-to-Code)
    *   3.8[3.8. 文本生成科学文本 Text-to-Science](#id-2023.05.11~现有人工智能大模型使用调研-文本生成科学文本Text-to-Science)
    *   3.9[3.9. 其他模型 Other Models](#id-2023.05.11~现有人工智能大模型使用调研-其他模型OtherModels)
*   4[4\. 大模型的使用调研](#id-2023.05.11~现有人工智能大模型使用调研-大模型的使用调研)
    *   4.1[4.1. 国外](#id-2023.05.11~现有人工智能大模型使用调研-国外)
        *   4.1.1[4.1.1. Text-to-Image](#id-2023.05.11~现有人工智能大模型使用调研-Text-to-Image)
        *   4.1.2[4.1.2. Text-to-Text](#id-2023.05.11~现有人工智能大模型使用调研-Text-to-Text)
    *   4.2[4.2. 国内](#id-2023.05.11~现有人工智能大模型使用调研-国内)
        *   4.2.1[4.2.1. Text-to-Text](#id-2023.05.11~现有人工智能大模型使用调研-Text-to-Text.1)
        *   4.2.2[4.2.2. Text-to-Image](#id-2023.05.11~现有人工智能大模型使用调研-Text-to-Image.1)

1\. 调研目的
========

在阿里达摩院发布的《达摩院2023十大科技趋势》报告中，【多模态与训练大模型】与【生成式AI】分别代表底层技术与应用场景被列入了2023年最可能十大科技发展方向。

人工智能大模型（后文简称”大模型“）

  

2\. 大模型简介
=========

2.1. 概念与特征
----------

大模型是人工智能的架构中距离上层应用最近的一层。人工智能的四层架构从下到上分别是：底层芯片、深度学习框架、大模型、上层应用。深度学习框架与大模型的区别：

*   **框架**：开源库，使用框架的目的是为了更好地实现网络模型的搭建。目前常见的深度学习框架有：pytorch（Facebook）、tensorflow（Google）；国内的飞桨paddlepaddle（百度）、mindspore（华为）、oneflow（一流科技）、MegEngine（旷世）、Jittor（清华）。
*   **网络**：简单的结构，不包含任何权重参数。
*   **模型**：在网络上利用数据集进行训练，得到一个包含权重参数的数据，称为模型。（模型比网络更强大）

![](/download/thumbnails/101824243/image2023-5-11_15-36-28.png?version=1&modificationDate=1683790588698&api=v2)

大模型理论最早在2017年由谷歌的《Attention is All You Need》论文中提出。**大模型是深度学习在自然语言处理领域的最新技术**，是继RNN（循环神经网络）、CNN（卷积神经网络）等传统深度学习模型变体之后，在深度学习方向上的又一突破。大模型理论一经推出，即受到了广泛的关注。OpenAI受其启发在2018年6月发布了初代GPT大模型，谷歌紧接其后在2018年10月发布了BERT大模型。时至今日，基于通用大模型进行调参已成为自然语言处理任务的首选范式。

通用大模型具有三大特征：**生成式、预训练和多模态**。

1.  **”生成式“**指能够利用现有的内容生成多种多样格式的新内容；
2.  **”预训练“**指一种开发范式，先通过一批语料进行模型训练，然后在这个初步训练好的模型基础上再继续训练，以“大规模预训练﹢微调”范式满足多元化需求；
3.  **”多模态“**指拥有跨模态语义对齐能力，能够兼融差异化的数据形态，由文本、语音、视觉等单一模态智能向多种模态融合的方向发展。

由于大模型具有**可以将任何输入格式映射到任何输出格式**的特征，因此大模型是**生成式人工智能**的关键。生成式人工智能是指可以生成新内容的人工智能，是基于算法、模型、规则生成文本、图片、声音、视频、代码等内容的技术，也称为AIGC（AI generated content）。生成式人工智能不像早期的专家系统（包含知识库和通过if-else规则数据库生成内容的推理引擎）那样，只是简单地分析或处理现有数据；现代生成式人工智能包含一个在语料库或数据集上训练的鉴别器或转换器模型，能够将输入信息映射到潜在的高维空间，以及一个生成器模型，能够生成随机行为，在每次新试验中创建新内容，甚至从与输入相同的提示中，执行无监督、半监督或监督学习。

大模型可以处理许多更加复杂的任务，比如自然语言处理、图像识别、语音识别等。它通常需要在大规模的计算资源上进行训练，这些数据需要从不同的来源收集，包括互联网、社交媒体、传感器等；并且这些数据需要经过清洗、预处理和标注等步骤，才能用于训练模型。在训练过程中，需要使用分布式计算技术，将计算任务分配到多个计算节点上进行计算，以提高训练速度和效率。

2.2. 相关概念
---------

有监督学习、无监督学习：机器学习分为有监督学习和无监督学习。

*   有监督学习（supervised learning）：从给定的有标记的训练数据集中学习出一个函数（模型参数），当有新的数据时可以根据这个函数预测结果。
*   无监督学习（unsupervised learning）：没有标记的训练数据集，需要根据样本间的统计规律对样本集进行分类。
*   半监督学习（semi-supervised learning）：有监督学习与无监督学习相结合的一种学习方法，使用大量未标记数据的同时也使用标记数据进行学习。

判别式模型、生成式模型：有监督学习可以分为两类模型，判别式模型和生成式模型。

*   判别式模型（Discriminative Models）：判别式模型是通过学习来寻找到不同类别之间的一个决策边界，通过该边界来将样本划分到对应的类别，但对于每一个类别完整的边界没有概念。
*   生成式模型（Generative Moedels）生成式模型是学习每个类别的完整边界，来判断样本属于哪一个类别。

![](/download/attachments/101824243/image2023-5-17_8-59-35.png?version=1&modificationDate=1684285175793&api=v2)![](/download/attachments/101824243/image2023-5-17_9-4-7.png?version=1&modificationDate=1684285447201&api=v2)

2.3. 其他相似概念
-----------

大模型（Large Model）是指具有巨大参数量的深度学习模型，通常需要在大规模数据集上进行训练，这些模型可以包含数千万到数十亿个可训练参数，例如BERT、GPT-2等。

超大模型（X-Large Model）是指比大模型更庞大的深度学习模型，通常需要在更大规模的数据集上进行训练，这些模型包含数十亿到数百亿个可训练的参数，例如T5、GShard等。

基础模型或基石模型（Foundation Model）是指一类通用的、可扩展的大型深度学习模型，具有高度的可重用性和可扩展性，这些模型通常包含多个子模块，可以用于各种不同的自然语言处理和计算机视觉任务，例如Muppet、Switch Transformers等。

三者的差异主要有以下几个方面：

*   模型大小：三者的参数量和计算量都不同，随着模型大小的增大，模型的表达能力和性能也响应增强。
*   训练数据：三者的训练数据集不同，超大模型比大模型需要更大规模、更多样化的数据集进行训练，以提高模型的泛化能力。
*   训练策略：由于模型的大小和复杂度不同，训练策略也不同，比如超大模型可能需要使用分布式训练、模型并行等技术来加速训练。
*   应用场景：这些模型适用于不同的自然语言处理和计算机视觉任务，例如文本分类、语言模型、机器翻译、图像分类、目标检测等，其性能和表现也因此而不同。

  

3\. 现有大模型的分类
============

上述概念了解到大模型可以将任何输入格式映射到任何输出格式，因此，按照输入和输出的数据类型对大模型进行分类，目前共有9类。以下统计的是2022年发布的SOTA大模型（SOTA指State of the Arts，即在某一领域最先进的），这些大模型分别属于6个公司或组织。

![](/download/attachments/101824243/image2023-5-11_10-32-8.png?version=1&modificationDate=1683772329035&api=v2)

3.1. 文本生成图像 Text-to-Image
-------------------------

根据给定的文本条件(Text)准确的生成一张精度足够高的图像(Image)。

以DALL-E 2为例：由OpenAI开发，能够从由文本描述组成的提示中生成原始、逼真的图像，使用的是语言-图像预训练模型CLIP神经网络，特点在于可以将概念、属性和不同风格结合起来。

CLIP全称是Contrastive Language-Image Pre-Training（语言-图像预训练），CLIP一共有两个模态，一个是文本模态，一个是视觉模态，分别对应Text Encoder和Image Encoder，它们分别对文本和图像进行编码。DALL-E 2的工作原理很简单：

1.  将文本prompt输入到经过训练以将prompt映射到表征空间的文本编码器Text Encoder中；
2.  称为

CLIP embedding有几个理想属性：能够对图像分布进行稳定的转换；具有强大的zero-shot能力；在微调后实现了最先进的结果。

[https://blog.csdn.net/weixin\_44791964/article/details/129941386](https://blog.csdn.net/weixin_44791964/article/details/129941386)

[https://blog.csdn.net/qq\_45331246/article/details/127075745](https://blog.csdn.net/qq_45331246/article/details/127075745)

[https://blog.csdn.net/weixin\_45104951/article/details/126872568](https://blog.csdn.net/weixin_45104951/article/details/126872568)

3.2. 文本生成三维模型 Text-to-3D
------------------------

[https://blog.csdn.net/DUDUDUTU/article/details/129745399](https://blog.csdn.net/DUDUDUTU/article/details/129745399)

3.3. 图像生成文本（看图说话） Image-to-Text
-------------------------------

从图像到文字，这类模型也可以称为是Image Captioning模型。

GIT模型是基于Transformer结构，也就是基于self-attention 的机制进行图像处理并识别出文字。GIT模型具备了描述图片内容并且以人类可理解的语言表述出来的能力，同时还具备了文字识别OCR的功能。

[https://zhuanlan.zhihu.com/p/571742023](https://zhuanlan.zhihu.com/p/571742023)

3.4. 文本生成视频 Text-to-Video
-------------------------

[https://blog.csdn.net/weixin\_47196664/article/details/129980513](https://blog.csdn.net/weixin_47196664/article/details/129980513)

3.5. 文本生成音频 Text-to-Audio
-------------------------

[https://dashen.wang/1108.html](https://dashen.wang/1108.html)

[http://www.myzaker.com/article/63ec5d5a8e9f093ae04b7d01](http://www.myzaker.com/article/63ec5d5a8e9f093ae04b7d01)

3.6. 文本生成文本（聊天机器人） Text-to-Text
-------------------------------

  

3.7. 文本生成代码 Text-to-Code
------------------------

  

3.8. 文本生成科学文本 Text-to-Science
-----------------------------

  

3.9. 其他模型 Other Models
----------------------

  

4\. 大模型的使用调研
============

4.1. 国外
-------

### 4.1.1. Text-to-Image

Stable Diffusion

Midjourney

DALL-E 2

### 4.1.2. Text-to-Text

  

  

4.2. 国内
-------

### 4.2.1. Text-to-Text

百度——文心一言：[https://yiyan.baidu.com/welcome](https://yiyan.baidu.com/welcome)

阿里巴巴——通义千问：[https://tongyi.aliyun.com/](https://tongyi.aliyun.com/)

商汤——商汤日日新：[https://techday.sensetime.com/](https://techday.sensetime.com/)

科大讯飞——讯飞星火认知大模型：[https://xinghuo.xfyun.cn/desk](https://xinghuo.xfyun.cn/desk)

360——360GPT

毫末智行——DriveGPT（雪湖·海若），自动驾驶生成式大模型

华为——盘古大模型

京东——ChatJD

### 4.2.2. Text-to-Image

百度——文心一格：[https://yige.baidu.com/?source=33257731](https://yige.baidu.com/?source=33257731)

Vega AI：[https://rightbrain.art/](https://rightbrain.art/)

  

参考：

[https://blog.csdn.net/qq\_42485936/article/details/126244935](https://blog.csdn.net/qq_42485936/article/details/126244935)

[https://baijiahao.baidu.com/s?id=1756520241186383004&wfr=spider&for=pc](https://baijiahao.baidu.com/s?id=1756520241186383004&wfr=spider&for=pc)

[https://blog.csdn.net/weixin\_40252835/article/details/117936708?utm\_relevant\_index=6](https://blog.csdn.net/weixin_40252835/article/details/117936708?utm_relevant_index=6)

[https://www.zhihu.com/question/498275802/answer/2976868465?utm\_id=0](https://www.zhihu.com/question/498275802/answer/2976868465?utm_id=0)

[https://zhuanlan.zhihu.com/p/602997473](https://zhuanlan.zhihu.com/p/602997473)

[http://stock.hexun.com/2023-04-07/208224388.html](http://stock.hexun.com/2023-04-07/208224388.html)

[http://xxzx.guizhou.gov.cn/dsjzsk/swzx/202303/t20230313\_78441467.html](http://xxzx.guizhou.gov.cn/dsjzsk/swzx/202303/t20230313_78441467.html)

[https://baijiahao.baidu.com/s?id=1762887537909843466&wfr=spider&for=pc](https://baijiahao.baidu.com/s?id=1762887537909843466&wfr=spider&for=pc)

[http://www.360doc.com/content/12/0121/07/72305947\_1068819065.shtml](http://www.360doc.com/content/12/0121/07/72305947_1068819065.shtml)

[https://zhuanlan.zhihu.com/p/578696983](https://zhuanlan.zhihu.com/p/578696983)

[https://blog.csdn.net/yimeixiaobai\_/article/details/105925434](https://blog.csdn.net/yimeixiaobai_/article/details/105925434)

[《达摩院2023十大科技趋势》.pdf](/download/attachments/101824243/%E3%80%8A%E8%BE%BE%E6%91%A9%E9%99%A22023%E5%8D%81%E5%A4%A7%E7%A7%91%E6%8A%80%E8%B6%8B%E5%8A%BF%E3%80%8B.pdf?version=1&modificationDate=1683791188254&api=v2)

[艾瑞咨询：2023年中国科技与IT十大趋势.pdf](/download/attachments/101824243/%E8%89%BE%E7%91%9E%E5%92%A8%E8%AF%A2%EF%BC%9A2023%E5%B9%B4%E4%B8%AD%E5%9B%BD%E7%A7%91%E6%8A%80%E4%B8%8EIT%E5%8D%81%E5%A4%A7%E8%B6%8B%E5%8A%BF.pdf?version=1&modificationDate=1683791189972&api=v2)

[艾瑞咨询：ChatGPT浪潮下，看中国大语言模型产业发展.pdf](/download/attachments/101824243/%E8%89%BE%E7%91%9E%E5%92%A8%E8%AF%A2%EF%BC%9AChatGPT%E6%B5%AA%E6%BD%AE%E4%B8%8B%EF%BC%8C%E7%9C%8B%E4%B8%AD%E5%9B%BD%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%BA%A7%E4%B8%9A%E5%8F%91%E5%B1%95.pdf?version=1&modificationDate=1683791191077&api=v2)

[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)

[Configure buttons visibility](/users/tfac-settings.action)