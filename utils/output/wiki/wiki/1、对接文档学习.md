---
author: "王宇"
title: "1、对接文档学习"
date: 三月10,2023
description: "AIUI项目对接文档内容理解学习"
tags: ["AIUI项目对接文档内容理解学习"]
ShowReadingTime: "12s"
weight: 141
---
*   1[1\. 语音唤醒/语音识别/语音合成](#id-1、对接文档学习-语音唤醒/语音识别/语音合成)
    *   1.1[1.1. 语音唤醒](#id-1、对接文档学习-语音唤醒)
    *   1.2[1.2. 语音识别](#id-1、对接文档学习-语音识别)
    *   1.3[1.3. 语音合成](#id-1、对接文档学习-语音合成)

1\. 语音唤醒/语音识别/语音合成
==================

1.1. 语音唤醒
---------

**一、唤醒率：**

唤醒测试规范：[https://www.yuque.com/iflyaiui/zzoolv/neoqf7](https://www.yuque.com/iflyaiui/zzoolv/neoqf7)

效果调优：[https://www.yuque.com/iflyaiui/zzoolv/xf3mia#h8xJb](https://www.yuque.com/iflyaiui/zzoolv/xf3mia#h8xJb)

提高唤醒率的方法：

1、增加唤醒词的种类：一般情况就是只设置一个唤醒词，其他指令在唤醒后通过语音输入交互；其他的提高方法有：

（1）一些涉及到设备控制的指令操作，可配置成离线命令词，不用每次去请求云端，提高速率；

（2）和用户需求相关的指令操作（指令中带有“我想”“我要”“帮我”“给我”“有没有”等前缀），可配置成免唤醒入口词，将指令前缀设置为入口词，省去输入唤醒词的步骤。

2、对设置的唤醒词进行优化：有模糊匹配和快语速匹配两种，比如唤醒词是“你好小智”，模糊匹配可以设置“你好小芝”“尼好小智”“你好小字”等；快语速匹配可以设置“鸟小智”“辽小芝”等。

  

**二、误唤醒率：**

误唤醒原理：唤醒模型设定一个阈值，当唤醒得分＞阈值时就会被唤醒

浅定制唤醒词下的数据参考：

*   你好xx ，阈值900，一天误唤醒4次
*   ABAB，阈值900，一天误唤醒10+次

降低误唤率的方法：

1、简单的方法有：

（1）减少指令数量；

（2）增加指令字数（“播放”可以变成“给我播放”）；

（3）量化测试，根据测试结果来修改不同词的阈值；

（4）使用云端指令（见上面唤醒词类型表格），用在线语义做过滤；【这些简单的方法都是在一定程度上牺牲用户体验来换取较低的误唤醒率，慎用】

2、对不同场景设置不同的阈值和屏蔽，比如夜晚场景相对于白天场景来说阈值会稍微高一些，降低误唤率；只有在播放音乐的场景下才可以执行“快进30s”的指令，其他场景下则不会执行（实现方式：onWakeUp唤醒回调中，根据不同的场景判断score得分，并判断场景）；

3、（收费）反例训练：当前技术还无法完全屏蔽相似词唤醒，但可以做针对特定词的反例训练（比如“小飞小飞”的唤醒词，反例词可以是“小可小可”等），提供反例词列表给讯飞；

4、（收费）字阈值：针对某个字设定阈值，只有唤醒词得分＞阈值，且字得分＞字阈值时才会出发唤醒。

注：真实数据迭代训练：初次训练的数据是按标准场景录制的，设备卖出后迭代训练可以获取真实设备的用户唤醒数据，贴近实际场景。**数据量：唤醒数据 >4w ,建议8w；误唤醒数据>5k,建议1w**。

**唤醒率与误唤醒率的调优还要随着设备被放到真实环境中使用后持续进行**

1.2. 语音识别
---------

**三、识别率：**

语音识别测试规范：[https://www.yuque.com/iflyaiui/zzoolv/xno4yf](https://www.yuque.com/iflyaiui/zzoolv/xno4yf)

效果调优：[https://www.yuque.com/iflyaiui/zzoolv/xf3mia#h8xJb](https://www.yuque.com/iflyaiui/zzoolv/xf3mia#h8xJb)

提高识别率的方法：

1、定制识别模型是一种提高识别率的方法；

2、对识别的词本身做调整：

（1）配置识别热词：原理即增加词的权重，提高识别率，同音/相似词需慎重添加，可能导致热词误触发；

（2）识别结果模糊匹配：因发音错误导致的识别错误，可以在拿到识别结果后代码做强制转换，原因是兼容用户的错误发音，从而正确进行语义理解；

（3）过滤无意义词[https://www.yuque.com/iflyaiui/zzoolv/agg7qu：端侧过滤掉无意义的结果，从而不响应，针对技能类产品，可以先关闭闲聊，后期获取到用户真实数据后不断完善技能的说法；针对闲聊类产品，需要不断扩充无意义词库，可以有两种结果处理方式：](https://www.yuque.com/iflyaiui/zzoolv/agg7qu：端侧过滤掉无意义的结果，从而不响应，针对技能类产品，可以先关闭闲聊，后期获取到用户真实数据后不断完善技能的说法；针对闲聊类产品，需要不断扩充无意义词库，可以有两种结果处理方式：)

①屏幕不显示asr结果，也不播放tts和语义，直接结束对话；

②屏幕显示asr识别结果并显示没听懂，不播报tts，而是让用户再说一次。【②的处理方式更好些，显示出asr可以让用户下次输入时纠正自己的语音错误】

3、调整其他的参数：

（1）调整音量增益：定义交互距离，降低增益后，距离半米处的识别不会受到影响，但是远处的噪声能量很低不会触发vad，也就不会乱识别；

（2）调整VAD阈值（VAD，Voice Activity Detection语音端点检测）：VAD技术的主要任务是从带有噪声的语音中定位出语音的开始和结束点[https://www.jianshu.com/p/cfc9caee5b38。配置aiui.cfg的threshold参数，取值范围\[0,1](https://www.jianshu.com/p/cfc9caee5b38。配置aiui.cfg的threshold参数，取值范围[0,1)\] ,越大越难触发识别。一般设置为0.6。高噪声场景可以稍微调大vad阈值。

1.3. 语音合成
---------

  

  

[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)

[Configure buttons visibility](/users/tfac-settings.action)