---
author: "王宇"
title: "FAQ类短文本实践内容总结"
date: 二月19,2024
description: "知识插件"
tags: ["知识插件"]
ShowReadingTime: "12s"
weight: 693
---
前段时间，以“春节活动内容”作为基础文本数据，实现了从文本处理、知识库构建、检索方案确定及大模型知识问答整个 rag 系统全链路的流程。因“春节活动内容”是经过人工处理的答案类短文本（最长723个字），故其处理方式与 FAQ 类短文本的处理方式相差无几，本文对相关实践内容做一个总结。

1\. 文本处理
========

FAQ 类短文本直接按照一问一答的粒度拆分，考虑到向量化模型的长度限制，要求拆分后的文本最长不能超过750个词，最短不能少于1个词（过短的内容去除）。

因提供的文本数据只有答案无对应的问题，故未使用元数据，直接读取txt\\docx文档并利用换行符进行切分，得到拆分后的文本列表。

2\. 知识库构建
=========

向量化模型采用开源预训练的模型，本地 CPU 部署，未使用任何加速技术。

3\. 检索方案确定
==========

测试发现，纯向量检索召回（阈值范围0-2）效果不太好，阈值为1的情况下测试结果如下：

![](/download/attachments/119675228/image2024-2-18_18-46-35.png?version=1&modificationDate=1708253195527&api=v2)

由此可见，当前场景下，[bge-base-zh-v1.5](https://huggingface.co/BAAI/bge-base-zh-v1.5) 模型表现更好，故选用该模型构建向量库并用于向量检索。

通过引入关键词召回，并调整相关权重和阈值（向量召回权重0.8，阈值1.4；关键词召回权重0.2，阈值6），再次使用春节活动测试用例测试后，模型效果有较大提升：

![](/download/attachments/119675228/image2024-2-18_18-59-10.png?version=1&modificationDate=1708253950389&api=v2)

由此可见，检索方案的确定并非一蹴而就的，需要基于具体的场景数据来测评。首先要初选向量化模型，敲定检索方式后，还需要多次测试来确定具体的权重和阈值。

4\. 大模型知识问答
===========

本案例采用的是多次测试调整后的提示词和讯飞星火认知大模型完成知识问答，从测试结果来看，回答错误的用例中，有部分检索到了对应的知识，但大模型回答错误，可能与检索知识的顺序和无关内容的影响有关，由此可见检索效果对结果影响较大，但大模型本身的能力也很重要。所以后续大模型的选择、提示词的确认都需要基于具体的场景数据来测评抉择。

[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)

[Configure buttons visibility](/users/tfac-settings.action)