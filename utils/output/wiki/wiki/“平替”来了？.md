---
author: "王宇"
title: "“平替”来了？"
date: 四月11,2024
description: "GPT相关"
tags: ["GPT相关"]
ShowReadingTime: "12s"
weight: 200
---
1\. 概述     
===========

        目前公司研发中的虚拟数字人产品，定位成一个能和用户进行语音交互，能感知有限外部世界的，“住在屏幕里”的具有人形并是通过软件代码编写的“虚拟人物”。从这个定义来看，我们可以无限来拆解这些修饰词的概念，并结合当前时代的科学技术水平来给每一个因素做一个合理的限定。同时从技术角度来给每个部分做对应技术分析，以公开的技术、开源的代码做参考，对比每个技术的优缺点。在这个分析过程中，会涉及到技术选型分析、测试数据、效果测试等环节，技术层面会涉及到新知识、新概念，甚至知识盲区，故不会做过多细致的技术分析，以简洁描述为主。

【也有整体的方案：[https://www.xfyun.cn/doc/tts/virtual\_human/Web-SDK.html】](https://www.xfyun.cn/doc/tts/virtual_human/Web-SDK.html)

【如何最简单、通俗地理解什么是NLP？[https://www.zhihu.com/question/433756594](https://www.zhihu.com/question/433756594)】

1.1. 能和用户进行语音交互
---------------

     这个定义涉及到如下的概念：

1.  耳朵听得见、听得清、听得懂
2.  能给予合适的反馈，播报反馈内容

“**耳朵，听得见**，指的是硬件麦克风，目前万得厨2.0上的麦克风模组是科大讯飞公司建议的双麦模组。补充一点是，麦克风选型和麦克风阵列构型对声学效果至关重要，要求较高。可参考：[智能硬件通用方案说明](https://www.xfyun.cn/doc/solutions/hardwareUniversal/hardwareUniversalreadme.html)、[讯飞软硬件产品接入](https://aiui-doc.xf-yun.com/project-1/doc-38/)

“**听得清**”，指的是能够在外部有噪音情况下听得清用户语音内容，以及方言、不同语种（当前主打中文）、不同音色等等的语音表达，能够准确提炼出准确的文本内容。目前万得厨2.0采用的是科大讯飞提供的降噪算法，以及方言、语种、语音动态修正。

“**懂得懂**”，指的是能够识别出用户的语音所要表达的对应文本，词语类包含行业内专有名词，语义类包含整句话所要表达的意思，词语类采用的是科大讯飞的热词方案，也可使用：[语音听写自训练平台](https://www.xfyun.cn/solutions/voicedication-train)，来实现专有词语的准确识别。语义理解采用的是虚拟人公司的发难，通过接口api形式调用。

“**能给予合适的反馈，播报反馈内容**”，指的是在语义理解的基础上，识别出意图，给出语音反馈（从文本到语音），这一块技术难度系数最大，本质是对人类语言逻辑的一次响应，智能程度在此得到充分的表达。目前采用的是虚拟人公司提供的知识库方案，包含指令、问答。

### 1.1.1. 分析

**听得见、听得清**，目前采用的全是科大讯飞公司的方案，其方案整体实力在业内算是排在头部，平替方案为：采用其他公司的语音方案。

**听得懂**，包含行业内专有名词的词语类采用的是科大讯飞公司方案，平替方案为：采用其他公司的语音方案。

**听得懂，能给予合适的反馈，播报反馈内容，**“听得懂**”**中，整句话的语义理解，其实现技术为分词、文本分类，实体识别等等，平替方案如下所示。给予合适的反馈可以当做是“技能”，比作是AI时代的APP。可以是执行单一任务的弱智能，也可是能执行多任务、泛化问题的强智能。可使用问答系统、不同的大模型单独或者配合实现 。

### 1.1.2. 指令实现平替方案

    这个有几种常见的算法可以实现：余弦(cosine)相似度、逆文本频率(idf)与余弦(cosine)相结合、BM25 相关性评分、Jaccard 系数。

    如果要做每种算法的效果对比的话，准备工作如下：

*   step1：通过word2vec对txt文件进行向量训练，生成词向量文件
*   step2：对训练出来的词，计算其在词料库中的idf词，生成idf.txt文件
*   step3：统计词料库中存在的句子，生成flie\_sentence.txt文件
*   step4：运行程序，对设定好的输入的句子与文本，生成最相似的结果

平替方案中选用余弦相似度与Jaccard系数做对比，需要step2和step4，具体步骤如下：

1.  整理相似问文件、标准问文件；
2.  作为输入，进行余弦相似度和Jaccard相似度计算

核心代码如下：

**test.py**  展开源码

[expand source](#)[?](#)

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

`def` `test():`

    `test_data``=``[u``'启动烹饪'``]`

    `model_list``=``[``'cosine'``,``'jaccard'``,``'idf'``,``'bm25'``]`

    `file_sentence``=``codecs.``open``(``'./data_1/file_sentence.txt'``,``'r'``,encoding``=``'utf-8'``)`

    `train_data``=``file_sentence.readlines()`

    `for` `model` `in` `model_list[:``1``]:`

        `t1` `=` `time.time()`

        `dataset``=``dict``()`

        `result``=``dict``()`

        `for` `s1` `in` `test_data[``0``:``1``]:`

            `dataset[s1]``=``dict``()`

            `for` `s2` `in` `train_data:`

                `s2``=``s2.strip()`

                `if` `s1!``=``s2:`

                    `sim``=``similarity.ssim(s1,s2,model``=``model)`

                    `dataset[s1][s2]``=``dataset[s1].get(s2,``0``)``+``sim`

        `for` `r` `in` `dataset:`

            `top``=``sorted``(dataset[r].items(),key``=``lambda` `x:x[``1``],reverse``=``True``)`

            `result[r]``=``top[``0``:``10``]`

        `with codecs.``open``(``'./data_1/test_result.txt'``,``'w'``,encoding``=``'utf-8'``) as f:`

            `f.write(``'--------------The result of %s method------------------\n '``%``model)`

            `f.write(``'\tThe computing cost %.3f seconds\n'``%` `(time.time()` `-` `t1))`

            `f.write(json.dumps(result, ensure_ascii``=``False``, indent``=``2``, sort_keys``=``False``))`

            `f.write(``'\n\n'``)`

    `file_sentence.close()`

**similarity.py**  展开源码

[expand source](#)[?](#)

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

`#encoding:utf-8`

`from` `__future__` `import` `absolute_import`

`import` `jieba`

`import` `time`

`from` `scipy` `import` `spatial`

`import` `numpy as np`

`from` `Utils.load_data` `import` `*`

`file_voc``=``'./data_1/voc.txt'`

`file_idf``=``'./data_1/idf.txt'`

`file_userdict``=``'./data_1/medfw.txt'`

`class` `SSIM(``object``):`

    `def` `__init__(``self``):`

        `t1` `=` `time.time()`

        `self``.voc``=``load_voc(file_voc)`

        `print``(``"Loading  word2vec vector cost %.3f seconds...\n"` `%` `(time.time()` `-` `t1))`

        `t1` `=` `time.time()`

        `self``.idf``=``load_idf(file_idf)`

        `print``(``"Loading  idf data cost %.3f seconds...\n"` `%` `(time.time()` `-` `t1))`

        `jieba.load_userdict(file_userdict)`

    `def` `M_jaccard(``self``,s1, s2):`

        `s1` `=` `set``(s1)`

        `s2` `=` `set``(s2)`

        `ret1` `=` `s1.intersection(s2)`

        `ret2` `=` `s1.union(s2)`

        `jaccard` `=` `1.0` `*` `len``(ret1)``/` `len``(ret2)`

        `return` `jaccard`

    `def` `ssim(``self``,s1,s2,model``=``'cosine'``):`

        `if` `model``=``=``'idf'``:`

            `f_ssim``=``self``.M_idf`

        `elif` `model``=``=``'bm25'``:`

            `f_ssim``=``self``.M_bm25`

        `elif` `model``=``=``'jaccard'``:`

            `f_ssim``=``self``.M_jaccard`

        `else``:`

            `f_ssim` `=` `self``.M_cosine`

        `sim``=``f_ssim(s1,s2)`

        `return` `sim`

`sm``=``SSIM()`

`ssim``=``sm.ssim`

以“启动烹饪”为标准问，数字为相似度，取相似度前十的数据为：

**result.json**  展开源码

[expand source](#)[?](#)

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

58

59

60

61

62

63

64

65

66

67

68

69

70

71

72

73

74

75

`--------------The result of cosine method------------------`

    `The computing cost 0.200 seconds`

`{`

  `"启动烹饪": [`

    `["烹饪启动",1.0],`

    `["启动烹饪程序",0.9998],`

    `["启动微波烹饪",0.9998],`

    `["启动微博烹饪",0.9998],`

    `["启动微波炉烹饪",0.9997],`

    `["请启动烹饪",0.9997],`

    `["我想烹饪启动",0.9997],`

    `["查看DIY烹饪页面",0.9996],`

    `["启动烹饪功能",0.9996],`

    `["启动食品烹饪",0.9996],`

    `["请启动微波炉烹饪",0.9996],`

    `["停止烹饪",0.9996],`

    `["烹饪停止",0.9996],`

    `["跳转到我的烹饪记录页面",0.9995],`

    `["宝宝微热烹饪",0.9995],`

    `["打开DIY烹饪页面",0.9995],`

    `["开启DIY烹饪页面",0.9995],`

    `["调出DIY烹饪页面",0.9995],`

    `["查看DIY烹饪",0.9995],`

    `["开启一键烹饪页面",0.9995],`

    `["调出一键烹饪页面",0.9995],`

    `["查看一键烹饪页面",0.9995],`

    `["我想一键烹饪",0.9995],`

    `["我要查看一键烹饪页面",0.9995],`

    `["查看智能烹饪页面",0.9995],`

    `["查看智能烹饪",0.9995],`

    `["我要查看智能烹饪页面",0.9995],`

    `["开启烹饪",0.9995],`

    `["开启烹饪程序",0.9995],`

    `["烹饪开启",0.9995`

    `]`

  `]`

`}`

`--------------The result of jaccard method------------------`

    `The computing cost 0.010 seconds`

`{`

  `"启动烹饪": [`

    `["烹饪启动",1.0],`

    `["请启动烹饪",0.8],`

    `["启动烹饪功能",0.667],`

    `["启动烹饪程序",0.667],`

    `["启动食品烹饪",0.667],`

    `["启动微波烹饪",0.667],`

    `["启动微博烹饪",0.667],`

    `["我想烹饪启动",0.667],`

    `["启动烹调",0.6],`

    `["开启烹饪",0.6],`

    `["烹调启动",0.6],`

    `["烹饪开启",0.6],`

    `["启动微波炉烹饪",0.571],`

    `["启动万得厨烹饪",0.571],`

    `["启动",0.5],`

    `["请启动微波炉烹饪",0.5],`

    `["开启一键烹饪",0.429],`

    `["开启智能烹饪",0.429],`

    `["启动烹调功能",0.429],`

    `["开启烹饪功能",0.429],`

    `["启动烹调程序",0.429],`

    `["开启烹饪程序",0.429],`

    `["启动食品烹调",0.429],`

    `["开启食品烹饪",0.429],`

    `["启动微波烹调",0.429],`

    `["启动微波炉烹调",0.375],`

    `["启动万得厨烹调",0.375],`

    `["开启DIY烹饪",0.375],`

    `["重新烹饪",0.333],`

    `["解冻烹饪",0.333`

    `]`

  `]`

`}`

这其中能够看出，对于标准问与列出的相似问列表，其中的按照语义可按照两者之间相关性给出匹配，但这和目标要求的路径有点差距。举例子：

1.  “开始烹饪”，\[“烹饪启动”，“烹饪开启”\]，两者之间有一定的语义相关性，但与“开始做菜”的语义相似度为0，相似问的目的就是将“开始做菜”这种Jaccard相似度低的，也能匹配的上，这里需要做一个转换、训练；
2.  语义匹配度，相似问里面的语句应该都得是1，相似问的期望就是：在相似问里面的所有语句，匹配度都是1，当然也可设置一个阈值（一般90%以上）；
3.  余弦（cosine）相似度方案有较明显的误识别情况，而Jaccard相似度方案又识别不了的情况（设置某一个阈值的情况），这个需要讲训练集（目前是相似问）需要做一些工程上的处理，提升准确度。

### 1.1.3. 优化方案-----使用bert模型

    模型名称为bert-base-chinese，其具体实现如下：

**similarity.py**  展开源码

[expand source](#)[?](#)

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

`import` `json`

`import` `time`

`import` `numpy as np`

`import` `pandas as pd`

`from` `flask` `import` `Flask, request, jsonify`

`from` `sentence_transformers` `import` `SentenceTransformer`

`app` `=` `Flask(__name__)`

`model` `=` `SentenceTransformer(r``'D:\gitlab\sentence-similarity\model\bert-base-chinese'``)`

`model.``eval``()`

`content` `=` `pd.read_table(``"./data_1/bert_test_data.txt"``, header``=``None``)[``0``].values.tolist()`

`passage_embedding` `=` `model.encode(content, convert_to_numpy``=``True``)`

`def` `cosine_similarity(x, y):`

    `num` `=` `x.dot(y.T)`

    `denom` `=` `np.linalg.norm(x)` `*` `np.linalg.norm(y, axis``=``1``)`

    `return` `num` `/` `denom`

`def` `sim(ask, level):`

    `time1` `=` `time.time()`

    `ask` `=` `model.encode([ask])`

    `time2` `=` `time.time()`

    `spend_time` `=` `time2` `-` `time1`

    `print``(spend_time)`

    `cos_matrix` `=` `cosine_similarity(ask, passage_embedding)[``0``]`

    `index` `=` `np.argsort(``-``cos_matrix)[level]`

    `return` `[content[index], cos_matrix[index]]`

`@app``.route(``'/top_ask'``, methods``=``[``'GET'``,` `'POST'``])`

`def` `get_synonyms():`

    `json_data` `=` `request.get_data()`

    `comment_json` `=` `json.loads(json_data)`

    `ask` `=` `comment_json[``'ask'``]`

    `json_data` `=` `sim2(ask,` `0``)`

    `return` `jsonify({``"text"``:` `str``(json_data[``0``]),` `"相似度"``:` `str``(json_data[``1``])})`

`if` `__name__` `=``=` `'__main__'``:`  `#`

    `app.run(host``=``"0.0.0.0"``, port``=``1089``, debug``=``True``)`

其中：

*   bert\_test\_data在本例中是相似问集合，

1.2. 具有人形并通过文本驱动动作
------------------

  

  

  

  

  

  

[Filter table data](#)[Create a pivot table](#)[Create a chart from data series](#)

[Configure buttons visibility](/users/tfac-settings.action)